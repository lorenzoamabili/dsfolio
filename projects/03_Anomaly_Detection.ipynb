{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Multivariate Anomaly Detection\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš¨ Anomaly Detection in Sensor Streams\n",
    "**Portfolio Project 3 â€” Multivariate Anomaly Detection**\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "Detect point anomalies and contextual anomalies in multivariate sensor data\n",
    "using statistical, isolation-based, and autoencoder approaches.\n",
    "\n",
    "## Dataset\n",
    "**NASA SMAP / MSL Benchmark (subset) â€” simulated equivalent**\n",
    "Original: https://github.com/nasa/anomaly-detection\n",
    "We replicate its structure with synthetic channels.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.signal import butter, filtfilt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Multi-Channel Sensor Data with Known Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate sensor streams + inject anomalies\n",
    "def gen_anomaly_data(n=10000, n_ch=5, seed=99):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    t = np.linspace(0, 50, n)\n",
    "\n",
    "    # Normal signals: sinusoidal + noise\n",
    "    signals = np.column_stack([\n",
    "        np.sin(t/(3+i) + i) * (1 + 0.2*i) + rng.normal(0, 0.15, n)\n",
    "        for i in range(n_ch)\n",
    "    ])\n",
    "\n",
    "    labels = np.zeros(n, dtype=int)  # 0 = normal\n",
    "\n",
    "    # --- Inject anomalies ---\n",
    "    # Point anomalies\n",
    "    point_idx = rng.choice(n, 80, replace=False)\n",
    "    ch_idx = rng.integers(0, n_ch, 80)\n",
    "    signals[point_idx,\n",
    "            ch_idx] += rng.choice([-1, 1], 80) * rng.uniform(3, 6, 80)\n",
    "    labels[point_idx] = 1\n",
    "\n",
    "    # Contextual anomalies: sudden mean shift on channel 0 for a window\n",
    "    for start in rng.choice(range(100, n-200), 5, replace=False):\n",
    "        window = slice(start, start+40)\n",
    "        signals[window, 0] += 2.5\n",
    "        labels[window] = 1\n",
    "\n",
    "    # Collective anomaly: correlated spike across all channels\n",
    "    for start in rng.choice(range(200, n-100), 3, replace=False):\n",
    "        window = slice(start, start+20)\n",
    "        signals[window, :] += rng.normal(1.8, 0.3, (20, n_ch))\n",
    "        labels[window] = 1\n",
    "\n",
    "    cols = [f'Ch_{i}' for i in range(n_ch)]\n",
    "    df = pd.DataFrame(signals, columns=cols)\n",
    "    df['Timestamp'] = pd.date_range('2024-03-01', periods=n, freq='1min')\n",
    "    df['True_Anomaly'] = labels\n",
    "    return df\n",
    "\n",
    "\n",
    "df = gen_anomaly_data()\n",
    "print(\n",
    "    f'Dataset: {df.shape}  |  Anomaly rate: {df[\"True_Anomaly\"].mean()*100:.1f}%')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Statistical Method â€” Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Per-channel Z-Score anomaly detection\n",
    "ch_cols = [c for c in df.columns if c.startswith('Ch_')]\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(\n",
    "    df[ch_cols]), columns=ch_cols, index=df.index)\n",
    "\n",
    "# Flag if |Z| > threshold on ANY channel\n",
    "Z_THRESH = 3.0\n",
    "df['zscore_anomaly'] = (df_scaled.abs() > Z_THRESH).any(axis=1).astype(int)\n",
    "\n",
    "print('Z-Score Detection:')\n",
    "print(classification_report(\n",
    "    df['True_Anomaly'], df['zscore_anomaly'], target_names=['Normal', 'Anomaly']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Isolation Forest\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination=df['True_Anomaly'].mean(),\n",
    "    max_samples=256,\n",
    "    random_state=42\n",
    ")\n",
    "df['iso_pred'] = (iso.fit_predict(df[ch_cols]) == -1).astype(int)\n",
    "# higher = more anomalous\n",
    "df['iso_score'] = -iso.decision_function(df[ch_cols])\n",
    "\n",
    "print('Isolation Forest Detection:')\n",
    "print(classification_report(df['True_Anomaly'],\n",
    "      df['iso_pred'], target_names=['Normal', 'Anomaly']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sliding-Window Autoencoder (Reconstruction Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Simple sliding-window reconstruction (no deep-learning dependency)\n",
    "# Uses PCA as a linear autoencoder proxy â€” portable & fast\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "N_COMP = 2  # bottleneck dimension\n",
    "pca = PCA(n_components=N_COMP)\n",
    "recon = pca.fit_transform(df[ch_cols].values)\n",
    "recon_full = pca.inverse_transform(recon)  # reconstructed signal\n",
    "\n",
    "# Reconstruction error per row\n",
    "df['recon_error'] = np.mean((df[ch_cols].values - recon_full)**2, axis=1)\n",
    "\n",
    "# Threshold: mean + 3*std on training portion (first 80%)\n",
    "train_end = int(len(df)*0.8)\n",
    "thresh = df['recon_error'].iloc[:train_end].mean(\n",
    ") + 3*df['recon_error'].iloc[:train_end].std()\n",
    "df['recon_anomaly'] = (df['recon_error'] > thresh).astype(int)\n",
    "\n",
    "print(f'Reconstruction threshold: {thresh:.4f}')\n",
    "print('\\nPCA-Autoencoder Detection:')\n",
    "print(classification_report(\n",
    "    df['True_Anomaly'], df['recon_anomaly'], target_names=['Normal', 'Anomaly']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plot Channel 0 with all three detection layers\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 10), sharex=True)\n",
    "\n",
    "# Raw signal + true anomalies\n",
    "axes[0].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\n",
    "anom_mask = df['True_Anomaly'] == 1\n",
    "axes[0].scatter(df.loc[anom_mask, 'Timestamp'],\n",
    "                df.loc[anom_mask, 'Ch_0'], s=15, color='red', zorder=5)\n",
    "axes[0].set_title('Channel 0 â€” True Anomalies (red)', fontsize=11)\n",
    "axes[0].set_ylabel('Signal')\n",
    "\n",
    "# Z-Score detections\n",
    "axes[1].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\n",
    "z_mask = df['zscore_anomaly'] == 1\n",
    "axes[1].scatter(df.loc[z_mask, 'Timestamp'], df.loc[z_mask,\n",
    "                'Ch_0'], s=15, color='orange', zorder=5)\n",
    "axes[1].set_title('Z-Score Detections (orange)', fontsize=11)\n",
    "axes[1].set_ylabel('Signal')\n",
    "\n",
    "# Isolation Forest\n",
    "axes[2].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\n",
    "iso_mask = df['iso_pred'] == 1\n",
    "axes[2].scatter(df.loc[iso_mask, 'Timestamp'],\n",
    "                df.loc[iso_mask, 'Ch_0'], s=15, color='green', zorder=5)\n",
    "axes[2].set_title('Isolation Forest Detections (green)', fontsize=11)\n",
    "axes[2].set_ylabel('Signal')\n",
    "\n",
    "# Reconstruction error\n",
    "axes[3].plot(df['Timestamp'], df['recon_error'], lw=0.7, color='purple')\n",
    "axes[3].axhline(thresh, color='crimson', ls='--',\n",
    "                lw=1.2, label=f'Threshold={thresh:.3f}')\n",
    "axes[3].set_title('PCA Reconstruction Error', fontsize=11)\n",
    "axes[3].set_ylabel('MSE')\n",
    "axes[3].set_xlabel('Time')\n",
    "axes[3].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Confusion matrices side-by-side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "methods = [('Z-Score', 'zscore_anomaly'), ('Isolation Forest',\n",
    "                                           'iso_pred'), ('PCA-AE', 'recon_anomaly')]\n",
    "\n",
    "for ax, (name, col) in zip(axes, methods):\n",
    "    cm = confusion_matrix(df['True_Anomaly'], df[col])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "    ax.set_title(f'{name}', fontsize=12)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "plt.suptitle('Confusion Matrices', fontsize=14, y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Implemented three complementary anomaly-detection strategies\n",
    "- **Z-Score** catches large point anomalies; misses contextual shifts\n",
    "- **Isolation Forest** adapts to multivariate density; good recall on collective anomalies\n",
    "- **PCA Reconstruction** captures structural deviation across all channels\n",
    "- An ensemble (OR/AND combination) of these methods is the production-ready approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
