{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Energy Consumption Forecasting\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Time Series Forecasting\n",
    "**Portfolio Project 2 â€” Energy Consumption Prediction**\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "Build and evaluate multiple forecasting models on an energy-consumption time series.\n",
    "\n",
    "## Dataset\n",
    "**UCI Appliances Energy Prediction Dataset**\n",
    "- 10 minutes resolution, ~20,000 rows\n",
    "- Target: `Appliances` energy (Wh)\n",
    "- Features: temperature, humidity, wind, pressure from 3 weather stations\n",
    "- Download: https://archive.ics.uci.edu/dataset/330\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation (UCI-Replica Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Synthetic energy data matching UCI structure\n",
    "def gen_energy_data(n=20050, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dates = pd.date_range('2016-01-11 00:00', periods=n, freq='10min')\n",
    "\n",
    "    hour = dates.hour + dates.minute / 60\n",
    "    dow = dates.dayofweek\n",
    "\n",
    "    # Realistic temperature (Â°C) with daily cycle\n",
    "    T1 = 20 + 5*np.sin(2*np.pi*(hour-6)/24) + rng.normal(0, 1.5, n)\n",
    "    T2 = T1 + rng.normal(0.5, 0.8, n)\n",
    "    T3 = T1 + rng.normal(-0.3, 1.0, n)\n",
    "\n",
    "    # Humidity\n",
    "    H1 = 55 - 0.8*T1 + rng.normal(0, 4, n)\n",
    "    H2 = H1 + rng.normal(0, 2, n)\n",
    "    H3 = H1 + rng.normal(1, 3, n)\n",
    "\n",
    "    # Wind & pressure\n",
    "    wind = np.clip(rng.exponential(3, n), 0, 25)\n",
    "    pressure = 1013 + rng.normal(0, 5, n)\n",
    "\n",
    "    # Target: Appliances energy\n",
    "    appliances = (\n",
    "        30\n",
    "        + 12 * np.sin(2*np.pi*(hour-7)/24)**2\n",
    "        + 8 * (dow < 5).astype(float)\n",
    "        + 0.3*T1 + 0.1*H1 - 0.05*wind\n",
    "        + rng.normal(0, 8, n)\n",
    "    )\n",
    "    appliances = np.clip(appliances, 5, 250)\n",
    "\n",
    "    # Random appliance\n",
    "    random_app = rng.exponential(15, n)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'Appliances': appliances.round(1),\n",
    "        'random1': random_app.round(1),\n",
    "        'T1': T1.round(2), 'T2': T2.round(2), 'T3': T3.round(2),\n",
    "        'H1': H1.round(2), 'H2': H2.round(2), 'H3': H3.round(2),\n",
    "        'Wind': wind.round(2), 'Pressure': pressure.round(2)\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "df = gen_energy_data()\n",
    "df.set_index('date', inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Temporal + lag features\n",
    "df['hour'] = df.index.hour\n",
    "df['dow'] = df.index.dayofweek\n",
    "df['month'] = df.index.month\n",
    "df['is_weekend'] = (df['dow'] >= 5).astype(int)\n",
    "\n",
    "# Lag features\n",
    "for lag in [6, 12, 24, 144]:  # 1h, 2h, 4h, 1day\n",
    "    df[f'App_lag{lag}'] = df['Appliances'].shift(lag)\n",
    "\n",
    "# Rolling features\n",
    "for win in [6, 24, 144]:\n",
    "    df[f'App_roll_mean_{win}'] = df['Appliances'].rolling(win).mean()\n",
    "    df[f'App_roll_std_{win}'] = df['Appliances'].rolling(win).std()\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(f'After feature eng: {df.shape}')\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train / Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Chronological train-test split\n",
    "TARGET = 'Appliances'\n",
    "DROP = ['random1']  # intentionally noisy feature\n",
    "\n",
    "X = df.drop(columns=[TARGET] + DROP)\n",
    "y = df[TARGET]\n",
    "\n",
    "# Last 20% as test (temporal)\n",
    "split = int(len(X)*0.8)\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train: {X_train_s.shape}  |  Test: {X_test_s.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train three models\n",
    "models = {\n",
    "    'Ridge':    Ridge(alpha=1.0),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, max_depth=12, random_state=0, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.05, random_state=0)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_s, y_train)\n",
    "    preds = model.predict(X_test_s)\n",
    "    results[name] = {\n",
    "        'preds': preds,\n",
    "        'rmse': np.sqrt(mean_squared_error(y_test, preds)),\n",
    "        'mae':  mean_absolute_error(y_test, preds),\n",
    "        'r2':   r2_score(y_test, preds)\n",
    "    }\n",
    "    print(\n",
    "        f'{name:20s} | RMSE={results[name][\"rmse\"]:6.2f} | MAE={results[name][\"mae\"]:5.2f} | RÂ²={results[name][\"r2\"]:.3f}')\n",
    "\n",
    "best = max(results, key=lambda k: results[k]['r2'])\n",
    "print(f'\\nâœ… Best model: {best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Actual vs Predicted â€” best model\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.plot(y_test.index[:500], y_test.values[:500],\n",
    "        label='Actual', lw=1.2, color='steelblue')\n",
    "ax.plot(y_test.index[:500], results[best]['preds'][:500],\n",
    "        label=f'{best} Predicted', lw=1.2, color='crimson', alpha=0.7)\n",
    "ax.set_title(f'Energy Forecasting â€” {best} Model (first 500 test points)')\n",
    "ax.set_ylabel('Appliances Energy (Wh)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Residual analysis\n",
    "residuals = y_test.values - results[best]['preds']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(residuals, bins=60, color='steelblue',\n",
    "             edgecolor='white', density=True)\n",
    "axes[0].set_title('Residual Distribution')\n",
    "axes[0].set_xlabel('Residual')\n",
    "\n",
    "# QQ plot\n",
    "stats_mod = __import__('scipy').stats\n",
    "(osm, osr), (slope, intercept, r) = stats_mod.probplot(residuals, dist='norm')\n",
    "axes[1].plot(osm, osr, 'o', markersize=2, color='steelblue')\n",
    "axes[1].plot(osm, slope*np.array(osm)+intercept, 'r-', lw=1.5)\n",
    "axes[1].set_title('Q-Q Plot')\n",
    "axes[1].set_xlabel('Theoretical Quantiles')\n",
    "axes[1].set_ylabel('Sample Quantiles')\n",
    "\n",
    "# Residual vs Predicted\n",
    "axes[2].scatter(results[best]['preds'][:2000], residuals[:2000],\n",
    "                s=3, alpha=0.4, color='steelblue')\n",
    "axes[2].axhline(0, color='crimson', lw=1)\n",
    "axes[2].set_title('Residual vs Predicted')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model comparison bar chart\n",
    "metrics_df = pd.DataFrame({\n",
    "    name: {'RMSE': r['rmse'], 'MAE': r['mae'], 'RÂ²': r['r2']}\n",
    "    for name, r in results.items()\n",
    "}).T\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "colors = ['#4c72b0', '#55a868', '#c44e52']\n",
    "for ax, col, c in zip(axes, ['RMSE', 'MAE', 'RÂ²'], colors):\n",
    "    axes_bar = metrics_df[col].plot(\n",
    "        kind='bar', ax=ax, color=c, edgecolor='white')\n",
    "    ax.set_title(col)\n",
    "    ax.set_ylabel(col)\n",
    "    ax.tick_params(axis='x', rotation=25)\n",
    "    for i, v in enumerate(metrics_df[col]):\n",
    "        ax.text(i, v*1.02, f'{v:.3f}', ha='center', fontsize=9)\n",
    "plt.suptitle('Model Comparison', fontsize=13, y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Engineered temporal, lag, and rolling features from a 10-min energy dataset\n",
    "- Trained Ridge, Random Forest, and Gradient Boosting regressors\n",
    "- Gradient Boosting consistently delivered the best RMSE/RÂ² trade-off\n",
    "- Residual analysis confirmed homoscedastic, near-Gaussian errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
