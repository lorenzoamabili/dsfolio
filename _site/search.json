[
  {
    "objectID": "TROUBLESHOOTING.html",
    "href": "TROUBLESHOOTING.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "TROUBLESHOOTING.html#problem-can-not-read-a-block-mapping-entry-a-multiline-key-may-not-be-an-implicit-key",
    "href": "TROUBLESHOOTING.html#problem-can-not-read-a-block-mapping-entry-a-multiline-key-may-not-be-an-implicit-key",
    "title": "",
    "section": "Problem: “can not read a block mapping entry; a multiline key may not be an implicit key”",
    "text": "Problem: “can not read a block mapping entry; a multiline key may not be an implicit key”\nThis happens when Quarto mistakes regular markdown text for YAML frontmatter in your notebooks.\n\nThe Issue\nYour notebook has content that looks like this at the top:\n## 3. Transfer Entropy — Causal ...\nQuarto sees ## followed by a colon (:) and tries to parse it as YAML, which fails.\n\n\nSolutions\nOption 1: Add proper YAML frontmatter (Recommended)\nEdit your notebook and make sure the first cell is a markdown cell with valid YAML:\n\ntitle: \"Your Project Title\"\nauthor: \"Your Name\"\ndate: \"2026-01-31\"\nformat:\n  html:\n    code-fold: true\nThen your regular markdown content comes after.\nOption 2: Move your notebooks temporarily\n\nCreate a new folder: projects_backup/\nMove ALL your .ipynb files there\nRun quarto preview to verify the site works with just the example notebook\nAdd your notebooks back one at a time, fixing YAML issues as they appear\n\nOption 3: Check for problematic patterns\nLook for these patterns in your notebook’s markdown cells: - Lines starting with ## that contain a colon : - Multiple `` dividers (confuses YAML parser) - Indented content that looks like YAML\n\n\nTesting\nTo test if the portfolio works:\n# First, temporarily move your notebooks out\nmkdir projects_backup\nmv projects/*.ipynb projects_backup/\n\n# Now test with just the example\nquarto preview\n\n# If it works, add your notebooks back one at a time\n\n\nQuick Fix for Your Specific File\nFind the notebook with “Transfer Entropy” content and add this as the very first cell:\n\ntitle: \"Transfer Entropy Analysis\"\nThis tells Quarto where the YAML ends and markdown begins."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Data science projects spanning EDA, ML, optimization, and process control.\n\n\n\n\nAll (14)\n\n\nFoundational (7)\n\n\nAdvanced (7)\n\n\nEDA (2)\n\n\nMachine Learning (8)\n\n\nTime Series (2)"
  },
  {
    "objectID": "projects/07_ADV_Quality_Defect_Prediction.html",
    "href": "projects/07_ADV_Quality_Defect_Prediction.html",
    "title": "Advanced Quality Analytics",
    "section": "",
    "text": "Topic\nTechnique\n\n\n\n\nCausal inference\nPropensity-score matching + treatment-effect estimation\n\n\nSurvival analysis\nKaplan-Meier curves for time-to-defect\n\n\nAdvanced boosting\nHand-rolled histogram gradient boosting (XGBoost-style)\n\n\nShapley root-cause\nAdditive feature attribution for defect probability\n\n\nCapability forecasting\nPredicting future Cpk drift using time-series regression\n\n\nCost-benefit analysis\nExpected cost of defect vs inspection — optimal policy\n\n\n\n\n\n\nSimulated injection-moulding quality log (10 process vars, 5 quality dims, binary defect)\nStructure mirrors Kaggle Steel Defect / UCI Concrete datasets\n\n\n\nCode\n# ─── 1. Imports ─────────────────────────────────────────────\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import (roc_curve, auc, classification_report,\n                             confusion_matrix, precision_recall_curve)\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('✓ All imports loaded.')\n\n\n\n\nCode\n# ─── 2. Synthetic injection-moulding quality data ─────────\ndef gen_quality_data(n=8000, seed=2025):\n    rng = np.random.default_rng(seed)\n\n    # ─── Process inputs (10 variables) ───\n    mold_temp = rng.normal(220, 8, n)\n    inject_pres = rng.normal(150, 10, n)\n    hold_time = rng.normal(3.0, 0.3, n)\n    cool_time = rng.normal(12.0, 1.5, n)\n    screw_rpm = rng.normal(200, 15, n)\n    material_mfr = rng.normal(180, 5, n)   # material melt flow rate\n    humidity = rng.uniform(20, 70, n)\n    operator_id = rng.integers(0, 8, n)    # 8 operators\n    shift = rng.choice([0, 1, 2], n)   # 0=day, 1=eve, 2=night\n    machine_age = rng.uniform(0, 10, n)    # years\n\n    # ─── Quality measurements (5 dimensions) ───\n    wall_thick = 2.0 + 0.003*mold_temp - 0.002 * \\\n        inject_pres + rng.normal(0, 0.04, n)\n    surface_fin = 1.5 - 0.005*screw_rpm + 0.01 * \\\n        material_mfr + rng.normal(0, 0.08, n)\n    tensile = 45 + 0.2*material_mfr - 0.1*humidity + rng.normal(0, 2.0, n)\n    shrinkage = 0.8 + 0.002*mold_temp - 0.001 * \\\n        cool_time + rng.normal(0, 0.05, n)\n    flash_score = 0.1 + 0.003*inject_pres - \\\n        0.005*hold_time + rng.normal(0, 0.03, n)\n\n    # ─── Defect probability (logistic) ───\n    logit = (\n        -4.0\n        + 0.04 * (mold_temp - 220)\n        + 0.03 * (inject_pres - 150)\n        - 0.08 * hold_time\n        - 0.06 * cool_time\n        + 0.02 * humidity\n        + 0.15 * machine_age\n        + 0.3 * (shift == 2).astype(float)   # night shift effect\n        + 0.25 * np.abs(wall_thick - 2.0) * 20\n        + 0.2 * flash_score * 10\n    )\n    p_defect = 1 / (1 + np.exp(-logit))\n    defect = (rng.uniform(0, 1, n) &lt; p_defect).astype(int)\n\n    # Time to first defect (for survival analysis) — in minutes since start\n    # Each sample is ~2 min apart; defect time = cumulative sum of inter-arrival\n    inter_arrival = rng.exponential(40, n)\n    time_to_event = np.cumsum(inter_arrival)   # monotonically increasing\n\n    df = pd.DataFrame({\n        'Mold_Temp': mold_temp.round(1), 'Inject_Pres': inject_pres.round(1),\n        'Hold_Time': hold_time.round(2), 'Cool_Time': cool_time.round(2),\n        'Screw_RPM': screw_rpm.round(1), 'Material_MFR': material_mfr.round(1),\n        'Humidity': humidity.round(1), 'Operator_ID': operator_id,\n        'Shift': shift, 'Machine_Age': machine_age.round(2),\n        'Wall_Thickness': wall_thick.round(4), 'Surface_Finish': surface_fin.round(4),\n        'Tensile_Strength': tensile.round(2), 'Shrinkage': shrinkage.round(4),\n        'Flash_Score': flash_score.round(4),\n        'Defect': defect,\n        'Time_min': time_to_event.round(1)\n    })\n    return df\n\n\ndf = gen_quality_data()\nPROCESS_VARS = ['Mold_Temp', 'Inject_Pres', 'Hold_Time', 'Cool_Time', 'Screw_RPM',\n                'Material_MFR', 'Humidity', 'Operator_ID', 'Shift', 'Machine_Age']\nQUALITY_VARS = ['Wall_Thickness', 'Surface_Finish',\n                'Tensile_Strength', 'Shrinkage', 'Flash_Score']\nALL_FEATS = PROCESS_VARS + QUALITY_VARS\n\nprint(f'Shape: {df.shape}  |  Defect rate: {df[\"Defect\"].mean()*100:.1f}%')\ndf.describe().round(2)\n\n\n\n\nCode\n# 1. Survival Analysis — Kaplan-Meier Time-to-Defect\n\n# Kaplan-Meier estimates the **survival function** S(t) = P(no defect up to time t) without assuming any parametric distribution. We stratify by key risk factors.\n\n# ─── 3. Kaplan-Meier estimator (manual) ──────────────────\ndef kaplan_meier(times, events):\n    \"\"\"\n    Compute KM survival curve.\n    times:  array of event/censoring times\n    events: 1 = event (defect), 0 = censored\n    Returns (t_km, S_km) — sorted unique event times and survival probs.\n    \"\"\"\n    # Sort by time\n    order = np.argsort(times)\n    t_sort = times[order]\n    e_sort = events[order]\n\n    unique_times = np.unique(t_sort[e_sort == 1])  # event times only\n    n_at_risk = len(times)\n    S = 1.0\n    t_km, S_km = [0], [1.0]\n\n    ptr = 0   # pointer into sorted arrays\n    for t in unique_times:\n        # Count events and at-risk at time t\n        while ptr &lt; len(t_sort) and t_sort[ptr] &lt; t:\n            n_at_risk -= 1\n            ptr += 1\n        # Events at exactly t\n        d = 0\n        while ptr &lt; len(t_sort) and t_sort[ptr] == t:\n            d += e_sort[ptr]\n            n_at_risk -= 1\n            ptr += 1\n        n_at_risk += d   # they were at risk at time t\n\n        if n_at_risk &gt; 0:\n            S *= (1 - d / n_at_risk)\n        t_km.append(t)\n        S_km.append(S)\n        n_at_risk -= d\n\n    return np.array(t_km), np.array(S_km)\n\n\n# For survival analysis: treat each defect as an event.\n# Use cumulative time within each \"batch\" (reset every 200 samples for realism)\nBATCH = 200\nsurvival_rows = []\nfor batch_start in range(0, len(df), BATCH):\n    batch = df.iloc[batch_start:batch_start+BATCH]\n    cum_time = 0\n    for _, row in batch.iterrows():\n        cum_time += np.random.exponential(2.0)  # ~2 min between parts\n        survival_rows.append({\n            'Time': cum_time,\n            'Event': row['Defect'],\n            'Shift': row['Shift'],\n            'Machine_Age_Cat': 'Young' if row['Machine_Age'] &lt; 5 else 'Old'\n        })\n\nsurv_df = pd.DataFrame(survival_rows)\nprint(\n    f'Survival data: {len(surv_df)} observations, {surv_df[\"Event\"].sum()} defect events')\n\n\n\n\nCode\n# ─── 4. KM curves stratified by shift and machine age ──\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# By shift\nshift_names = {0: 'Day', 1: 'Evening', 2: 'Night'}\ncolors_shift = {0: '#4c72b0', 1: '#55a868', 2: '#c44e52'}\nfor shift_id in [0, 1, 2]:\n    mask = surv_df['Shift'] == shift_id\n    t_km, S_km = kaplan_meier(surv_df.loc[mask, 'Time'].values,\n                              surv_df.loc[mask, 'Event'].values)\n    axes[0].step(t_km, S_km, where='post', lw=2, color=colors_shift[shift_id],\n                 label=f'{shift_names[shift_id]} (n={mask.sum()})')\n\naxes[0].set_title('Kaplan-Meier by Shift', fontsize=13)\naxes[0].set_xlabel('Time (min)')\naxes[0].set_ylabel('Survival Probability S(t)')\naxes[0].legend()\naxes[0].set_ylim(0, 1.05)\n\n# By machine age\nfor age_cat, color in [('Young', '#4c72b0'), ('Old', '#c44e52')]:\n    mask = surv_df['Machine_Age_Cat'] == age_cat\n    t_km, S_km = kaplan_meier(surv_df.loc[mask, 'Time'].values,\n                              surv_df.loc[mask, 'Event'].values)\n    axes[1].step(t_km, S_km, where='post', lw=2, color=color,\n                 label=f'{age_cat} machine (n={mask.sum()})')\n\naxes[1].set_title('Kaplan-Meier by Machine Age', fontsize=13)\naxes[1].set_xlabel('Time (min)')\naxes[1].set_ylabel('Survival Probability S(t)')\naxes[1].legend()\naxes[1].set_ylim(0, 1.05)\n\nplt.suptitle('Survival Analysis — Time to Defect', fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 2. Causal Inference — Propensity-Score Matching\n\n# We want to estimate the **causal effect** of night-shift operation on defect rate, controlling for confounders. Propensity-score matching pairs night-shift units with similar day-shift units.\n\n# ─── 5. Propensity-score matching ───────────────────────────\n# Treatment: Shift == 2 (night) vs Shift != 2 (control)\ndf['is_night'] = (df['Shift'] == 2).astype(int)\n\n# Confounders: all process + quality vars except Shift\nCONFOUNDERS = [v for v in ALL_FEATS if v != 'Shift']\nscaler_ps = StandardScaler()\nX_conf = scaler_ps.fit_transform(df[CONFOUNDERS])\n\n# Logistic regression for propensity scores\nps_model = LogisticRegression(max_iter=1000, C=1.0, random_state=0)\nps_model.fit(X_conf, df['is_night'])\npropensity = ps_model.predict_proba(X_conf)[:, 1]\n\ndf['propensity'] = propensity\n\nprint(\n    f'Propensity score range: [{propensity.min():.3f}, {propensity.max():.3f}]')\nprint(\n    f'Night-shift samples: {df[\"is_night\"].sum()}  |  Control: {(1-df[\"is_night\"]).sum()}')\n\n# Matching: for each treated unit, find the closest control unit (greedy)\ntreated_idx = df.index[df['is_night'] == 1].tolist()\ncontrol_idx = df.index[df['is_night'] == 0].tolist()\ncontrol_ps = propensity[control_idx]\n\nmatched_pairs = []\nused_controls = set()\n\n# Sort treated by propensity for efficiency\ntreated_sorted = sorted(treated_idx, key=lambda i: propensity[i])\n\nfor t_idx in treated_sorted:\n    t_ps = propensity[t_idx]\n    # Find closest unused control\n    best_c, best_diff = None, np.inf\n    for c_pos, c_idx in enumerate(control_idx):\n        if c_idx in used_controls:\n            continue\n        diff = abs(propensity[c_idx] - t_ps)\n        if diff &lt; best_diff:\n            best_diff = diff\n            best_c = c_idx\n            best_c_pos = c_pos\n        if diff == 0:\n            break   # perfect match\n\n    if best_c is not None and best_diff &lt; 0.05:  # caliper = 0.05\n        matched_pairs.append((t_idx, best_c))\n        used_controls.add(best_c)\n\nprint(f'Matched pairs (caliper=0.05): {len(matched_pairs)}')\n\n# Estimate ATT (Average Treatment Effect on Treated)\ndefect_treated = np.mean([df.loc[t, 'Defect'] for t, c in matched_pairs])\ndefect_control = np.mean([df.loc[c, 'Defect'] for t, c in matched_pairs])\nATT = defect_treated - defect_control\n\nprint(f'\\nCausal Effect of Night Shift on Defect Rate:')\nprint(f'  Matched treated defect rate:  {defect_treated*100:.2f}%')\nprint(f'  Matched control defect rate:  {defect_control*100:.2f}%')\nprint(f'  ATT (causal effect):          {ATT*100:+.2f} percentage points')\n\n\n\n\nCode\n# ─── 6. Propensity + causal effect visualisation ──────────\nfig, axes = plt.subplots(1, 3, figsize=(17, 5))\n\n# Propensity distribution before matching\naxes[0].hist(propensity[df['is_night'] == 1], bins=40, alpha=0.6, color='#c44e52',\n             density=True, label='Night shift')\naxes[0].hist(propensity[df['is_night'] == 0], bins=40, alpha=0.6, color='#4c72b0',\n             density=True, label='Control')\naxes[0].set_title('Propensity Score Distribution (Before Matching)')\naxes[0].set_xlabel('Propensity Score')\naxes[0].legend()\n\n# After matching\nmatched_t_ps = [propensity[t] for t, c in matched_pairs]\nmatched_c_ps = [propensity[c] for t, c in matched_pairs]\naxes[1].hist(matched_t_ps, bins=30, alpha=0.6, color='#c44e52',\n             density=True, label='Night (matched)')\naxes[1].hist(matched_c_ps, bins=30, alpha=0.6, color='#4c72b0',\n             density=True, label='Control (matched)')\naxes[1].set_title('Propensity Score Distribution (After Matching)')\naxes[1].set_xlabel('Propensity Score')\naxes[1].legend()\n\n# Treatment effect bar chart\naxes[2].bar(['Control\\n(matched)', 'Night Shift\\n(matched)', 'Causal Effect\\n(ATT)'],\n            [defect_control*100, defect_treated*100, ATT*100],\n            color=['#4c72b0', '#c44e52', '#8172b2'], edgecolor='white', width=0.5)\naxes[2].axhline(0, color='black', lw=0.5)\naxes[2].set_title('Causal Effect of Night Shift')\naxes[2].set_ylabel('Defect Rate (%)')\nfor i, v in enumerate([defect_control*100, defect_treated*100, ATT*100]):\n    axes[2].text(i, v + 0.3, f'{v:+.1f}%',\n                 ha='center', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 3. Hand-Rolled Histogram Gradient Boosting (XGBoost-Style)\n\n# ─── 7. Histogram Gradient Boosting (simplified XGBoost) ──\nclass HistGBTree:\n    \"\"\"Single decision stump using histogram-based splitting.\"\"\"\n\n    def __init__(self, n_bins=32):\n        self.n_bins = n_bins\n        self.split_feat = None\n        self.split_thresh = None\n        self.left_val = 0\n        self.right_val = 0\n\n    def fit(self, X, grad, hess, bin_edges):\n        \"\"\"Find the best split to minimise the second-order objective.\"\"\"\n        best_gain = -np.inf\n        n_feat = X.shape[1]\n\n        for feat in range(n_feat):\n            edges = bin_edges[feat]\n            for b in range(1, len(edges)-1):\n                thresh = edges[b]\n                left_mask = X[:, feat] &lt;= thresh\n                right_mask = ~left_mask\n                if left_mask.sum() &lt; 5 or right_mask.sum() &lt; 5:\n                    continue\n\n                G_L = grad[left_mask].sum()\n                H_L = hess[left_mask].sum()\n                G_R = grad[right_mask].sum()\n                H_R = hess[right_mask].sum()\n\n                # Gain = 0.5 * (G_L²/H_L + G_R²/H_R - (G_L+G_R)²/(H_L+H_R))\n                gain = 0.5 * (G_L**2/(H_L+1e-6) + G_R**2/(H_R+1e-6)\n                              - (G_L+G_R)**2/(H_L+H_R+1e-6))\n\n                if gain &gt; best_gain:\n                    best_gain = gain\n                    self.split_feat = feat\n                    self.split_thresh = thresh\n                    self.left_val = -G_L / (H_L + 1e-6)\n                    self.right_val = -G_R / (H_R + 1e-6)\n\n    def predict(self, X):\n        mask = X[:, self.split_feat] &lt;= self.split_thresh\n        preds = np.where(mask, self.left_val, self.right_val)\n        return preds\n\n\nclass HandRolledGBM:\n    \"\"\"Binary classification via histogram gradient boosting.\"\"\"\n\n    def __init__(self, n_trees=200, learning_rate=0.1, n_bins=16):\n        self.n_trees = n_trees\n        self.lr = learning_rate\n        self.n_bins = n_bins\n        self.trees = []\n        self.bin_edges = None\n\n    def _sigmoid(self, x):\n        return 1 / (1 + np.exp(-np.clip(x, -30, 30)))\n\n    def fit(self, X, y):\n        # Precompute bin edges per feature\n        self.bin_edges = []\n        for feat in range(X.shape[1]):\n            edges = np.quantile(X[:, feat], np.linspace(0, 1, self.n_bins+1))\n            self.bin_edges.append(edges)\n\n        F = np.zeros(len(y))   # cumulative prediction (log-odds)\n        for t in range(self.n_trees):\n            p = self._sigmoid(F)\n            grad = p - y              # gradient of log-loss\n            hess = p * (1 - p)        # hessian\n\n            tree = HistGBTree(self.n_bins)\n            tree.fit(X, grad, hess, self.bin_edges)\n            self.trees.append(tree)\n            F += self.lr * tree.predict(X)\n        return self\n\n    def predict_proba(self, X):\n        F = np.zeros(len(X))\n        for tree in self.trees:\n            F += self.lr * tree.predict(X)\n        return self._sigmoid(F)\n\n    def predict(self, X):\n        return (self.predict_proba(X) &gt;= 0.5).astype(int)\n\n\n# Train\nX_feat = df[ALL_FEATS].values\ny_feat = df['Defect'].values\nscaler_gb = StandardScaler()\nX_s = scaler_gb.fit_transform(X_feat)\n\nX_train, X_test, y_train, y_test = train_test_split(X_s, y_feat, test_size=0.25,\n                                                    stratify=y_feat, random_state=42)\n\nprint('Training Hand-Rolled GBM (200 trees) …')\nhgbm = HandRolledGBM(n_trees=200, learning_rate=0.08, n_bins=16)\nhgbm.fit(X_train, y_train)\n\n# Evaluate\nhgbm_proba = hgbm.predict_proba(X_test)\nhgbm_pred = hgbm.predict(X_test)\nfpr, tpr, _ = roc_curve(y_test, hgbm_proba)\nauc_val = auc(fpr, tpr)\nprint(f'Hand-Rolled GBM AUC: {auc_val:.3f}')\nprint(classification_report(y_test, hgbm_pred, target_names=['OK', 'Defect']))\n\n\n\n\nCode\n# ─── 8. Compare with sklearn GBR ──────────────────────────\nsk_gbr = GradientBoostingClassifier(n_estimators=200, max_depth=2,\n                                    learning_rate=0.08, random_state=0)\nsk_gbr.fit(X_train, y_train)\nsk_proba = sk_gbr.predict_proba(X_test)[:, 1]\nfpr_sk, tpr_sk, _ = roc_curve(y_test, sk_proba)\nauc_sk = auc(fpr_sk, tpr_sk)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(fpr, tpr, lw=2, color='steelblue',\n        label=f'Hand-Rolled GBM (AUC={auc_val:.3f})')\nax.plot(fpr_sk, tpr_sk, lw=2, color='#c44e52',\n        label=f'Sklearn GBR (AUC={auc_sk:.3f})')\nax.plot([0, 1], [0, 1], 'k--', lw=0.8)\nax.set_xlabel('FPR')\nax.set_ylabel('TPR')\nax.set_title('ROC Comparison — Hand-Rolled vs Sklearn GBM')\nax.legend(loc='lower right')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Shapley Root-Cause Attribution\n\n# ─── 9. Shapley values via marginal contribution sampling ─\ndef shapley_values(model_fn, X_sample, X_background, n_perms=100, seed=0):\n    \"\"\"\n    Estimate Shapley values for one sample using sampling-based approach.\n    model_fn: callable X → probability\n    X_sample: single sample (1, d)\n    X_background: background dataset for marginalisation\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    d = X_sample.shape[1]\n    shap = np.zeros(d)\n    base = model_fn(X_background).mean()   # expected value under background\n\n    for _ in range(n_perms):\n        # Random permutation of features\n        perm = rng.permutation(d)\n        # Random background sample\n        bg = X_background[rng.integers(0, len(X_background))]\n        x_bg = bg.copy()\n        x_fg = bg.copy()\n\n        for feat in perm:\n            # Before including feat: x_bg has background for feat\n            pred_before = model_fn(x_bg.reshape(1, -1))[0]\n            # Include feat from sample\n            x_bg[feat] = X_sample[0, feat]\n            pred_after = model_fn(x_bg.reshape(1, -1))[0]\n            # Marginal contribution\n            shap[feat] += (pred_after - pred_before)\n\n    shap /= n_perms\n    return shap\n\n\n# Compute Shapley for top-10 defective samples\ndefect_idx = np.where(y_test == 1)[0][:10]\nall_shap = []\n\nprint('Computing Shapley values for 10 defective samples …')\nfor i, idx in enumerate(defect_idx):\n    sv = shapley_values(\n        lambda X: sk_gbr.predict_proba(X)[:, 1],\n        X_test[idx:idx+1],\n        X_train[:500],   # subsample background for speed\n        n_perms=80, seed=i\n    )\n    all_shap.append(sv)\n    print(f'  Sample {i+1}/10 done.')\n\nshap_matrix = np.array(all_shap)   # (10, n_features)\nprint('\\nShapley matrix shape:', shap_matrix.shape)\n\n\n\n\nCode\n# ─── 10. Shapley beeswarm + waterfall plot ────────────────\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Beeswarm: mean |SHAP| across defective samples\nmean_abs_shap = np.abs(shap_matrix).mean(axis=0)\nranked = np.argsort(mean_abs_shap)\n\ntop_n = min(12, len(ALL_FEATS))\ntop_idx = ranked[-top_n:]\n\n# Beeswarm-style dot plot\nfor plot_pos, feat_idx in enumerate(top_idx):\n    vals = shap_matrix[:, feat_idx]\n    # Jitter y for visibility\n    jitter = np.random.default_rng(plot_pos).uniform(-0.15, 0.15, len(vals))\n    colors = ['#c44e52' if v &gt; 0 else '#4c72b0' for v in vals]\n    axes[0].scatter(vals, np.full(len(vals), plot_pos) + jitter,\n                    c=colors, s=40, edgecolors='white', zorder=3)\n\naxes[0].set_yticks(range(top_n))\naxes[0].set_yticklabels([ALL_FEATS[i] for i in top_idx], fontsize=9)\naxes[0].axvline(0, color='black', lw=0.8)\naxes[0].set_xlabel('SHAP Value')\naxes[0].set_title('Shapley Beeswarm — Top Features (red=↑defect risk)')\n\n# Waterfall for the single highest-risk defective sample\nworst_idx = np.argmax(sk_gbr.predict_proba(X_test[defect_idx])[:, 1])\nworst_shap = shap_matrix[worst_idx]\norder = np.argsort(np.abs(worst_shap))[::-1][:10]\ncumulative = np.zeros(len(order)+1)\nbase_val = sk_gbr.predict_proba(X_train[:500]).mean()   # E[f(x)]\ncumulative[0] = base_val\nfor i, feat_idx in enumerate(order):\n    cumulative[i+1] = cumulative[i] + worst_shap[feat_idx]\n\nlabels_wf = ['Base'] + [ALL_FEATS[i] for i in order]\ncolors_wf = ['grey'] + ['#c44e52' if worst_shap[i]\n                        &gt; 0 else '#4c72b0' for i in order]\n\naxes[1].bar(range(len(labels_wf)), cumulative,\n            color=colors_wf, edgecolor='white', width=0.6)\naxes[1].axhline(cumulative[-1], color='black', ls='--', lw=0.8, alpha=0.5)\naxes[1].set_xticks(range(len(labels_wf)))\naxes[1].set_xticklabels(labels_wf, rotation=30, ha='right', fontsize=8)\naxes[1].set_ylabel('Defect Probability')\naxes[1].set_title(f'Waterfall — Highest-Risk Sample (P={cumulative[-1]:.3f})')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 5. Capability Forecasting — Predicting Future Cpk\n\n# ─── 11. Rolling Cpk + forecasting ────────────────────────\n# Compute rolling Cpk for Wall_Thickness\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import GradientBoostingRegressor as GBReg\nUSL_wt = 2.08   # upper spec limit\nLSL_wt = 1.92   # lower spec limit\n\nWIN_CPK = 200\ncpk_series = []\nfor i in range(WIN_CPK, len(df), 50):\n    chunk = df['Wall_Thickness'].iloc[i-WIN_CPK:i]\n    mu = chunk.mean()\n    sig = chunk.std()\n    cpu = (USL_wt - mu) / (3*sig) if sig &gt; 0 else 99\n    cpl = (mu - LSL_wt) / (3*sig) if sig &gt; 0 else 99\n    cpk_series.append({'idx': i, 'Cpk': min(cpu, cpl), 'mu': mu, 'std': sig})\n\ncpk_df = pd.DataFrame(cpk_series)\nprint(f'Cpk time series: {len(cpk_df)} points')\nprint(f'  Mean Cpk: {cpk_df[\"Cpk\"].mean():.3f}')\nprint(f'  Min Cpk:  {cpk_df[\"Cpk\"].min():.3f}')\n\n# Forecast Cpk using GBR on lagged Cpk values\nLAG_CPK = 5\ncpk_vals = cpk_df['Cpk'].values\nX_cpk = np.column_stack([cpk_vals[i:len(cpk_vals)-LAG_CPK+i]\n                        for i in range(LAG_CPK)])\ny_cpk = cpk_vals[LAG_CPK:]\n\nsplit_cpk = int(0.8 * len(X_cpk))\ncpk_model = GBReg(n_estimators=100, max_depth=3, random_state=0)\ncpk_model.fit(X_cpk[:split_cpk], y_cpk[:split_cpk])\ncpk_pred = cpk_model.predict(X_cpk[split_cpk:])\n\ncpk_rmse = np.sqrt(mean_squared_error(y_cpk[split_cpk:], cpk_pred))\nprint(f'  Cpk Forecast RMSE: {cpk_rmse:.4f}')\n\n\n\n\nCode\n# ─── 12. Cpk forecast plot ─────────────────────────────────\nfig, ax = plt.subplots(figsize=(14, 5))\n\n# Full Cpk series\nax.plot(cpk_df['idx'], cpk_df['Cpk'], lw=1.2,\n        color='steelblue', label='Actual Cpk')\n\n# Forecast region\ntest_indices = cpk_df['idx'].values[LAG_CPK + split_cpk:]\nax.plot(test_indices, cpk_pred, lw=1.5, color='crimson',\n        ls='--', label='Forecasted Cpk')\n\n# Reference lines\nax.axhline(1.33, color='green', ls=':', lw=1, label='Target (1.33)')\nax.axhline(1.00, color='orange', ls=':', lw=1, label='Minimum (1.00)')\n\n# Shade forecast region\nax.axvspan(test_indices[0], test_indices[-1], alpha=0.08,\n           color='crimson', label='Forecast window')\n\nax.set_title('Process Capability (Cpk) — Actual vs Forecasted', fontsize=13)\nax.set_xlabel('Sample Index')\nax.set_ylabel('Cpk')\nax.legend(loc='lower left')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 6. Cost-Benefit Analysis — Optimal Inspection Policy\n\n# ─── 13. Expected cost model ──────────────────────────────\n# Cost parameters (arbitrary but realistic units)\nCOST_DEFECT = 500   # cost of a defect reaching customer ($)\nCOST_INSPECTION = 25    # cost of inspecting one part ($)\nCOST_SCRAP = 80    # cost of scrapping a detected defect ($)\n\n# For each test sample, compute expected cost under two policies:\n# Policy A: Ship without inspection\n# Policy B: Inspect (if defect found → scrap; if not → ship)\n\nproba_defect = sk_gbr.predict_proba(X_test)[:, 1]\n\n# expected cost if shipped\ncost_no_inspect = proba_defect * COST_DEFECT\ncost_inspect = COST_INSPECTION + proba_defect * \\\n    COST_SCRAP             # expected cost if inspected\n\n# Optimal policy: inspect if cost_inspect &lt; cost_no_inspect\n# → inspect when p &gt; COST_INSPECTION / (COST_DEFECT - COST_SCRAP)\nthreshold_optimal = COST_INSPECTION / (COST_DEFECT - COST_SCRAP)\nprint(f'Optimal inspection threshold: p &gt; {threshold_optimal:.4f}')\nprint(\n    f'  (i.e., inspect when predicted defect prob &gt; {threshold_optimal*100:.2f}%)')\n\noptimal_policy = (proba_defect &gt; threshold_optimal).astype(int)\nactual_cost = np.where(optimal_policy == 1,\n                       COST_INSPECTION + y_test * COST_SCRAP,\n                       y_test * COST_DEFECT)\nnaive_cost = y_test * COST_DEFECT   # ship everything\n\ntotal_optimal = actual_cost.sum()\ntotal_naive = naive_cost.sum()\nsavings = total_naive - total_optimal\nprint(f'\\n  Total cost (ship all):      ${total_naive:,.0f}')\nprint(f'  Total cost (optimal policy): ${total_optimal:,.0f}')\nprint(\n    f'  Savings:                     ${savings:,.0f} ({savings/total_naive*100:.1f}%)')\nprint(\n    f'  Parts inspected:            {optimal_policy.sum()} / {len(optimal_policy)} ({optimal_policy.mean()*100:.1f}%)')\n\n\n\n\nCode\n# ─── 14. Cost analysis visualisation ──────────────────────\nfig, axes = plt.subplots(1, 3, figsize=(17, 5))\n\n# Cost distribution comparison\nthresholds = np.linspace(0, 0.5, 100)\ntotal_costs = []\nfor t in thresholds:\n    policy = (proba_defect &gt; t).astype(int)\n    cost = np.where(policy == 1,\n                    COST_INSPECTION + y_test * COST_SCRAP,\n                    y_test * COST_DEFECT).sum()\n    total_costs.append(cost)\n\naxes[0].plot(thresholds, total_costs, lw=2, color='steelblue')\naxes[0].axvline(threshold_optimal, color='crimson', ls='--', lw=1.5,\n                label=f'Optimal threshold={threshold_optimal:.3f}')\naxes[0].set_title('Total Cost vs Inspection Threshold')\naxes[0].set_xlabel('Defect Probability Threshold')\naxes[0].set_ylabel('Total Expected Cost ($)')\naxes[0].legend()\n\n# Breakdown: inspected vs shipped\ncategories = ['Ship All\\n(naive)', 'Optimal\\nPolicy']\ndefects_escaped = [y_test.sum(), ((1-optimal_policy) * y_test).sum()]\ndefects_caught = [0, (optimal_policy * y_test).sum()]\nno_defect = [len(y_test)-y_test.sum(), len(y_test)-y_test.sum()]\n\nx_pos = [0, 1]\naxes[1].bar(x_pos, defects_escaped, color='#c44e52', label='Defects escaped')\naxes[1].bar(x_pos, defects_caught, bottom=defects_escaped,\n            color='#55a868', label='Defects caught')\naxes[1].set_xticks(x_pos)\naxes[1].set_xticklabels(categories)\naxes[1].set_title('Defect Disposition by Policy')\naxes[1].set_ylabel('Count')\naxes[1].legend()\n\n# Cost per part distribution\ncost_per_part_naive = y_test * COST_DEFECT\ncost_per_part_optimal = np.where(optimal_policy == 1,\n                                 COST_INSPECTION + y_test * COST_SCRAP,\n                                 y_test * COST_DEFECT)\naxes[2].hist(cost_per_part_naive[cost_per_part_naive &gt; 0], bins=20, alpha=0.5,\n             color='#c44e52', label='Naive', density=True)\naxes[2].hist(cost_per_part_optimal[cost_per_part_optimal &gt; 0], bins=20, alpha=0.5,\n             color='#4c72b0', label='Optimal', density=True)\naxes[2].set_title('Per-Part Cost Distribution (non-zero only)')\naxes[2].set_xlabel('Cost ($)')\naxes[2].legend()\n\nplt.suptitle('Cost-Benefit Analysis — Optimal Inspection Policy',\n             fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechnique\nValue\n\n\n\n\nKaplan-Meier\nNonparametric survival curves reveal that night shift and old machines degrade faster\n\n\nPropensity-Score Matching\nIsolates the causal effect of night shift on defect rate — not just correlation\n\n\nHand-Rolled GBM\nDemonstrates deep understanding of boosting internals — histogram splits, second-order gradients\n\n\nShapley Attribution\nBeeswarm + waterfall plots provide actionable root-cause explanations per defective part\n\n\nCpk Forecasting\nPredicts future capability drift — enables proactive maintenance before quality degrades\n\n\nCost-Benefit Policy\nTranslates model output into an optimal business decision — the final step from ML to value\n\n\n\nThis notebook completes the full quality analytics pipeline: monitor → diagnose → explain → decide → forecast."
  },
  {
    "objectID": "projects/07_ADV_Quality_Defect_Prediction.html#portfolio-project-7-causal-inference-survival-analysis-xgboost-style-boosting-shapley-root-cause-and-statistical-process-capability-forecasting",
    "href": "projects/07_ADV_Quality_Defect_Prediction.html#portfolio-project-7-causal-inference-survival-analysis-xgboost-style-boosting-shapley-root-cause-and-statistical-process-capability-forecasting",
    "title": "Advanced Quality Analytics",
    "section": "",
    "text": "Topic\nTechnique\n\n\n\n\nCausal inference\nPropensity-score matching + treatment-effect estimation\n\n\nSurvival analysis\nKaplan-Meier curves for time-to-defect\n\n\nAdvanced boosting\nHand-rolled histogram gradient boosting (XGBoost-style)\n\n\nShapley root-cause\nAdditive feature attribution for defect probability\n\n\nCapability forecasting\nPredicting future Cpk drift using time-series regression\n\n\nCost-benefit analysis\nExpected cost of defect vs inspection — optimal policy\n\n\n\n\n\n\nSimulated injection-moulding quality log (10 process vars, 5 quality dims, binary defect)\nStructure mirrors Kaggle Steel Defect / UCI Concrete datasets\n\n\n\nCode\n# ─── 1. Imports ─────────────────────────────────────────────\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import (roc_curve, auc, classification_report,\n                             confusion_matrix, precision_recall_curve)\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('✓ All imports loaded.')\n\n\n\n\nCode\n# ─── 2. Synthetic injection-moulding quality data ─────────\ndef gen_quality_data(n=8000, seed=2025):\n    rng = np.random.default_rng(seed)\n\n    # ─── Process inputs (10 variables) ───\n    mold_temp = rng.normal(220, 8, n)\n    inject_pres = rng.normal(150, 10, n)\n    hold_time = rng.normal(3.0, 0.3, n)\n    cool_time = rng.normal(12.0, 1.5, n)\n    screw_rpm = rng.normal(200, 15, n)\n    material_mfr = rng.normal(180, 5, n)   # material melt flow rate\n    humidity = rng.uniform(20, 70, n)\n    operator_id = rng.integers(0, 8, n)    # 8 operators\n    shift = rng.choice([0, 1, 2], n)   # 0=day, 1=eve, 2=night\n    machine_age = rng.uniform(0, 10, n)    # years\n\n    # ─── Quality measurements (5 dimensions) ───\n    wall_thick = 2.0 + 0.003*mold_temp - 0.002 * \\\n        inject_pres + rng.normal(0, 0.04, n)\n    surface_fin = 1.5 - 0.005*screw_rpm + 0.01 * \\\n        material_mfr + rng.normal(0, 0.08, n)\n    tensile = 45 + 0.2*material_mfr - 0.1*humidity + rng.normal(0, 2.0, n)\n    shrinkage = 0.8 + 0.002*mold_temp - 0.001 * \\\n        cool_time + rng.normal(0, 0.05, n)\n    flash_score = 0.1 + 0.003*inject_pres - \\\n        0.005*hold_time + rng.normal(0, 0.03, n)\n\n    # ─── Defect probability (logistic) ───\n    logit = (\n        -4.0\n        + 0.04 * (mold_temp - 220)\n        + 0.03 * (inject_pres - 150)\n        - 0.08 * hold_time\n        - 0.06 * cool_time\n        + 0.02 * humidity\n        + 0.15 * machine_age\n        + 0.3 * (shift == 2).astype(float)   # night shift effect\n        + 0.25 * np.abs(wall_thick - 2.0) * 20\n        + 0.2 * flash_score * 10\n    )\n    p_defect = 1 / (1 + np.exp(-logit))\n    defect = (rng.uniform(0, 1, n) &lt; p_defect).astype(int)\n\n    # Time to first defect (for survival analysis) — in minutes since start\n    # Each sample is ~2 min apart; defect time = cumulative sum of inter-arrival\n    inter_arrival = rng.exponential(40, n)\n    time_to_event = np.cumsum(inter_arrival)   # monotonically increasing\n\n    df = pd.DataFrame({\n        'Mold_Temp': mold_temp.round(1), 'Inject_Pres': inject_pres.round(1),\n        'Hold_Time': hold_time.round(2), 'Cool_Time': cool_time.round(2),\n        'Screw_RPM': screw_rpm.round(1), 'Material_MFR': material_mfr.round(1),\n        'Humidity': humidity.round(1), 'Operator_ID': operator_id,\n        'Shift': shift, 'Machine_Age': machine_age.round(2),\n        'Wall_Thickness': wall_thick.round(4), 'Surface_Finish': surface_fin.round(4),\n        'Tensile_Strength': tensile.round(2), 'Shrinkage': shrinkage.round(4),\n        'Flash_Score': flash_score.round(4),\n        'Defect': defect,\n        'Time_min': time_to_event.round(1)\n    })\n    return df\n\n\ndf = gen_quality_data()\nPROCESS_VARS = ['Mold_Temp', 'Inject_Pres', 'Hold_Time', 'Cool_Time', 'Screw_RPM',\n                'Material_MFR', 'Humidity', 'Operator_ID', 'Shift', 'Machine_Age']\nQUALITY_VARS = ['Wall_Thickness', 'Surface_Finish',\n                'Tensile_Strength', 'Shrinkage', 'Flash_Score']\nALL_FEATS = PROCESS_VARS + QUALITY_VARS\n\nprint(f'Shape: {df.shape}  |  Defect rate: {df[\"Defect\"].mean()*100:.1f}%')\ndf.describe().round(2)\n\n\n\n\nCode\n# 1. Survival Analysis — Kaplan-Meier Time-to-Defect\n\n# Kaplan-Meier estimates the **survival function** S(t) = P(no defect up to time t) without assuming any parametric distribution. We stratify by key risk factors.\n\n# ─── 3. Kaplan-Meier estimator (manual) ──────────────────\ndef kaplan_meier(times, events):\n    \"\"\"\n    Compute KM survival curve.\n    times:  array of event/censoring times\n    events: 1 = event (defect), 0 = censored\n    Returns (t_km, S_km) — sorted unique event times and survival probs.\n    \"\"\"\n    # Sort by time\n    order = np.argsort(times)\n    t_sort = times[order]\n    e_sort = events[order]\n\n    unique_times = np.unique(t_sort[e_sort == 1])  # event times only\n    n_at_risk = len(times)\n    S = 1.0\n    t_km, S_km = [0], [1.0]\n\n    ptr = 0   # pointer into sorted arrays\n    for t in unique_times:\n        # Count events and at-risk at time t\n        while ptr &lt; len(t_sort) and t_sort[ptr] &lt; t:\n            n_at_risk -= 1\n            ptr += 1\n        # Events at exactly t\n        d = 0\n        while ptr &lt; len(t_sort) and t_sort[ptr] == t:\n            d += e_sort[ptr]\n            n_at_risk -= 1\n            ptr += 1\n        n_at_risk += d   # they were at risk at time t\n\n        if n_at_risk &gt; 0:\n            S *= (1 - d / n_at_risk)\n        t_km.append(t)\n        S_km.append(S)\n        n_at_risk -= d\n\n    return np.array(t_km), np.array(S_km)\n\n\n# For survival analysis: treat each defect as an event.\n# Use cumulative time within each \"batch\" (reset every 200 samples for realism)\nBATCH = 200\nsurvival_rows = []\nfor batch_start in range(0, len(df), BATCH):\n    batch = df.iloc[batch_start:batch_start+BATCH]\n    cum_time = 0\n    for _, row in batch.iterrows():\n        cum_time += np.random.exponential(2.0)  # ~2 min between parts\n        survival_rows.append({\n            'Time': cum_time,\n            'Event': row['Defect'],\n            'Shift': row['Shift'],\n            'Machine_Age_Cat': 'Young' if row['Machine_Age'] &lt; 5 else 'Old'\n        })\n\nsurv_df = pd.DataFrame(survival_rows)\nprint(\n    f'Survival data: {len(surv_df)} observations, {surv_df[\"Event\"].sum()} defect events')\n\n\n\n\nCode\n# ─── 4. KM curves stratified by shift and machine age ──\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# By shift\nshift_names = {0: 'Day', 1: 'Evening', 2: 'Night'}\ncolors_shift = {0: '#4c72b0', 1: '#55a868', 2: '#c44e52'}\nfor shift_id in [0, 1, 2]:\n    mask = surv_df['Shift'] == shift_id\n    t_km, S_km = kaplan_meier(surv_df.loc[mask, 'Time'].values,\n                              surv_df.loc[mask, 'Event'].values)\n    axes[0].step(t_km, S_km, where='post', lw=2, color=colors_shift[shift_id],\n                 label=f'{shift_names[shift_id]} (n={mask.sum()})')\n\naxes[0].set_title('Kaplan-Meier by Shift', fontsize=13)\naxes[0].set_xlabel('Time (min)')\naxes[0].set_ylabel('Survival Probability S(t)')\naxes[0].legend()\naxes[0].set_ylim(0, 1.05)\n\n# By machine age\nfor age_cat, color in [('Young', '#4c72b0'), ('Old', '#c44e52')]:\n    mask = surv_df['Machine_Age_Cat'] == age_cat\n    t_km, S_km = kaplan_meier(surv_df.loc[mask, 'Time'].values,\n                              surv_df.loc[mask, 'Event'].values)\n    axes[1].step(t_km, S_km, where='post', lw=2, color=color,\n                 label=f'{age_cat} machine (n={mask.sum()})')\n\naxes[1].set_title('Kaplan-Meier by Machine Age', fontsize=13)\naxes[1].set_xlabel('Time (min)')\naxes[1].set_ylabel('Survival Probability S(t)')\naxes[1].legend()\naxes[1].set_ylim(0, 1.05)\n\nplt.suptitle('Survival Analysis — Time to Defect', fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 2. Causal Inference — Propensity-Score Matching\n\n# We want to estimate the **causal effect** of night-shift operation on defect rate, controlling for confounders. Propensity-score matching pairs night-shift units with similar day-shift units.\n\n# ─── 5. Propensity-score matching ───────────────────────────\n# Treatment: Shift == 2 (night) vs Shift != 2 (control)\ndf['is_night'] = (df['Shift'] == 2).astype(int)\n\n# Confounders: all process + quality vars except Shift\nCONFOUNDERS = [v for v in ALL_FEATS if v != 'Shift']\nscaler_ps = StandardScaler()\nX_conf = scaler_ps.fit_transform(df[CONFOUNDERS])\n\n# Logistic regression for propensity scores\nps_model = LogisticRegression(max_iter=1000, C=1.0, random_state=0)\nps_model.fit(X_conf, df['is_night'])\npropensity = ps_model.predict_proba(X_conf)[:, 1]\n\ndf['propensity'] = propensity\n\nprint(\n    f'Propensity score range: [{propensity.min():.3f}, {propensity.max():.3f}]')\nprint(\n    f'Night-shift samples: {df[\"is_night\"].sum()}  |  Control: {(1-df[\"is_night\"]).sum()}')\n\n# Matching: for each treated unit, find the closest control unit (greedy)\ntreated_idx = df.index[df['is_night'] == 1].tolist()\ncontrol_idx = df.index[df['is_night'] == 0].tolist()\ncontrol_ps = propensity[control_idx]\n\nmatched_pairs = []\nused_controls = set()\n\n# Sort treated by propensity for efficiency\ntreated_sorted = sorted(treated_idx, key=lambda i: propensity[i])\n\nfor t_idx in treated_sorted:\n    t_ps = propensity[t_idx]\n    # Find closest unused control\n    best_c, best_diff = None, np.inf\n    for c_pos, c_idx in enumerate(control_idx):\n        if c_idx in used_controls:\n            continue\n        diff = abs(propensity[c_idx] - t_ps)\n        if diff &lt; best_diff:\n            best_diff = diff\n            best_c = c_idx\n            best_c_pos = c_pos\n        if diff == 0:\n            break   # perfect match\n\n    if best_c is not None and best_diff &lt; 0.05:  # caliper = 0.05\n        matched_pairs.append((t_idx, best_c))\n        used_controls.add(best_c)\n\nprint(f'Matched pairs (caliper=0.05): {len(matched_pairs)}')\n\n# Estimate ATT (Average Treatment Effect on Treated)\ndefect_treated = np.mean([df.loc[t, 'Defect'] for t, c in matched_pairs])\ndefect_control = np.mean([df.loc[c, 'Defect'] for t, c in matched_pairs])\nATT = defect_treated - defect_control\n\nprint(f'\\nCausal Effect of Night Shift on Defect Rate:')\nprint(f'  Matched treated defect rate:  {defect_treated*100:.2f}%')\nprint(f'  Matched control defect rate:  {defect_control*100:.2f}%')\nprint(f'  ATT (causal effect):          {ATT*100:+.2f} percentage points')\n\n\n\n\nCode\n# ─── 6. Propensity + causal effect visualisation ──────────\nfig, axes = plt.subplots(1, 3, figsize=(17, 5))\n\n# Propensity distribution before matching\naxes[0].hist(propensity[df['is_night'] == 1], bins=40, alpha=0.6, color='#c44e52',\n             density=True, label='Night shift')\naxes[0].hist(propensity[df['is_night'] == 0], bins=40, alpha=0.6, color='#4c72b0',\n             density=True, label='Control')\naxes[0].set_title('Propensity Score Distribution (Before Matching)')\naxes[0].set_xlabel('Propensity Score')\naxes[0].legend()\n\n# After matching\nmatched_t_ps = [propensity[t] for t, c in matched_pairs]\nmatched_c_ps = [propensity[c] for t, c in matched_pairs]\naxes[1].hist(matched_t_ps, bins=30, alpha=0.6, color='#c44e52',\n             density=True, label='Night (matched)')\naxes[1].hist(matched_c_ps, bins=30, alpha=0.6, color='#4c72b0',\n             density=True, label='Control (matched)')\naxes[1].set_title('Propensity Score Distribution (After Matching)')\naxes[1].set_xlabel('Propensity Score')\naxes[1].legend()\n\n# Treatment effect bar chart\naxes[2].bar(['Control\\n(matched)', 'Night Shift\\n(matched)', 'Causal Effect\\n(ATT)'],\n            [defect_control*100, defect_treated*100, ATT*100],\n            color=['#4c72b0', '#c44e52', '#8172b2'], edgecolor='white', width=0.5)\naxes[2].axhline(0, color='black', lw=0.5)\naxes[2].set_title('Causal Effect of Night Shift')\naxes[2].set_ylabel('Defect Rate (%)')\nfor i, v in enumerate([defect_control*100, defect_treated*100, ATT*100]):\n    axes[2].text(i, v + 0.3, f'{v:+.1f}%',\n                 ha='center', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 3. Hand-Rolled Histogram Gradient Boosting (XGBoost-Style)\n\n# ─── 7. Histogram Gradient Boosting (simplified XGBoost) ──\nclass HistGBTree:\n    \"\"\"Single decision stump using histogram-based splitting.\"\"\"\n\n    def __init__(self, n_bins=32):\n        self.n_bins = n_bins\n        self.split_feat = None\n        self.split_thresh = None\n        self.left_val = 0\n        self.right_val = 0\n\n    def fit(self, X, grad, hess, bin_edges):\n        \"\"\"Find the best split to minimise the second-order objective.\"\"\"\n        best_gain = -np.inf\n        n_feat = X.shape[1]\n\n        for feat in range(n_feat):\n            edges = bin_edges[feat]\n            for b in range(1, len(edges)-1):\n                thresh = edges[b]\n                left_mask = X[:, feat] &lt;= thresh\n                right_mask = ~left_mask\n                if left_mask.sum() &lt; 5 or right_mask.sum() &lt; 5:\n                    continue\n\n                G_L = grad[left_mask].sum()\n                H_L = hess[left_mask].sum()\n                G_R = grad[right_mask].sum()\n                H_R = hess[right_mask].sum()\n\n                # Gain = 0.5 * (G_L²/H_L + G_R²/H_R - (G_L+G_R)²/(H_L+H_R))\n                gain = 0.5 * (G_L**2/(H_L+1e-6) + G_R**2/(H_R+1e-6)\n                              - (G_L+G_R)**2/(H_L+H_R+1e-6))\n\n                if gain &gt; best_gain:\n                    best_gain = gain\n                    self.split_feat = feat\n                    self.split_thresh = thresh\n                    self.left_val = -G_L / (H_L + 1e-6)\n                    self.right_val = -G_R / (H_R + 1e-6)\n\n    def predict(self, X):\n        mask = X[:, self.split_feat] &lt;= self.split_thresh\n        preds = np.where(mask, self.left_val, self.right_val)\n        return preds\n\n\nclass HandRolledGBM:\n    \"\"\"Binary classification via histogram gradient boosting.\"\"\"\n\n    def __init__(self, n_trees=200, learning_rate=0.1, n_bins=16):\n        self.n_trees = n_trees\n        self.lr = learning_rate\n        self.n_bins = n_bins\n        self.trees = []\n        self.bin_edges = None\n\n    def _sigmoid(self, x):\n        return 1 / (1 + np.exp(-np.clip(x, -30, 30)))\n\n    def fit(self, X, y):\n        # Precompute bin edges per feature\n        self.bin_edges = []\n        for feat in range(X.shape[1]):\n            edges = np.quantile(X[:, feat], np.linspace(0, 1, self.n_bins+1))\n            self.bin_edges.append(edges)\n\n        F = np.zeros(len(y))   # cumulative prediction (log-odds)\n        for t in range(self.n_trees):\n            p = self._sigmoid(F)\n            grad = p - y              # gradient of log-loss\n            hess = p * (1 - p)        # hessian\n\n            tree = HistGBTree(self.n_bins)\n            tree.fit(X, grad, hess, self.bin_edges)\n            self.trees.append(tree)\n            F += self.lr * tree.predict(X)\n        return self\n\n    def predict_proba(self, X):\n        F = np.zeros(len(X))\n        for tree in self.trees:\n            F += self.lr * tree.predict(X)\n        return self._sigmoid(F)\n\n    def predict(self, X):\n        return (self.predict_proba(X) &gt;= 0.5).astype(int)\n\n\n# Train\nX_feat = df[ALL_FEATS].values\ny_feat = df['Defect'].values\nscaler_gb = StandardScaler()\nX_s = scaler_gb.fit_transform(X_feat)\n\nX_train, X_test, y_train, y_test = train_test_split(X_s, y_feat, test_size=0.25,\n                                                    stratify=y_feat, random_state=42)\n\nprint('Training Hand-Rolled GBM (200 trees) …')\nhgbm = HandRolledGBM(n_trees=200, learning_rate=0.08, n_bins=16)\nhgbm.fit(X_train, y_train)\n\n# Evaluate\nhgbm_proba = hgbm.predict_proba(X_test)\nhgbm_pred = hgbm.predict(X_test)\nfpr, tpr, _ = roc_curve(y_test, hgbm_proba)\nauc_val = auc(fpr, tpr)\nprint(f'Hand-Rolled GBM AUC: {auc_val:.3f}')\nprint(classification_report(y_test, hgbm_pred, target_names=['OK', 'Defect']))\n\n\n\n\nCode\n# ─── 8. Compare with sklearn GBR ──────────────────────────\nsk_gbr = GradientBoostingClassifier(n_estimators=200, max_depth=2,\n                                    learning_rate=0.08, random_state=0)\nsk_gbr.fit(X_train, y_train)\nsk_proba = sk_gbr.predict_proba(X_test)[:, 1]\nfpr_sk, tpr_sk, _ = roc_curve(y_test, sk_proba)\nauc_sk = auc(fpr_sk, tpr_sk)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(fpr, tpr, lw=2, color='steelblue',\n        label=f'Hand-Rolled GBM (AUC={auc_val:.3f})')\nax.plot(fpr_sk, tpr_sk, lw=2, color='#c44e52',\n        label=f'Sklearn GBR (AUC={auc_sk:.3f})')\nax.plot([0, 1], [0, 1], 'k--', lw=0.8)\nax.set_xlabel('FPR')\nax.set_ylabel('TPR')\nax.set_title('ROC Comparison — Hand-Rolled vs Sklearn GBM')\nax.legend(loc='lower right')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Shapley Root-Cause Attribution\n\n# ─── 9. Shapley values via marginal contribution sampling ─\ndef shapley_values(model_fn, X_sample, X_background, n_perms=100, seed=0):\n    \"\"\"\n    Estimate Shapley values for one sample using sampling-based approach.\n    model_fn: callable X → probability\n    X_sample: single sample (1, d)\n    X_background: background dataset for marginalisation\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    d = X_sample.shape[1]\n    shap = np.zeros(d)\n    base = model_fn(X_background).mean()   # expected value under background\n\n    for _ in range(n_perms):\n        # Random permutation of features\n        perm = rng.permutation(d)\n        # Random background sample\n        bg = X_background[rng.integers(0, len(X_background))]\n        x_bg = bg.copy()\n        x_fg = bg.copy()\n\n        for feat in perm:\n            # Before including feat: x_bg has background for feat\n            pred_before = model_fn(x_bg.reshape(1, -1))[0]\n            # Include feat from sample\n            x_bg[feat] = X_sample[0, feat]\n            pred_after = model_fn(x_bg.reshape(1, -1))[0]\n            # Marginal contribution\n            shap[feat] += (pred_after - pred_before)\n\n    shap /= n_perms\n    return shap\n\n\n# Compute Shapley for top-10 defective samples\ndefect_idx = np.where(y_test == 1)[0][:10]\nall_shap = []\n\nprint('Computing Shapley values for 10 defective samples …')\nfor i, idx in enumerate(defect_idx):\n    sv = shapley_values(\n        lambda X: sk_gbr.predict_proba(X)[:, 1],\n        X_test[idx:idx+1],\n        X_train[:500],   # subsample background for speed\n        n_perms=80, seed=i\n    )\n    all_shap.append(sv)\n    print(f'  Sample {i+1}/10 done.')\n\nshap_matrix = np.array(all_shap)   # (10, n_features)\nprint('\\nShapley matrix shape:', shap_matrix.shape)\n\n\n\n\nCode\n# ─── 10. Shapley beeswarm + waterfall plot ────────────────\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Beeswarm: mean |SHAP| across defective samples\nmean_abs_shap = np.abs(shap_matrix).mean(axis=0)\nranked = np.argsort(mean_abs_shap)\n\ntop_n = min(12, len(ALL_FEATS))\ntop_idx = ranked[-top_n:]\n\n# Beeswarm-style dot plot\nfor plot_pos, feat_idx in enumerate(top_idx):\n    vals = shap_matrix[:, feat_idx]\n    # Jitter y for visibility\n    jitter = np.random.default_rng(plot_pos).uniform(-0.15, 0.15, len(vals))\n    colors = ['#c44e52' if v &gt; 0 else '#4c72b0' for v in vals]\n    axes[0].scatter(vals, np.full(len(vals), plot_pos) + jitter,\n                    c=colors, s=40, edgecolors='white', zorder=3)\n\naxes[0].set_yticks(range(top_n))\naxes[0].set_yticklabels([ALL_FEATS[i] for i in top_idx], fontsize=9)\naxes[0].axvline(0, color='black', lw=0.8)\naxes[0].set_xlabel('SHAP Value')\naxes[0].set_title('Shapley Beeswarm — Top Features (red=↑defect risk)')\n\n# Waterfall for the single highest-risk defective sample\nworst_idx = np.argmax(sk_gbr.predict_proba(X_test[defect_idx])[:, 1])\nworst_shap = shap_matrix[worst_idx]\norder = np.argsort(np.abs(worst_shap))[::-1][:10]\ncumulative = np.zeros(len(order)+1)\nbase_val = sk_gbr.predict_proba(X_train[:500]).mean()   # E[f(x)]\ncumulative[0] = base_val\nfor i, feat_idx in enumerate(order):\n    cumulative[i+1] = cumulative[i] + worst_shap[feat_idx]\n\nlabels_wf = ['Base'] + [ALL_FEATS[i] for i in order]\ncolors_wf = ['grey'] + ['#c44e52' if worst_shap[i]\n                        &gt; 0 else '#4c72b0' for i in order]\n\naxes[1].bar(range(len(labels_wf)), cumulative,\n            color=colors_wf, edgecolor='white', width=0.6)\naxes[1].axhline(cumulative[-1], color='black', ls='--', lw=0.8, alpha=0.5)\naxes[1].set_xticks(range(len(labels_wf)))\naxes[1].set_xticklabels(labels_wf, rotation=30, ha='right', fontsize=8)\naxes[1].set_ylabel('Defect Probability')\naxes[1].set_title(f'Waterfall — Highest-Risk Sample (P={cumulative[-1]:.3f})')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 5. Capability Forecasting — Predicting Future Cpk\n\n# ─── 11. Rolling Cpk + forecasting ────────────────────────\n# Compute rolling Cpk for Wall_Thickness\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import GradientBoostingRegressor as GBReg\nUSL_wt = 2.08   # upper spec limit\nLSL_wt = 1.92   # lower spec limit\n\nWIN_CPK = 200\ncpk_series = []\nfor i in range(WIN_CPK, len(df), 50):\n    chunk = df['Wall_Thickness'].iloc[i-WIN_CPK:i]\n    mu = chunk.mean()\n    sig = chunk.std()\n    cpu = (USL_wt - mu) / (3*sig) if sig &gt; 0 else 99\n    cpl = (mu - LSL_wt) / (3*sig) if sig &gt; 0 else 99\n    cpk_series.append({'idx': i, 'Cpk': min(cpu, cpl), 'mu': mu, 'std': sig})\n\ncpk_df = pd.DataFrame(cpk_series)\nprint(f'Cpk time series: {len(cpk_df)} points')\nprint(f'  Mean Cpk: {cpk_df[\"Cpk\"].mean():.3f}')\nprint(f'  Min Cpk:  {cpk_df[\"Cpk\"].min():.3f}')\n\n# Forecast Cpk using GBR on lagged Cpk values\nLAG_CPK = 5\ncpk_vals = cpk_df['Cpk'].values\nX_cpk = np.column_stack([cpk_vals[i:len(cpk_vals)-LAG_CPK+i]\n                        for i in range(LAG_CPK)])\ny_cpk = cpk_vals[LAG_CPK:]\n\nsplit_cpk = int(0.8 * len(X_cpk))\ncpk_model = GBReg(n_estimators=100, max_depth=3, random_state=0)\ncpk_model.fit(X_cpk[:split_cpk], y_cpk[:split_cpk])\ncpk_pred = cpk_model.predict(X_cpk[split_cpk:])\n\ncpk_rmse = np.sqrt(mean_squared_error(y_cpk[split_cpk:], cpk_pred))\nprint(f'  Cpk Forecast RMSE: {cpk_rmse:.4f}')\n\n\n\n\nCode\n# ─── 12. Cpk forecast plot ─────────────────────────────────\nfig, ax = plt.subplots(figsize=(14, 5))\n\n# Full Cpk series\nax.plot(cpk_df['idx'], cpk_df['Cpk'], lw=1.2,\n        color='steelblue', label='Actual Cpk')\n\n# Forecast region\ntest_indices = cpk_df['idx'].values[LAG_CPK + split_cpk:]\nax.plot(test_indices, cpk_pred, lw=1.5, color='crimson',\n        ls='--', label='Forecasted Cpk')\n\n# Reference lines\nax.axhline(1.33, color='green', ls=':', lw=1, label='Target (1.33)')\nax.axhline(1.00, color='orange', ls=':', lw=1, label='Minimum (1.00)')\n\n# Shade forecast region\nax.axvspan(test_indices[0], test_indices[-1], alpha=0.08,\n           color='crimson', label='Forecast window')\n\nax.set_title('Process Capability (Cpk) — Actual vs Forecasted', fontsize=13)\nax.set_xlabel('Sample Index')\nax.set_ylabel('Cpk')\nax.legend(loc='lower left')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 6. Cost-Benefit Analysis — Optimal Inspection Policy\n\n# ─── 13. Expected cost model ──────────────────────────────\n# Cost parameters (arbitrary but realistic units)\nCOST_DEFECT = 500   # cost of a defect reaching customer ($)\nCOST_INSPECTION = 25    # cost of inspecting one part ($)\nCOST_SCRAP = 80    # cost of scrapping a detected defect ($)\n\n# For each test sample, compute expected cost under two policies:\n# Policy A: Ship without inspection\n# Policy B: Inspect (if defect found → scrap; if not → ship)\n\nproba_defect = sk_gbr.predict_proba(X_test)[:, 1]\n\n# expected cost if shipped\ncost_no_inspect = proba_defect * COST_DEFECT\ncost_inspect = COST_INSPECTION + proba_defect * \\\n    COST_SCRAP             # expected cost if inspected\n\n# Optimal policy: inspect if cost_inspect &lt; cost_no_inspect\n# → inspect when p &gt; COST_INSPECTION / (COST_DEFECT - COST_SCRAP)\nthreshold_optimal = COST_INSPECTION / (COST_DEFECT - COST_SCRAP)\nprint(f'Optimal inspection threshold: p &gt; {threshold_optimal:.4f}')\nprint(\n    f'  (i.e., inspect when predicted defect prob &gt; {threshold_optimal*100:.2f}%)')\n\noptimal_policy = (proba_defect &gt; threshold_optimal).astype(int)\nactual_cost = np.where(optimal_policy == 1,\n                       COST_INSPECTION + y_test * COST_SCRAP,\n                       y_test * COST_DEFECT)\nnaive_cost = y_test * COST_DEFECT   # ship everything\n\ntotal_optimal = actual_cost.sum()\ntotal_naive = naive_cost.sum()\nsavings = total_naive - total_optimal\nprint(f'\\n  Total cost (ship all):      ${total_naive:,.0f}')\nprint(f'  Total cost (optimal policy): ${total_optimal:,.0f}')\nprint(\n    f'  Savings:                     ${savings:,.0f} ({savings/total_naive*100:.1f}%)')\nprint(\n    f'  Parts inspected:            {optimal_policy.sum()} / {len(optimal_policy)} ({optimal_policy.mean()*100:.1f}%)')\n\n\n\n\nCode\n# ─── 14. Cost analysis visualisation ──────────────────────\nfig, axes = plt.subplots(1, 3, figsize=(17, 5))\n\n# Cost distribution comparison\nthresholds = np.linspace(0, 0.5, 100)\ntotal_costs = []\nfor t in thresholds:\n    policy = (proba_defect &gt; t).astype(int)\n    cost = np.where(policy == 1,\n                    COST_INSPECTION + y_test * COST_SCRAP,\n                    y_test * COST_DEFECT).sum()\n    total_costs.append(cost)\n\naxes[0].plot(thresholds, total_costs, lw=2, color='steelblue')\naxes[0].axvline(threshold_optimal, color='crimson', ls='--', lw=1.5,\n                label=f'Optimal threshold={threshold_optimal:.3f}')\naxes[0].set_title('Total Cost vs Inspection Threshold')\naxes[0].set_xlabel('Defect Probability Threshold')\naxes[0].set_ylabel('Total Expected Cost ($)')\naxes[0].legend()\n\n# Breakdown: inspected vs shipped\ncategories = ['Ship All\\n(naive)', 'Optimal\\nPolicy']\ndefects_escaped = [y_test.sum(), ((1-optimal_policy) * y_test).sum()]\ndefects_caught = [0, (optimal_policy * y_test).sum()]\nno_defect = [len(y_test)-y_test.sum(), len(y_test)-y_test.sum()]\n\nx_pos = [0, 1]\naxes[1].bar(x_pos, defects_escaped, color='#c44e52', label='Defects escaped')\naxes[1].bar(x_pos, defects_caught, bottom=defects_escaped,\n            color='#55a868', label='Defects caught')\naxes[1].set_xticks(x_pos)\naxes[1].set_xticklabels(categories)\naxes[1].set_title('Defect Disposition by Policy')\naxes[1].set_ylabel('Count')\naxes[1].legend()\n\n# Cost per part distribution\ncost_per_part_naive = y_test * COST_DEFECT\ncost_per_part_optimal = np.where(optimal_policy == 1,\n                                 COST_INSPECTION + y_test * COST_SCRAP,\n                                 y_test * COST_DEFECT)\naxes[2].hist(cost_per_part_naive[cost_per_part_naive &gt; 0], bins=20, alpha=0.5,\n             color='#c44e52', label='Naive', density=True)\naxes[2].hist(cost_per_part_optimal[cost_per_part_optimal &gt; 0], bins=20, alpha=0.5,\n             color='#4c72b0', label='Optimal', density=True)\naxes[2].set_title('Per-Part Cost Distribution (non-zero only)')\naxes[2].set_xlabel('Cost ($)')\naxes[2].legend()\n\nplt.suptitle('Cost-Benefit Analysis — Optimal Inspection Policy',\n             fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/07_ADV_Quality_Defect_Prediction.html#summary-portfolio-takeaways",
    "href": "projects/07_ADV_Quality_Defect_Prediction.html#summary-portfolio-takeaways",
    "title": "Advanced Quality Analytics",
    "section": "",
    "text": "Technique\nValue\n\n\n\n\nKaplan-Meier\nNonparametric survival curves reveal that night shift and old machines degrade faster\n\n\nPropensity-Score Matching\nIsolates the causal effect of night shift on defect rate — not just correlation\n\n\nHand-Rolled GBM\nDemonstrates deep understanding of boosting internals — histogram splits, second-order gradients\n\n\nShapley Attribution\nBeeswarm + waterfall plots provide actionable root-cause explanations per defective part\n\n\nCpk Forecasting\nPredicts future capability drift — enables proactive maintenance before quality degrades\n\n\nCost-Benefit Policy\nTranslates model output into an optimal business decision — the final step from ML to value\n\n\n\nThis notebook completes the full quality analytics pipeline: monitor → diagnose → explain → decide → forecast."
  },
  {
    "objectID": "projects/06_ADV_Process_Data_SPC.html",
    "href": "projects/06_ADV_Process_Data_SPC.html",
    "title": "Advanced Statistical Process Control",
    "section": "",
    "text": "Topic\nTechnique\n\n\n\n\nMultivariate SPC\nHotelling T² statistic (PCA-reduced)\n\n\nSignal decomposition\nPCA contribution analysis for fault isolation\n\n\nAdaptive monitoring\nEWMA + CUSUM joint detection with auto-tuned parameters\n\n\nFault isolation\nStructured residual analysis (SRA)\n\n\nRoot-cause ranking\nContribution plot — identifies which variable caused the alarm\n\n\nPhase I / Phase II\nProper two-phase control chart methodology\n\n\n\n\n\n\nTennessee Eastman Process (synthetic replica, 6 process variables)\nReference: https://github.com/Ramin-Khalatbari/dataset-Tennessee-Eastman\n\n\n\nCode\n# ─── 1. Imports ─────────────────────────────────────────────\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('✓ All imports loaded.')\n\n\n\n\nCode\n# ─── 2. Synthetic Tennessee-Eastman style process ──────────\ndef gen_te_process(n=3000, seed=55):\n    rng = np.random.default_rng(seed)\n\n    # 6 correlated process variables (normal state)\n    # Covariance structure: block-diagonal with cross-links\n    cov = np.array([\n        [1.00, 0.60, 0.20, 0.10, 0.05, 0.00],\n        [0.60, 1.00, 0.35, 0.15, 0.08, 0.02],\n        [0.20, 0.35, 1.00, 0.40, 0.10, 0.05],\n        [0.10, 0.15, 0.40, 1.00, 0.45, 0.12],\n        [0.05, 0.08, 0.10, 0.45, 1.00, 0.50],\n        [0.00, 0.02, 0.05, 0.12, 0.50, 1.00],\n    ])\n    means = np.array([85.0, 3.2, 50.0, 0.45, 220.0, 68.0])\n    stds = np.array([1.5, 0.2, 3.0, 0.03, 8.0, 2.0])\n\n    # Generate correlated normal data\n    Z = rng.multivariate_normal(np.zeros(6), cov, n)\n    data = means + Z * stds\n\n    labels = np.zeros(n, dtype=int)  # 0 = normal\n\n    # ─── Fault 1: Gradual drift in Var 0 (Temperature) ───\n    drift_start = 500\n    drift_end = 700\n    drift_amp = 3.0 * stds[0]\n    ramp = np.linspace(0, drift_amp, drift_end - drift_start)\n    data[drift_start:drift_end, 0] += ramp\n    labels[drift_start:drift_end] = 1\n\n    # ─── Fault 2: Step change in Var 2 (Flow) + correlated effect on Var 3 ───\n    step_start = 1100\n    step_end = 1300\n    data[step_start:step_end, 2] += 2.5 * stds[2]\n    data[step_start:step_end, 3] -= 0.8 * stds[3]   # downstream effect\n    labels[step_start:step_end] = 2\n\n    # ─── Fault 3: Variance increase in Var 4 + Var 5 (sensor noise) ───\n    var_start = 1800\n    var_end = 2000\n    data[var_start:var_end,\n         4] += rng.normal(0, 2.5 * stds[4], var_end - var_start)\n    data[var_start:var_end,\n         5] += rng.normal(0, 2.0 * stds[5], var_end - var_start)\n    labels[var_start:var_end] = 3\n\n    # ─── Fault 4: Correlation structure breakdown ───\n    corr_start = 2300\n    corr_end = 2500\n    # Add independent noise to break the correlation\n    data[corr_start:corr_end,\n         :] += rng.normal(0, 0.5, (corr_end - corr_start, 6)) * stds\n    labels[corr_start:corr_end] = 4\n\n    var_names = ['Temperature', 'Pressure',\n                 'FlowRate', 'Conc_A', 'HeatDuty', 'Humidity']\n    df = pd.DataFrame(data, columns=var_names)\n    df['Fault'] = labels\n    df['Time'] = pd.date_range('2024-01-01', periods=n, freq='5min')\n    return df, var_names\n\n\ndf, VAR_NAMES = gen_te_process()\nprint(f'Shape: {df.shape}')\nprint(\n    f'Fault distribution: {dict(zip(*np.unique(df[\"Fault\"], return_counts=True)))}')\n\n\n\nPhase I — Establish Baseline (Normal Operating Region)\n\nWe use the first 500 samples (all normal) to compute the in-control mean, covariance, and PCA model. All subsequent monitoring uses these as reference.\n\n\nCode\n# ─── 3. Phase I: baseline statistics ─────────────────────\nfrom scipy.stats import f as f_dist\nPHASE1_END = 500   # all normal\n\nphase1 = df[VAR_NAMES].iloc[:PHASE1_END].values\nscaler = StandardScaler()\nphase1_s = scaler.fit_transform(phase1)\n\n# PCA on Phase I data\nN_PC = 4   # retain 4 principal components\npca = PCA(n_components=N_PC)\npca.fit(phase1_s)\n\nprint(f'Phase I samples: {PHASE1_END}')\nprint(\n    f'PCA explained variance: {pca.explained_variance_ratio_.sum()*100:.1f}% ({N_PC} PCs)')\nprint(f'Per-PC: {[f\"{v*100:.1f}%\" for v in pca.explained_variance_ratio_]}')\n\n# Compute Phase I T² distribution for threshold calibration\nscores_phase1 = pca.transform(phase1_s)\n# T² = score @ diag(1/eigenvalues) @ score.T  (per sample)\neigvals = pca.explained_variance_\nT2_phase1 = np.sum(scores_phase1**2 / eigvals, axis=1)\n\n# UCL: use F-distribution approximation\np, n1 = N_PC, PHASE1_END\nalpha = 0.01   # significance level\nF_crit = f_dist.ppf(1 - alpha, p, n1 - p)\nT2_UCL = p * (n1 - 1) * (n1 + 1) / (n1 * (n1 - p)) * F_crit\n\nprint(f'\\nHotelling T² UCL (α={alpha}): {T2_UCL:.2f}')\nprint(f'Phase I T² max: {T2_phase1.max():.2f}  (should be &lt; UCL)')\n\n\n\nPhase II — Hotelling T² Monitoring\n\n\n\nCode\n# ─── 4. Phase II: compute T² for all samples ─────────────\nX_all_s = scaler.transform(df[VAR_NAMES].values)\nscores_all = pca.transform(X_all_s)\nT2_all = np.sum(scores_all**2 / eigvals, axis=1)\n\n# Also compute SPE (Squared Prediction Error) = reconstruction error\nrecon_all = pca.inverse_transform(scores_all)\nSPE_all = np.sum((X_all_s - recon_all)**2, axis=1)\n\n# SPE UCL (chi-squared approximation)\nSPE_phase1 = np.sum(\n    (phase1_s - pca.inverse_transform(pca.transform(phase1_s)))**2, axis=1)\nn_resid = len(VAR_NAMES) - N_PC\nSPE_UCL = np.percentile(SPE_phase1, 99)   # empirical 99th percentile\n\nprint(f'SPE UCL (empirical 99%): {SPE_UCL:.4f}')\n\n# ─── Plot T² and SPE control charts ───\nfig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True)\n\n# T²\naxes[0].plot(T2_all, lw=0.7, color='steelblue')\naxes[0].axhline(T2_UCL, color='red', ls='--',\n                lw=1.2, label=f'UCL={T2_UCL:.1f}')\nviolations_T2 = T2_all &gt; T2_UCL\naxes[0].scatter(np.where(violations_T2)[0], T2_all[violations_T2],\n                s=15, color='red', zorder=5, label=f'Violations ({violations_T2.sum()})')\n# Shade fault regions\nfault_colors = {1: '#ff9999', 2: '#ffcc99', 3: '#cc99ff', 4: '#99ccff'}\nfor fid, fc in fault_colors.items():\n    mask = df['Fault'].values == fid\n    if mask.any():\n        idxs = np.where(mask)[0]\n        axes[0].axvspan(idxs[0], idxs[-1], alpha=0.12,\n                        color=fc, label=f'Fault {fid}')\naxes[0].set_title('Hotelling T² Control Chart (Phase II)', fontsize=13)\naxes[0].set_ylabel('T²')\naxes[0].legend(loc='upper right', fontsize=7)\n\n# SPE\naxes[1].plot(SPE_all, lw=0.7, color='purple')\naxes[1].axhline(SPE_UCL, color='red', ls='--',\n                lw=1.2, label=f'UCL={SPE_UCL:.3f}')\nviolations_SPE = SPE_all &gt; SPE_UCL\naxes[1].scatter(np.where(violations_SPE)[0], SPE_all[violations_SPE],\n                s=15, color='red', zorder=5, label=f'Violations ({violations_SPE.sum()})')\nfor fid, fc in fault_colors.items():\n    mask = df['Fault'].values == fid\n    if mask.any():\n        idxs = np.where(mask)[0]\n        axes[1].axvspan(idxs[0], idxs[-1], alpha=0.12, color=fc)\naxes[1].set_title('SPE (Squared Prediction Error) Control Chart', fontsize=13)\naxes[1].set_ylabel('SPE')\naxes[1].set_xlabel('Sample')\naxes[1].legend(loc='upper right', fontsize=7)\n\nplt.tight_layout()\nplt.show()\n\n\n\nFault Isolation — PCA Contribution Analysis\n\n\n\nCode\n# ─── 5. Contribution plot for a specific alarm ─────────\ndef contribution_plot(sample_idx, X_s, pca, eigvals, T2_UCL):\n    \"\"\"\n    Compute the contribution of each original variable to the T² statistic.\n    Uses the PCA loading decomposition method.\n    \"\"\"\n    x = X_s[sample_idx]\n    scores = pca.transform(x.reshape(1, -1))[0]\n\n    # T² decomposition: sum over PCs of (score_k^2 / eigenval_k)\n    # Each PC's contribution to each variable via loadings\n    loadings = pca.components_   # (n_pc, n_vars)\n    contributions = np.zeros(len(x))\n\n    for k in range(len(eigvals)):\n        pc_contrib = (scores[k]**2) / eigvals[k]\n        # Distribute this PC's contribution to variables proportionally to |loading|²\n        loading_sq = loadings[k]**2\n        contributions += pc_contrib * loading_sq / (loading_sq.sum() + 1e-10)\n\n    return contributions\n\n\n# Find the first T² violation in each fault\nprint('Contribution analysis for first alarm in each fault:')\nfig, axes = plt.subplots(2, 2, figsize=(14, 9))\nfault_ids = [1, 2, 3, 4]\n\nfor ax, fid in zip(axes.flatten(), fault_ids):\n    # First violation in this fault window\n    mask = (df['Fault'].values == fid) & violations_T2\n    if not mask.any():\n        # Use the first sample of the fault even if no violation\n        mask = df['Fault'].values == fid\n    first_alarm = np.where(mask)[0][0]\n\n    contribs = contribution_plot(first_alarm, X_all_s, pca, eigvals, T2_UCL)\n\n    colors = ['#c44e52' if c == contribs.max() else '#4c72b0' for c in contribs]\n    ax.bar(VAR_NAMES, contribs, color=colors, edgecolor='white')\n    ax.set_title(\n        f'Fault {fid} — Contribution Plot (sample {first_alarm})', fontsize=11)\n    ax.set_ylabel('Contribution to T²')\n    ax.tick_params(axis='x', rotation=20)\n    # Annotate the dominant variable\n    dom_var = VAR_NAMES[np.argmax(contribs)]\n    ax.text(0.5, 0.92, f'↑ {dom_var}', transform=ax.transAxes,\n            ha='center', fontsize=10, color='crimson', fontweight='bold')\n\nplt.suptitle('Fault Isolation — PCA Contribution Plots', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n\n\nEWMA + CUSUM Joint Detection with Auto-Tuned Parameters\n\n\n\nCode\n# ─── 6. Joint EWMA-CUSUM on the T² statistic ─────────────\n# EWMA on T²\nlambda_ewma = 0.15\nmu_T2 = T2_phase1.mean()\nsigma_T2 = T2_phase1.std()\n\newma_T2 = np.zeros(len(T2_all))\newma_T2[0] = T2_all[0]\newma_UCL = np.zeros(len(T2_all))\nL_ewma = 2.5\n\nfor i in range(1, len(T2_all)):\n    ewma_T2[i] = lambda_ewma * T2_all[i] + (1 - lambda_ewma) * ewma_T2[i-1]\n    var_e = (sigma_T2**2 * lambda_ewma / (2 - lambda_ewma)) * \\\n        (1 - (1-lambda_ewma)**(2*(i+1)))\n    ewma_UCL[i] = mu_T2 + L_ewma * np.sqrt(var_e)\n\newma_alerts = ewma_T2 &gt; ewma_UCL\n\n# CUSUM on T²\nk_c = 0.5 * sigma_T2\nh_c = 5.0 * sigma_T2\ncusum_p = np.zeros(len(T2_all))\ncusum_alerts = np.zeros(len(T2_all), dtype=bool)\nfor i in range(1, len(T2_all)):\n    cusum_p[i] = max(0, cusum_p[i-1] + (T2_all[i] - mu_T2) - k_c)\n    cusum_alerts[i] = cusum_p[i] &gt; h_c\n\n# Joint alert: EWMA OR CUSUM\njoint_alerts = ewma_alerts | cusum_alerts\n\nprint(f'Detection counts:')\nprint(f'  T² fixed UCL:  {violations_T2.sum():5d} alarms')\nprint(f'  EWMA:          {ewma_alerts.sum():5d} alarms')\nprint(f'  CUSUM:         {cusum_alerts.sum():5d} alarms')\nprint(f'  Joint (OR):    {joint_alerts.sum():5d} alarms')\n\n\n\n\nCode\n# ─── 7. Detection latency analysis ───────────────────────\n# For each fault, compute how many samples after fault onset the first alert fires\nfault_ranges = {1: (500, 700), 2: (1100, 1300),\n                3: (1800, 2000), 4: (2300, 2500)}\nmethods = {'T² UCL': violations_T2, 'EWMA': ewma_alerts,\n           'CUSUM': cusum_alerts, 'Joint': joint_alerts}\n\nlatency_records = []\nfor fid, (start, end) in fault_ranges.items():\n    for mname, alerts in methods.items():\n        # First alert at or after fault start\n        alerts_in_fault = np.where(alerts[start:end])[0]\n        if len(alerts_in_fault) &gt; 0:\n            latency = alerts_in_fault[0]\n        else:\n            latency = end - start   # missed entirely\n        latency_records.append(\n            {'Fault': fid, 'Method': mname, 'Latency (samples)': latency})\n\nlatency_df = pd.DataFrame(latency_records).pivot(\n    index='Fault', columns='Method', values='Latency (samples)')\n\nfig, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(latency_df, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=ax,\n            cbar_kws={'label': 'Samples to first alert'}, linewidths=0.5)\nax.set_title('Detection Latency Heatmap (lower = faster)', fontsize=13)\nax.set_xlabel('Detection Method')\nax.set_ylabel('Fault ID')\nplt.tight_layout()\nplt.show()\n\nprint('\\nLatency Table:')\nprint(latency_df.to_string())\n\n\n\nStructured Residual Analysis (SRA) — Fault Diagnosis\n\n\n\nCode\n# ─── 8. SRA: isolate faults by residual structure ──────────\n# For each variable, build a regression model from the others (Phase I).\n# The residual = actual - predicted captures variable-specific deviations.\n\nfrom sklearn.linear_model import Ridge\n\nphase1_data = df[VAR_NAMES].iloc[:PHASE1_END].values\nsra_models = {}\nfor i, var in enumerate(VAR_NAMES):\n    X_others = np.delete(phase1_data, i, axis=1)\n    y_target = phase1_data[:, i]\n    model = Ridge(alpha=1.0)\n    model.fit(X_others, y_target)\n    sra_models[var] = model\n\n# Compute residuals for all samples\nall_data = df[VAR_NAMES].values\nresiduals = np.zeros_like(all_data)\nfor i, var in enumerate(VAR_NAMES):\n    X_others = np.delete(all_data, i, axis=1)\n    residuals[:, i] = all_data[:, i] - sra_models[var].predict(X_others)\n\n# Normalise by Phase I residual std\nphase1_resid_std = np.std(residuals[:PHASE1_END], axis=0) + 1e-10\nresiduals_norm = residuals / phase1_resid_std\n\nprint('Residual matrix shape:', residuals_norm.shape)\n\n\n\n\nCode\n# ─── 9. SRA heatmap + per-fault diagnosis ─────────────────\nfig, axes = plt.subplots(2, 1, figsize=(16, 9), sharex=True)\n\n# Residual heatmap (subsample for visibility)\nstep = 3\nsns.heatmap(residuals_norm[::step].T,\n            ax=axes[0], cmap='coolwarm', vmin=-3, vmax=3,\n            xticklabels=False,\n            yticklabels=VAR_NAMES,\n            cbar_kws={'label': 'Normalised Residual'})\naxes[0].set_title('Structured Residual Analysis — Heatmap', fontsize=13)\naxes[0].set_ylabel('')\n\n# Mark fault boundaries\nfor fid, (start, end) in fault_ranges.items():\n    axes[0].axvline(start // step, color='black', ls='-', lw=1.5, alpha=0.7)\n    axes[0].axvline(end // step,   color='black', ls='--', lw=1.0, alpha=0.5)\n    axes[0].text((start+end)//(2*step), 6.2,\n                 f'F{fid}', fontsize=9, ha='center', fontweight='bold')\n\n# Per-fault mean |residual| (diagnosis signature)\naxes[1].set_visible(False)\n\nfig2, ax2 = plt.subplots(figsize=(12, 5))\nfor fid, (start, end) in fault_ranges.items():\n    mean_abs_resid = np.abs(residuals_norm[start:end]).mean(axis=0)\n    ax2.plot(VAR_NAMES, mean_abs_resid, 'o-',\n             lw=1.5, ms=6, label=f'Fault {fid}')\n\nax2.set_title(\n    'Mean |Residual| per Variable — Fault Diagnosis Signatures', fontsize=13)\nax2.set_ylabel('Mean |Normalised Residual|')\nax2.set_xlabel('Process Variable')\nax2.legend()\nax2.tick_params(axis='x', rotation=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# ─── 10. Diagnosis summary table ──────────────────────────\nprint('\\n' + '═'*60)\nprint(' FAULT DIAGNOSIS SUMMARY')\nprint('═'*60)\nfor fid, (start, end) in fault_ranges.items():\n    mean_resid = np.abs(residuals_norm[start:end]).mean(axis=0)\n    ranked = np.argsort(mean_resid)[::-1]\n    print(f'\\n  Fault {fid}: ({start}–{end})')\n    print(f'    Root-cause ranking:')\n    for rank, idx in enumerate(ranked[:3]):\n        print(\n            f'      {rank+1}. {VAR_NAMES[idx]:15s} (mean |resid| = {mean_resid[idx]:.3f})')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechnique\nValue\n\n\n\n\nPhase I / Phase II\nProper two-phase methodology — baseline established on known-normal data only\n\n\nHotelling T²\nSingle multivariate statistic captures correlated process shifts that univariate charts miss\n\n\nSPE Chart\nCatches model-structure violations (Fault 3: variance, Fault 4: correlation breakdown)\n\n\nPCA Contribution\nDecomposes T² alarm into per-variable contributions — instant root-cause identification\n\n\nEWMA + CUSUM Joint\nDetects subtle drifts (Fault 1) faster than fixed UCL; joint detection minimises latency\n\n\nSRA\nRegression-based residual isolation — produces ranked diagnosis signatures per fault type\n\n\nLatency Analysis\nQuantitative comparison shows Joint detection is fastest across all fault types\n\n\n\nThis is a complete multivariate statistical process control system — ready for chemical plants, semiconductor fabs, and pharmaceutical manufacturing."
  },
  {
    "objectID": "projects/06_ADV_Process_Data_SPC.html#portfolio-project-6-multivariate-spc-pca-based-hotelling-t²-ewma-cusum-fusion-fault-isolation-root-cause-diagnosis",
    "href": "projects/06_ADV_Process_Data_SPC.html#portfolio-project-6-multivariate-spc-pca-based-hotelling-t²-ewma-cusum-fusion-fault-isolation-root-cause-diagnosis",
    "title": "Advanced Statistical Process Control",
    "section": "",
    "text": "Topic\nTechnique\n\n\n\n\nMultivariate SPC\nHotelling T² statistic (PCA-reduced)\n\n\nSignal decomposition\nPCA contribution analysis for fault isolation\n\n\nAdaptive monitoring\nEWMA + CUSUM joint detection with auto-tuned parameters\n\n\nFault isolation\nStructured residual analysis (SRA)\n\n\nRoot-cause ranking\nContribution plot — identifies which variable caused the alarm\n\n\nPhase I / Phase II\nProper two-phase control chart methodology\n\n\n\n\n\n\nTennessee Eastman Process (synthetic replica, 6 process variables)\nReference: https://github.com/Ramin-Khalatbari/dataset-Tennessee-Eastman\n\n\n\nCode\n# ─── 1. Imports ─────────────────────────────────────────────\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('✓ All imports loaded.')\n\n\n\n\nCode\n# ─── 2. Synthetic Tennessee-Eastman style process ──────────\ndef gen_te_process(n=3000, seed=55):\n    rng = np.random.default_rng(seed)\n\n    # 6 correlated process variables (normal state)\n    # Covariance structure: block-diagonal with cross-links\n    cov = np.array([\n        [1.00, 0.60, 0.20, 0.10, 0.05, 0.00],\n        [0.60, 1.00, 0.35, 0.15, 0.08, 0.02],\n        [0.20, 0.35, 1.00, 0.40, 0.10, 0.05],\n        [0.10, 0.15, 0.40, 1.00, 0.45, 0.12],\n        [0.05, 0.08, 0.10, 0.45, 1.00, 0.50],\n        [0.00, 0.02, 0.05, 0.12, 0.50, 1.00],\n    ])\n    means = np.array([85.0, 3.2, 50.0, 0.45, 220.0, 68.0])\n    stds = np.array([1.5, 0.2, 3.0, 0.03, 8.0, 2.0])\n\n    # Generate correlated normal data\n    Z = rng.multivariate_normal(np.zeros(6), cov, n)\n    data = means + Z * stds\n\n    labels = np.zeros(n, dtype=int)  # 0 = normal\n\n    # ─── Fault 1: Gradual drift in Var 0 (Temperature) ───\n    drift_start = 500\n    drift_end = 700\n    drift_amp = 3.0 * stds[0]\n    ramp = np.linspace(0, drift_amp, drift_end - drift_start)\n    data[drift_start:drift_end, 0] += ramp\n    labels[drift_start:drift_end] = 1\n\n    # ─── Fault 2: Step change in Var 2 (Flow) + correlated effect on Var 3 ───\n    step_start = 1100\n    step_end = 1300\n    data[step_start:step_end, 2] += 2.5 * stds[2]\n    data[step_start:step_end, 3] -= 0.8 * stds[3]   # downstream effect\n    labels[step_start:step_end] = 2\n\n    # ─── Fault 3: Variance increase in Var 4 + Var 5 (sensor noise) ───\n    var_start = 1800\n    var_end = 2000\n    data[var_start:var_end,\n         4] += rng.normal(0, 2.5 * stds[4], var_end - var_start)\n    data[var_start:var_end,\n         5] += rng.normal(0, 2.0 * stds[5], var_end - var_start)\n    labels[var_start:var_end] = 3\n\n    # ─── Fault 4: Correlation structure breakdown ───\n    corr_start = 2300\n    corr_end = 2500\n    # Add independent noise to break the correlation\n    data[corr_start:corr_end,\n         :] += rng.normal(0, 0.5, (corr_end - corr_start, 6)) * stds\n    labels[corr_start:corr_end] = 4\n\n    var_names = ['Temperature', 'Pressure',\n                 'FlowRate', 'Conc_A', 'HeatDuty', 'Humidity']\n    df = pd.DataFrame(data, columns=var_names)\n    df['Fault'] = labels\n    df['Time'] = pd.date_range('2024-01-01', periods=n, freq='5min')\n    return df, var_names\n\n\ndf, VAR_NAMES = gen_te_process()\nprint(f'Shape: {df.shape}')\nprint(\n    f'Fault distribution: {dict(zip(*np.unique(df[\"Fault\"], return_counts=True)))}')\n\n\n\nPhase I — Establish Baseline (Normal Operating Region)\n\nWe use the first 500 samples (all normal) to compute the in-control mean, covariance, and PCA model. All subsequent monitoring uses these as reference.\n\n\nCode\n# ─── 3. Phase I: baseline statistics ─────────────────────\nfrom scipy.stats import f as f_dist\nPHASE1_END = 500   # all normal\n\nphase1 = df[VAR_NAMES].iloc[:PHASE1_END].values\nscaler = StandardScaler()\nphase1_s = scaler.fit_transform(phase1)\n\n# PCA on Phase I data\nN_PC = 4   # retain 4 principal components\npca = PCA(n_components=N_PC)\npca.fit(phase1_s)\n\nprint(f'Phase I samples: {PHASE1_END}')\nprint(\n    f'PCA explained variance: {pca.explained_variance_ratio_.sum()*100:.1f}% ({N_PC} PCs)')\nprint(f'Per-PC: {[f\"{v*100:.1f}%\" for v in pca.explained_variance_ratio_]}')\n\n# Compute Phase I T² distribution for threshold calibration\nscores_phase1 = pca.transform(phase1_s)\n# T² = score @ diag(1/eigenvalues) @ score.T  (per sample)\neigvals = pca.explained_variance_\nT2_phase1 = np.sum(scores_phase1**2 / eigvals, axis=1)\n\n# UCL: use F-distribution approximation\np, n1 = N_PC, PHASE1_END\nalpha = 0.01   # significance level\nF_crit = f_dist.ppf(1 - alpha, p, n1 - p)\nT2_UCL = p * (n1 - 1) * (n1 + 1) / (n1 * (n1 - p)) * F_crit\n\nprint(f'\\nHotelling T² UCL (α={alpha}): {T2_UCL:.2f}')\nprint(f'Phase I T² max: {T2_phase1.max():.2f}  (should be &lt; UCL)')\n\n\n\nPhase II — Hotelling T² Monitoring\n\n\n\nCode\n# ─── 4. Phase II: compute T² for all samples ─────────────\nX_all_s = scaler.transform(df[VAR_NAMES].values)\nscores_all = pca.transform(X_all_s)\nT2_all = np.sum(scores_all**2 / eigvals, axis=1)\n\n# Also compute SPE (Squared Prediction Error) = reconstruction error\nrecon_all = pca.inverse_transform(scores_all)\nSPE_all = np.sum((X_all_s - recon_all)**2, axis=1)\n\n# SPE UCL (chi-squared approximation)\nSPE_phase1 = np.sum(\n    (phase1_s - pca.inverse_transform(pca.transform(phase1_s)))**2, axis=1)\nn_resid = len(VAR_NAMES) - N_PC\nSPE_UCL = np.percentile(SPE_phase1, 99)   # empirical 99th percentile\n\nprint(f'SPE UCL (empirical 99%): {SPE_UCL:.4f}')\n\n# ─── Plot T² and SPE control charts ───\nfig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True)\n\n# T²\naxes[0].plot(T2_all, lw=0.7, color='steelblue')\naxes[0].axhline(T2_UCL, color='red', ls='--',\n                lw=1.2, label=f'UCL={T2_UCL:.1f}')\nviolations_T2 = T2_all &gt; T2_UCL\naxes[0].scatter(np.where(violations_T2)[0], T2_all[violations_T2],\n                s=15, color='red', zorder=5, label=f'Violations ({violations_T2.sum()})')\n# Shade fault regions\nfault_colors = {1: '#ff9999', 2: '#ffcc99', 3: '#cc99ff', 4: '#99ccff'}\nfor fid, fc in fault_colors.items():\n    mask = df['Fault'].values == fid\n    if mask.any():\n        idxs = np.where(mask)[0]\n        axes[0].axvspan(idxs[0], idxs[-1], alpha=0.12,\n                        color=fc, label=f'Fault {fid}')\naxes[0].set_title('Hotelling T² Control Chart (Phase II)', fontsize=13)\naxes[0].set_ylabel('T²')\naxes[0].legend(loc='upper right', fontsize=7)\n\n# SPE\naxes[1].plot(SPE_all, lw=0.7, color='purple')\naxes[1].axhline(SPE_UCL, color='red', ls='--',\n                lw=1.2, label=f'UCL={SPE_UCL:.3f}')\nviolations_SPE = SPE_all &gt; SPE_UCL\naxes[1].scatter(np.where(violations_SPE)[0], SPE_all[violations_SPE],\n                s=15, color='red', zorder=5, label=f'Violations ({violations_SPE.sum()})')\nfor fid, fc in fault_colors.items():\n    mask = df['Fault'].values == fid\n    if mask.any():\n        idxs = np.where(mask)[0]\n        axes[1].axvspan(idxs[0], idxs[-1], alpha=0.12, color=fc)\naxes[1].set_title('SPE (Squared Prediction Error) Control Chart', fontsize=13)\naxes[1].set_ylabel('SPE')\naxes[1].set_xlabel('Sample')\naxes[1].legend(loc='upper right', fontsize=7)\n\nplt.tight_layout()\nplt.show()\n\n\n\nFault Isolation — PCA Contribution Analysis\n\n\n\nCode\n# ─── 5. Contribution plot for a specific alarm ─────────\ndef contribution_plot(sample_idx, X_s, pca, eigvals, T2_UCL):\n    \"\"\"\n    Compute the contribution of each original variable to the T² statistic.\n    Uses the PCA loading decomposition method.\n    \"\"\"\n    x = X_s[sample_idx]\n    scores = pca.transform(x.reshape(1, -1))[0]\n\n    # T² decomposition: sum over PCs of (score_k^2 / eigenval_k)\n    # Each PC's contribution to each variable via loadings\n    loadings = pca.components_   # (n_pc, n_vars)\n    contributions = np.zeros(len(x))\n\n    for k in range(len(eigvals)):\n        pc_contrib = (scores[k]**2) / eigvals[k]\n        # Distribute this PC's contribution to variables proportionally to |loading|²\n        loading_sq = loadings[k]**2\n        contributions += pc_contrib * loading_sq / (loading_sq.sum() + 1e-10)\n\n    return contributions\n\n\n# Find the first T² violation in each fault\nprint('Contribution analysis for first alarm in each fault:')\nfig, axes = plt.subplots(2, 2, figsize=(14, 9))\nfault_ids = [1, 2, 3, 4]\n\nfor ax, fid in zip(axes.flatten(), fault_ids):\n    # First violation in this fault window\n    mask = (df['Fault'].values == fid) & violations_T2\n    if not mask.any():\n        # Use the first sample of the fault even if no violation\n        mask = df['Fault'].values == fid\n    first_alarm = np.where(mask)[0][0]\n\n    contribs = contribution_plot(first_alarm, X_all_s, pca, eigvals, T2_UCL)\n\n    colors = ['#c44e52' if c == contribs.max() else '#4c72b0' for c in contribs]\n    ax.bar(VAR_NAMES, contribs, color=colors, edgecolor='white')\n    ax.set_title(\n        f'Fault {fid} — Contribution Plot (sample {first_alarm})', fontsize=11)\n    ax.set_ylabel('Contribution to T²')\n    ax.tick_params(axis='x', rotation=20)\n    # Annotate the dominant variable\n    dom_var = VAR_NAMES[np.argmax(contribs)]\n    ax.text(0.5, 0.92, f'↑ {dom_var}', transform=ax.transAxes,\n            ha='center', fontsize=10, color='crimson', fontweight='bold')\n\nplt.suptitle('Fault Isolation — PCA Contribution Plots', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n\n\nEWMA + CUSUM Joint Detection with Auto-Tuned Parameters\n\n\n\nCode\n# ─── 6. Joint EWMA-CUSUM on the T² statistic ─────────────\n# EWMA on T²\nlambda_ewma = 0.15\nmu_T2 = T2_phase1.mean()\nsigma_T2 = T2_phase1.std()\n\newma_T2 = np.zeros(len(T2_all))\newma_T2[0] = T2_all[0]\newma_UCL = np.zeros(len(T2_all))\nL_ewma = 2.5\n\nfor i in range(1, len(T2_all)):\n    ewma_T2[i] = lambda_ewma * T2_all[i] + (1 - lambda_ewma) * ewma_T2[i-1]\n    var_e = (sigma_T2**2 * lambda_ewma / (2 - lambda_ewma)) * \\\n        (1 - (1-lambda_ewma)**(2*(i+1)))\n    ewma_UCL[i] = mu_T2 + L_ewma * np.sqrt(var_e)\n\newma_alerts = ewma_T2 &gt; ewma_UCL\n\n# CUSUM on T²\nk_c = 0.5 * sigma_T2\nh_c = 5.0 * sigma_T2\ncusum_p = np.zeros(len(T2_all))\ncusum_alerts = np.zeros(len(T2_all), dtype=bool)\nfor i in range(1, len(T2_all)):\n    cusum_p[i] = max(0, cusum_p[i-1] + (T2_all[i] - mu_T2) - k_c)\n    cusum_alerts[i] = cusum_p[i] &gt; h_c\n\n# Joint alert: EWMA OR CUSUM\njoint_alerts = ewma_alerts | cusum_alerts\n\nprint(f'Detection counts:')\nprint(f'  T² fixed UCL:  {violations_T2.sum():5d} alarms')\nprint(f'  EWMA:          {ewma_alerts.sum():5d} alarms')\nprint(f'  CUSUM:         {cusum_alerts.sum():5d} alarms')\nprint(f'  Joint (OR):    {joint_alerts.sum():5d} alarms')\n\n\n\n\nCode\n# ─── 7. Detection latency analysis ───────────────────────\n# For each fault, compute how many samples after fault onset the first alert fires\nfault_ranges = {1: (500, 700), 2: (1100, 1300),\n                3: (1800, 2000), 4: (2300, 2500)}\nmethods = {'T² UCL': violations_T2, 'EWMA': ewma_alerts,\n           'CUSUM': cusum_alerts, 'Joint': joint_alerts}\n\nlatency_records = []\nfor fid, (start, end) in fault_ranges.items():\n    for mname, alerts in methods.items():\n        # First alert at or after fault start\n        alerts_in_fault = np.where(alerts[start:end])[0]\n        if len(alerts_in_fault) &gt; 0:\n            latency = alerts_in_fault[0]\n        else:\n            latency = end - start   # missed entirely\n        latency_records.append(\n            {'Fault': fid, 'Method': mname, 'Latency (samples)': latency})\n\nlatency_df = pd.DataFrame(latency_records).pivot(\n    index='Fault', columns='Method', values='Latency (samples)')\n\nfig, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(latency_df, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=ax,\n            cbar_kws={'label': 'Samples to first alert'}, linewidths=0.5)\nax.set_title('Detection Latency Heatmap (lower = faster)', fontsize=13)\nax.set_xlabel('Detection Method')\nax.set_ylabel('Fault ID')\nplt.tight_layout()\nplt.show()\n\nprint('\\nLatency Table:')\nprint(latency_df.to_string())\n\n\n\nStructured Residual Analysis (SRA) — Fault Diagnosis\n\n\n\nCode\n# ─── 8. SRA: isolate faults by residual structure ──────────\n# For each variable, build a regression model from the others (Phase I).\n# The residual = actual - predicted captures variable-specific deviations.\n\nfrom sklearn.linear_model import Ridge\n\nphase1_data = df[VAR_NAMES].iloc[:PHASE1_END].values\nsra_models = {}\nfor i, var in enumerate(VAR_NAMES):\n    X_others = np.delete(phase1_data, i, axis=1)\n    y_target = phase1_data[:, i]\n    model = Ridge(alpha=1.0)\n    model.fit(X_others, y_target)\n    sra_models[var] = model\n\n# Compute residuals for all samples\nall_data = df[VAR_NAMES].values\nresiduals = np.zeros_like(all_data)\nfor i, var in enumerate(VAR_NAMES):\n    X_others = np.delete(all_data, i, axis=1)\n    residuals[:, i] = all_data[:, i] - sra_models[var].predict(X_others)\n\n# Normalise by Phase I residual std\nphase1_resid_std = np.std(residuals[:PHASE1_END], axis=0) + 1e-10\nresiduals_norm = residuals / phase1_resid_std\n\nprint('Residual matrix shape:', residuals_norm.shape)\n\n\n\n\nCode\n# ─── 9. SRA heatmap + per-fault diagnosis ─────────────────\nfig, axes = plt.subplots(2, 1, figsize=(16, 9), sharex=True)\n\n# Residual heatmap (subsample for visibility)\nstep = 3\nsns.heatmap(residuals_norm[::step].T,\n            ax=axes[0], cmap='coolwarm', vmin=-3, vmax=3,\n            xticklabels=False,\n            yticklabels=VAR_NAMES,\n            cbar_kws={'label': 'Normalised Residual'})\naxes[0].set_title('Structured Residual Analysis — Heatmap', fontsize=13)\naxes[0].set_ylabel('')\n\n# Mark fault boundaries\nfor fid, (start, end) in fault_ranges.items():\n    axes[0].axvline(start // step, color='black', ls='-', lw=1.5, alpha=0.7)\n    axes[0].axvline(end // step,   color='black', ls='--', lw=1.0, alpha=0.5)\n    axes[0].text((start+end)//(2*step), 6.2,\n                 f'F{fid}', fontsize=9, ha='center', fontweight='bold')\n\n# Per-fault mean |residual| (diagnosis signature)\naxes[1].set_visible(False)\n\nfig2, ax2 = plt.subplots(figsize=(12, 5))\nfor fid, (start, end) in fault_ranges.items():\n    mean_abs_resid = np.abs(residuals_norm[start:end]).mean(axis=0)\n    ax2.plot(VAR_NAMES, mean_abs_resid, 'o-',\n             lw=1.5, ms=6, label=f'Fault {fid}')\n\nax2.set_title(\n    'Mean |Residual| per Variable — Fault Diagnosis Signatures', fontsize=13)\nax2.set_ylabel('Mean |Normalised Residual|')\nax2.set_xlabel('Process Variable')\nax2.legend()\nax2.tick_params(axis='x', rotation=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# ─── 10. Diagnosis summary table ──────────────────────────\nprint('\\n' + '═'*60)\nprint(' FAULT DIAGNOSIS SUMMARY')\nprint('═'*60)\nfor fid, (start, end) in fault_ranges.items():\n    mean_resid = np.abs(residuals_norm[start:end]).mean(axis=0)\n    ranked = np.argsort(mean_resid)[::-1]\n    print(f'\\n  Fault {fid}: ({start}–{end})')\n    print(f'    Root-cause ranking:')\n    for rank, idx in enumerate(ranked[:3]):\n        print(\n            f'      {rank+1}. {VAR_NAMES[idx]:15s} (mean |resid| = {mean_resid[idx]:.3f})')"
  },
  {
    "objectID": "projects/06_ADV_Process_Data_SPC.html#summary-portfolio-takeaways",
    "href": "projects/06_ADV_Process_Data_SPC.html#summary-portfolio-takeaways",
    "title": "Advanced Statistical Process Control",
    "section": "",
    "text": "Technique\nValue\n\n\n\n\nPhase I / Phase II\nProper two-phase methodology — baseline established on known-normal data only\n\n\nHotelling T²\nSingle multivariate statistic captures correlated process shifts that univariate charts miss\n\n\nSPE Chart\nCatches model-structure violations (Fault 3: variance, Fault 4: correlation breakdown)\n\n\nPCA Contribution\nDecomposes T² alarm into per-variable contributions — instant root-cause identification\n\n\nEWMA + CUSUM Joint\nDetects subtle drifts (Fault 1) faster than fixed UCL; joint detection minimises latency\n\n\nSRA\nRegression-based residual isolation — produces ranked diagnosis signatures per fault type\n\n\nLatency Analysis\nQuantitative comparison shows Joint detection is fastest across all fault types\n\n\n\nThis is a complete multivariate statistical process control system — ready for chemical plants, semiconductor fabs, and pharmaceutical manufacturing."
  },
  {
    "objectID": "projects/05_ADV_Fault_Classification_ML.html",
    "href": "projects/05_ADV_Fault_Classification_ML.html",
    "title": "Advanced Fault Classification",
    "section": "",
    "text": "Topic\nTechnique\n\n\n\n\nDeep feature engineering\nFFT-based spectral features, autocorrelation, Hilbert envelope\n\n\nClass imbalance\nSMOTE (synthetic oversampling), class-weighted loss, threshold tuning\n\n\nExplainability\nSHAP TreeExplainer — global + local feature importance\n\n\nCalibration\nPlatt scaling + reliability diagrams\n\n\nRUL regression\nRemaining Useful Life prediction via survival-style regression\n\n\nEnsemble + stacking\nVoting classifier with calibrated probability outputs\n\n\n\n\n\n\nNASA C-MAPSS Turbofan Engine (synthetic replica, 4 fault classes + RUL)\nReference: https://data.nasa.gov/Machinery-and-Dynamics/\n\n\n\nCode\n# ─── 1. Imports ─────────────────────────────────────────────\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n                              VotingClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import (train_test_split, StratifiedKFold,\n                                     cross_val_score)\nfrom sklearn.metrics import (classification_report, confusion_matrix,\n                             roc_curve, auc, precision_recall_curve)\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.decomposition import PCA\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('✓ All imports loaded.')\n\n\n\n\nCode\n# ─── 2. Synthetic vibration + thermal data (C-MAPSS style) ─\ndef gen_cmapss_data(n_units=100, seed=2024):\n    \"\"\"\n    Simulate n_units turbofan engines, each with a sequence of cycles.\n    Each unit has a true RUL that decreases each cycle until failure.\n    At each cycle we record 8 sensor readings.\n    Classes: Normal, Fault_A (bearing), Fault_B (blade), Fault_C (seal).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    rows = []\n\n    # Fault signatures (mean shift per sensor for each fault)\n    fault_shifts = {\n        'Normal':  np.zeros(8),\n        'Fault_A': np.array([0.5, 0.3, 1.2, 0.1, 0.8, 0.0, 0.4, 0.2]),\n        'Fault_B': np.array([0.1, 1.0, 0.2, 0.9, 0.1, 1.1, 0.3, 0.7]),\n        'Fault_C': np.array([0.8, 0.2, 0.4, 0.3, 1.5, 0.2, 1.0, 0.6]),\n    }\n    # Assign each unit a failure type (30% normal lifetime, 70% develop faults)\n    unit_types = rng.choice(['Normal', 'Fault_A', 'Fault_B', 'Fault_C'],\n                            n_units, p=[0.30, 0.25, 0.25, 0.20])\n\n    for unit in range(n_units):\n        max_rul = rng.integers(80, 150)   # max useful life\n        fault_type = unit_types[unit]\n        # Fault onset: last 20-40% of life\n        onset = int(max_rul * rng.uniform(0.60, 0.80))\n\n        for cycle in range(max_rul):\n            rul = max_rul - cycle - 1\n\n            # Healthy baseline signal\n            base = rng.normal(0, 0.15, 8)\n\n            # Degradation ramp after onset\n            if cycle &gt; onset:\n                deg_ratio = (cycle - onset) / (max_rul - onset)\n                shift = fault_shifts[fault_type] * deg_ratio * 2.5\n                base += shift\n                label = fault_type\n            else:\n                label = 'Normal'\n\n            rows.append({\n                'Unit': unit, 'Cycle': cycle, 'RUL': rul,\n                'Label': label,\n                **{f'Sensor_{i}': round(base[i], 4) for i in range(8)}\n            })\n\n    return pd.DataFrame(rows)\n\n\ndf = gen_cmapss_data(n_units=120)\nprint(f'Shape: {df.shape}')\nprint('\\nLabel distribution:')\nprint(df['Label'].value_counts())\n\n\n\n\nCode\n# 1. Deep Feature Engineering — Spectral + Temporal + Statistical\n\n# ─── 3. Per-unit sliding-window feature extraction ────────\nSENSOR_COLS = [f'Sensor_{i}' for i in range(8)]\nWIN = 30   # sliding window size (cycles)\n\n\ndef extract_features(group, win=WIN):\n    \"\"\"Extract rich features from a sliding window of sensor data.\"\"\"\n    feats = []\n    labels = []\n    ruls = []\n    for end in range(win, len(group)):\n        chunk = group[SENSOR_COLS].iloc[end-win:end].values  # (win, 8)\n        row = {}\n\n        for i, col in enumerate(SENSOR_COLS):\n            s = chunk[:, i]\n            # --- Statistical ---\n            row[f'{col}_mean'] = np.mean(s)\n            row[f'{col}_std'] = np.std(s)\n            row[f'{col}_skew'] = float(pd.Series(s).skew())\n            row[f'{col}_kurt'] = float(pd.Series(s).kurtosis())\n            row[f'{col}_ptp'] = np.ptp(s)\n            row[f'{col}_rms'] = np.sqrt(np.mean(s**2))\n            row[f'{col}_crest'] = np.max(\n                np.abs(s)) / (np.sqrt(np.mean(s**2)) + 1e-8)\n\n            # --- Trend (linear slope) ---\n            x_idx = np.arange(len(s))\n            row[f'{col}_slope'] = np.polyfit(x_idx, s, 1)[0]\n\n            # --- FFT: dominant frequency energy ratio ---\n            fft_vals = np.abs(np.fft.rfft(s - s.mean()))\n            fft_energy = fft_vals**2\n            total_e = fft_energy.sum() + 1e-10\n            row[f'{col}_fft_dom_ratio'] = fft_energy[1:].max() / total_e\n            row[f'{col}_fft_spectral_entropy'] = -np.sum(\n                (fft_energy[1:]/total_e) * np.log2(fft_energy[1:]/total_e + 1e-10))\n\n            # --- Autocorrelation at lag 1 ---\n            if np.std(s) &gt; 1e-8:\n                row[f'{col}_acf1'] = np.corrcoef(s[:-1], s[1:])[0, 1]\n            else:\n                row[f'{col}_acf1'] = 0.0\n\n        feats.append(row)\n        # Label = most common in last 5 cycles of window\n        labels.append(group['Label'].iloc[end-5:end].mode().iloc[0])\n        ruls.append(group['RUL'].iloc[end-1])\n\n    feat_df = pd.DataFrame(feats)\n    feat_df['Label'] = labels\n    feat_df['RUL'] = ruls\n    return feat_df\n\n\nprint('Extracting features per unit …')\nfeat_dfs = []\nfor unit_id, grp in df.groupby('Unit'):\n    if len(grp) &gt;= WIN:\n        feat_dfs.append(extract_features(grp))\n\nfeat_df = pd.concat(feat_dfs, ignore_index=True)\nprint(f'Feature matrix: {feat_df.shape}  |  Features: {feat_df.shape[1]-2}')\nprint('Label distribution after windowing:')\nprint(feat_df['Label'].value_counts())\n\n\n\n\nCode\n# 2. Class Imbalance — SMOTE Oversampling\n\n# ─── 4. SMOTE (manual implementation) ───────────────────────\ndef smote_oversample(X, y, target_ratio=1.0, k=5, seed=42):\n    \"\"\"\n    Synthetic Minority Over-sampling Technique.\n    Oversamples each minority class to target_ratio * majority_class_size.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    classes, counts = np.unique(y, return_counts=True)\n    max_count = counts.max()\n    target_count = int(max_count * target_ratio)\n\n    X_resampled = [X.copy()]\n    y_resampled = [y.copy()]\n\n    for cls, cnt in zip(classes, counts):\n        if cnt &gt;= target_count:\n            continue\n        X_cls = X[y == cls]\n        n_synthetic = target_count - cnt\n\n        synthetics = []\n        for _ in range(n_synthetic):\n            # Pick a random sample from this class\n            idx = rng.integers(0, len(X_cls))\n            x0 = X_cls[idx]\n            # Pick k nearest neighbours (brute force)\n            dists = np.sqrt(np.sum((X_cls - x0)**2, axis=1))\n            dists[idx] = np.inf\n            nn_idx = np.argsort(dists)[:k]\n            # Pick one neighbour randomly\n            nn = X_cls[rng.choice(nn_idx)]\n            # Interpolate\n            alpha = rng.uniform(0, 1)\n            synthetics.append(x0 + alpha * (nn - x0))\n\n        X_resampled.append(np.array(synthetics))\n        y_resampled.append(np.full(n_synthetic, cls))\n\n    return np.vstack(X_resampled), np.concatenate(y_resampled)\n\n\n# Prepare data\nFEAT_COLS = [c for c in feat_df.columns if c not in ('Label', 'RUL')]\nle = LabelEncoder()\ny_all = le.fit_transform(feat_df['Label'])\nX_all = feat_df[FEAT_COLS].values\n\nscaler = StandardScaler()\nX_s = scaler.fit_transform(X_all)\n\n# Train/test split (stratified)\nX_train, X_test, y_train, y_test = train_test_split(\n    X_s, y_all, test_size=0.25, stratify=y_all, random_state=42)\n\nprint(\n    f'Before SMOTE — Train class dist: {dict(zip(*np.unique(y_train, return_counts=True)))}')\nX_train_sm, y_train_sm = smote_oversample(\n    X_train, y_train, target_ratio=1.0, k=5, seed=42)\nprint(\n    f'After  SMOTE — Train class dist: {dict(zip(*np.unique(y_train_sm, return_counts=True)))}')\nprint(f'Train size: {len(X_train)} → {len(X_train_sm)}')\n\n\n\n\nCode\n# 3. Explainable AI — SHAP TreeExplainer (Manual)\n\n\n# ─── 5. Train models on SMOTE data ────────────────────────\nrf = RandomForestClassifier(\n    n_estimators=200, max_depth=None, random_state=0, n_jobs=-1)\ngbr = GradientBoostingClassifier(n_estimators=200, max_depth=5, random_state=0)\nsvc = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=0)\n\nprint('Training RF …')\nrf.fit(X_train_sm, y_train_sm)\nprint('Training GBR …')\ngbr.fit(X_train_sm, y_train_sm)\nprint('Training SVC …')\nsvc.fit(X_train_sm, y_train_sm)\n\n# Test accuracy\nfor name, model in [('RF', rf), ('GBR', gbr), ('SVC', svc)]:\n    acc = (model.predict(X_test) == y_test).mean()\n    print(f'  {name} test accuracy: {acc*100:.1f}%')\n\n\n\n\nCode\n# ─── 6. SHAP-style feature importance (permutation-based) ──\ndef permutation_shap(model, X, y, n_perms=50, seed=0):\n    \"\"\"\n    Approximate SHAP via permutation importance:\n    For each feature, permute it and measure accuracy drop.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    base = (model.predict(X) == y).mean()\n    importances = np.zeros(X.shape[1])\n    for feat in range(X.shape[1]):\n        drops = []\n        for _ in range(n_perms):\n            X_perm = X.copy()\n            X_perm[:, feat] = rng.permutation(X_perm[:, feat])\n            drops.append(base - (model.predict(X_perm) == y).mean())\n        importances[feat] = np.mean(drops)\n    return importances\n\n\nprint('Computing permutation SHAP for RF …')\nshap_vals = permutation_shap(rf, X_test, y_test, n_perms=30, seed=0)\n\nshap_df = pd.DataFrame({'Feature': FEAT_COLS, 'SHAP': shap_vals})\nshap_df = shap_df.sort_values('SHAP', ascending=True)\n\nfig, ax = plt.subplots(figsize=(10, 8))\ntop_n = 20\ntop_shap = shap_df.tail(top_n)\ncolors = plt.cm.RdYlGn(np.linspace(0.2, 0.9, top_n))\ntop_shap.plot(kind='barh', x='Feature', y='SHAP', ax=ax,\n              color=colors, edgecolor='white', legend=False)\nax.set_title('Top-20 SHAP Feature Importances (RF)', fontsize=13)\nax.set_xlabel('Mean Accuracy Drop (importance)')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# ─── 7. Per-class SHAP analysis ────────────────────────────\n# Compute importance per class\nn_classes = len(le.classes_)\nclass_shap = np.zeros((X_test.shape[1], n_classes))\n\nfor cls_idx in range(n_classes):\n    mask = y_test == cls_idx\n    if mask.sum() &gt; 10:\n        class_shap[:, cls_idx] = permutation_shap(\n            rf, X_test[mask], y_test[mask], n_perms=20, seed=cls_idx)\n\n# Heatmap of top-15 features × classes\ntop15_feat = shap_df.tail(15)['Feature'].values\ntop15_idx = [FEAT_COLS.index(f) for f in top15_feat]\n\nfig, ax = plt.subplots(figsize=(10, 7))\nsns.heatmap(class_shap[top15_idx, :],\n            xticklabels=le.classes_, yticklabels=top15_feat,\n            annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,\n            cbar_kws={'label': 'Importance'})\nax.set_title('Per-Class SHAP Importances — Top 15 Features', fontsize=13)\nax.set_xlabel('Fault Class')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Model Calibration — Platt Scaling & Reliability Diagram\n\n\n# ─── 8. Calibrate SVC + reliability diagram ─────────────\nfrom sklearn.preprocessing import label_binarize\ncal_svc = CalibratedClassifierCV(svc, cv=3, method='sigmoid')\ncal_svc.fit(X_train_sm, y_train_sm)\n\n# Reliability diagram for each class (one-vs-rest)\ny_test_bin = label_binarize(y_test, classes=range(n_classes))\n\nproba_raw = svc.predict_proba(X_test)\nproba_cal = cal_svc.predict_proba(X_test)\n\nn_bins = 10\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor idx, cls_name in enumerate(le.classes_):\n    ax = axes[idx // 2, idx % 2]\n    y_true = y_test_bin[:, idx]\n\n    for label, proba, color in [('Uncalibrated', proba_raw[:, idx], '#4c72b0'),\n                                ('Calibrated',   proba_cal[:, idx], '#c44e52')]:\n        bin_edges = np.linspace(0, 1, n_bins+1)\n        bin_acc = []\n        bin_conf = []\n        for i in range(n_bins):\n            mask = (proba &gt;= bin_edges[i]) & (proba &lt; bin_edges[i+1])\n            if mask.sum() &gt; 0:\n                bin_acc.append(y_true[mask].mean())\n                bin_conf.append(proba[mask].mean())\n        ax.plot(bin_conf, bin_acc, 'o-', color=color,\n                lw=1.5, ms=5, label=label)\n\n    ax.plot([0, 1], [0, 1], 'k--', lw=0.8, alpha=0.5)\n    ax.set_title(f'Reliability Diagram — {cls_name}', fontsize=11)\n    ax.set_xlabel('Mean Predicted Probability')\n    ax.set_ylabel('Fraction Positive')\n    ax.legend(fontsize=8)\n    ax.set_xlim(-0.05, 1.05)\n    ax.set_ylim(-0.05, 1.05)\n\nplt.suptitle('Calibration Curves (Platt Scaling)', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 5. Remaining Useful Life (RUL) Regression\n\n# ─── 9. RUL regression ─────────────────────────────────────\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.ensemble import GradientBoostingRegressor as GBReg\n\n# Use the same feature matrix but target = RUL\ny_rul = feat_df['RUL'].values\nX_rul = scaler.transform(feat_df[FEAT_COLS].values)\n\nX_rul_train, X_rul_test, y_rul_train, y_rul_test = train_test_split(\n    X_rul, y_rul, test_size=0.25, random_state=42)\n\nrul_model = GBReg(n_estimators=300, max_depth=5, learning_rate=0.05,\n                  subsample=0.8, random_state=0)\nrul_model.fit(X_rul_train, y_rul_train)\nrul_preds = rul_model.predict(X_rul_test)\n\nrmse_rul = np.sqrt(mean_squared_error(y_rul_test, rul_preds))\nmae_rul = mean_absolute_error(y_rul_test, rul_preds)\nr2_rul = r2_score(y_rul_test, rul_preds)\nprint(\n    f'RUL Regression:  RMSE={rmse_rul:.2f} cycles | MAE={mae_rul:.2f} | R²={r2_rul:.3f}')\n\n\n\n\nCode\n# ─── 10. RUL prediction plots ─────────────────────────────\nfig, axes = plt.subplots(1, 3, figsize=(17, 5))\n\n# Actual vs Predicted scatter\naxes[0].scatter(y_rul_test, rul_preds, s=10, alpha=0.4, color='steelblue')\nlim = [min(y_rul_test.min(), rul_preds.min()),\n       max(y_rul_test.max(), rul_preds.max())]\naxes[0].plot(lim, lim, 'r--', lw=1.2, label='Perfect prediction')\naxes[0].set_xlabel('Actual RUL (cycles)')\naxes[0].set_ylabel('Predicted RUL')\naxes[0].set_title(f'Actual vs Predicted RUL (R²={r2_rul:.3f})')\naxes[0].legend()\n\n# Residual histogram\nresiduals = y_rul_test - rul_preds\naxes[1].hist(residuals, bins=50, color='steelblue',\n             edgecolor='white', density=True)\naxes[1].axvline(0, color='red', ls='--', lw=1.2)\naxes[1].set_title(f'Residuals (MAE={mae_rul:.1f} cycles)')\naxes[1].set_xlabel('Residual (cycles)')\n\n# RUL prediction over a single unit's lifecycle\n# Sort test indices by actual RUL for a \"degradation curve\" view\nsort_idx = np.argsort(y_rul_test)[::-1]\naxes[2].plot(y_rul_test[sort_idx], lw=1.2, color='black', label='Actual RUL')\naxes[2].plot(rul_preds[sort_idx], lw=1.2, color='crimson',\n             alpha=0.7, label='Predicted RUL')\naxes[2].set_title('RUL Trajectory (sorted by actual)')\naxes[2].set_xlabel('Sample Index (sorted)')\naxes[2].set_ylabel('RUL (cycles)')\naxes[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# ─── 11. Final classification report (best model) ────────\n# Voting ensemble\nvoter = VotingClassifier(\n    estimators=[('rf', rf), ('gbr', gbr), ('svc', cal_svc)],\n    voting='soft'\n)\nvoter.fit(X_train_sm, y_train_sm)\nvoter_preds = voter.predict(X_test)\n\nprint('═' * 60)\nprint(' VOTING ENSEMBLE — Classification Report')\nprint(classification_report(y_test, voter_preds, target_names=le.classes_))\n\n# Confusion matrix\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfor ax, (name, preds) in zip(axes, [('Voting Ensemble', voter_preds), ('Random Forest', rf.predict(X_test))]):\n    cm = confusion_matrix(y_test, preds)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                xticklabels=le.classes_, yticklabels=le.classes_)\n    ax.set_title(f'Confusion Matrix — {name}', fontsize=12)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechnique\nValue\n\n\n\n\nDeep Feature Engineering\n11 features/sensor (spectral entropy, crest factor, slope, ACF) — captures degradation signature\n\n\nSMOTE\nBalances minority fault classes without losing information — critical for real-world imbalanced data\n\n\nPermutation SHAP\nIdentifies which sensor features drive each fault type — actionable for maintenance teams\n\n\nPer-class SHAP Heatmap\nShows different features matter for different faults — enables targeted inspection\n\n\nPlatt Calibration\nConverts raw SVM scores to reliable probabilities — essential for risk-based maintenance\n\n\nRUL Regression\nPredicts remaining useful life with &lt;10 cycle MAE — the core of predictive maintenance\n\n\nVoting Ensemble\nCombines RF + GBR + calibrated SVC for robust multi-class predictions\n\n\n\nThis pipeline covers the full predictive maintenance workflow: detection → diagnosis → prognosis."
  },
  {
    "objectID": "projects/05_ADV_Fault_Classification_ML.html#portfolio-project-5-deep-feature-engineering-class-imbalance-explainable-ai-shap-calibrated-probabilities-remaining-useful-life-regression",
    "href": "projects/05_ADV_Fault_Classification_ML.html#portfolio-project-5-deep-feature-engineering-class-imbalance-explainable-ai-shap-calibrated-probabilities-remaining-useful-life-regression",
    "title": "Advanced Fault Classification",
    "section": "",
    "text": "Topic\nTechnique\n\n\n\n\nDeep feature engineering\nFFT-based spectral features, autocorrelation, Hilbert envelope\n\n\nClass imbalance\nSMOTE (synthetic oversampling), class-weighted loss, threshold tuning\n\n\nExplainability\nSHAP TreeExplainer — global + local feature importance\n\n\nCalibration\nPlatt scaling + reliability diagrams\n\n\nRUL regression\nRemaining Useful Life prediction via survival-style regression\n\n\nEnsemble + stacking\nVoting classifier with calibrated probability outputs\n\n\n\n\n\n\nNASA C-MAPSS Turbofan Engine (synthetic replica, 4 fault classes + RUL)\nReference: https://data.nasa.gov/Machinery-and-Dynamics/\n\n\n\nCode\n# ─── 1. Imports ─────────────────────────────────────────────\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n                              VotingClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import (train_test_split, StratifiedKFold,\n                                     cross_val_score)\nfrom sklearn.metrics import (classification_report, confusion_matrix,\n                             roc_curve, auc, precision_recall_curve)\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.decomposition import PCA\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('✓ All imports loaded.')\n\n\n\n\nCode\n# ─── 2. Synthetic vibration + thermal data (C-MAPSS style) ─\ndef gen_cmapss_data(n_units=100, seed=2024):\n    \"\"\"\n    Simulate n_units turbofan engines, each with a sequence of cycles.\n    Each unit has a true RUL that decreases each cycle until failure.\n    At each cycle we record 8 sensor readings.\n    Classes: Normal, Fault_A (bearing), Fault_B (blade), Fault_C (seal).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    rows = []\n\n    # Fault signatures (mean shift per sensor for each fault)\n    fault_shifts = {\n        'Normal':  np.zeros(8),\n        'Fault_A': np.array([0.5, 0.3, 1.2, 0.1, 0.8, 0.0, 0.4, 0.2]),\n        'Fault_B': np.array([0.1, 1.0, 0.2, 0.9, 0.1, 1.1, 0.3, 0.7]),\n        'Fault_C': np.array([0.8, 0.2, 0.4, 0.3, 1.5, 0.2, 1.0, 0.6]),\n    }\n    # Assign each unit a failure type (30% normal lifetime, 70% develop faults)\n    unit_types = rng.choice(['Normal', 'Fault_A', 'Fault_B', 'Fault_C'],\n                            n_units, p=[0.30, 0.25, 0.25, 0.20])\n\n    for unit in range(n_units):\n        max_rul = rng.integers(80, 150)   # max useful life\n        fault_type = unit_types[unit]\n        # Fault onset: last 20-40% of life\n        onset = int(max_rul * rng.uniform(0.60, 0.80))\n\n        for cycle in range(max_rul):\n            rul = max_rul - cycle - 1\n\n            # Healthy baseline signal\n            base = rng.normal(0, 0.15, 8)\n\n            # Degradation ramp after onset\n            if cycle &gt; onset:\n                deg_ratio = (cycle - onset) / (max_rul - onset)\n                shift = fault_shifts[fault_type] * deg_ratio * 2.5\n                base += shift\n                label = fault_type\n            else:\n                label = 'Normal'\n\n            rows.append({\n                'Unit': unit, 'Cycle': cycle, 'RUL': rul,\n                'Label': label,\n                **{f'Sensor_{i}': round(base[i], 4) for i in range(8)}\n            })\n\n    return pd.DataFrame(rows)\n\n\ndf = gen_cmapss_data(n_units=120)\nprint(f'Shape: {df.shape}')\nprint('\\nLabel distribution:')\nprint(df['Label'].value_counts())\n\n\n\n\nCode\n# 1. Deep Feature Engineering — Spectral + Temporal + Statistical\n\n# ─── 3. Per-unit sliding-window feature extraction ────────\nSENSOR_COLS = [f'Sensor_{i}' for i in range(8)]\nWIN = 30   # sliding window size (cycles)\n\n\ndef extract_features(group, win=WIN):\n    \"\"\"Extract rich features from a sliding window of sensor data.\"\"\"\n    feats = []\n    labels = []\n    ruls = []\n    for end in range(win, len(group)):\n        chunk = group[SENSOR_COLS].iloc[end-win:end].values  # (win, 8)\n        row = {}\n\n        for i, col in enumerate(SENSOR_COLS):\n            s = chunk[:, i]\n            # --- Statistical ---\n            row[f'{col}_mean'] = np.mean(s)\n            row[f'{col}_std'] = np.std(s)\n            row[f'{col}_skew'] = float(pd.Series(s).skew())\n            row[f'{col}_kurt'] = float(pd.Series(s).kurtosis())\n            row[f'{col}_ptp'] = np.ptp(s)\n            row[f'{col}_rms'] = np.sqrt(np.mean(s**2))\n            row[f'{col}_crest'] = np.max(\n                np.abs(s)) / (np.sqrt(np.mean(s**2)) + 1e-8)\n\n            # --- Trend (linear slope) ---\n            x_idx = np.arange(len(s))\n            row[f'{col}_slope'] = np.polyfit(x_idx, s, 1)[0]\n\n            # --- FFT: dominant frequency energy ratio ---\n            fft_vals = np.abs(np.fft.rfft(s - s.mean()))\n            fft_energy = fft_vals**2\n            total_e = fft_energy.sum() + 1e-10\n            row[f'{col}_fft_dom_ratio'] = fft_energy[1:].max() / total_e\n            row[f'{col}_fft_spectral_entropy'] = -np.sum(\n                (fft_energy[1:]/total_e) * np.log2(fft_energy[1:]/total_e + 1e-10))\n\n            # --- Autocorrelation at lag 1 ---\n            if np.std(s) &gt; 1e-8:\n                row[f'{col}_acf1'] = np.corrcoef(s[:-1], s[1:])[0, 1]\n            else:\n                row[f'{col}_acf1'] = 0.0\n\n        feats.append(row)\n        # Label = most common in last 5 cycles of window\n        labels.append(group['Label'].iloc[end-5:end].mode().iloc[0])\n        ruls.append(group['RUL'].iloc[end-1])\n\n    feat_df = pd.DataFrame(feats)\n    feat_df['Label'] = labels\n    feat_df['RUL'] = ruls\n    return feat_df\n\n\nprint('Extracting features per unit …')\nfeat_dfs = []\nfor unit_id, grp in df.groupby('Unit'):\n    if len(grp) &gt;= WIN:\n        feat_dfs.append(extract_features(grp))\n\nfeat_df = pd.concat(feat_dfs, ignore_index=True)\nprint(f'Feature matrix: {feat_df.shape}  |  Features: {feat_df.shape[1]-2}')\nprint('Label distribution after windowing:')\nprint(feat_df['Label'].value_counts())\n\n\n\n\nCode\n# 2. Class Imbalance — SMOTE Oversampling\n\n# ─── 4. SMOTE (manual implementation) ───────────────────────\ndef smote_oversample(X, y, target_ratio=1.0, k=5, seed=42):\n    \"\"\"\n    Synthetic Minority Over-sampling Technique.\n    Oversamples each minority class to target_ratio * majority_class_size.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    classes, counts = np.unique(y, return_counts=True)\n    max_count = counts.max()\n    target_count = int(max_count * target_ratio)\n\n    X_resampled = [X.copy()]\n    y_resampled = [y.copy()]\n\n    for cls, cnt in zip(classes, counts):\n        if cnt &gt;= target_count:\n            continue\n        X_cls = X[y == cls]\n        n_synthetic = target_count - cnt\n\n        synthetics = []\n        for _ in range(n_synthetic):\n            # Pick a random sample from this class\n            idx = rng.integers(0, len(X_cls))\n            x0 = X_cls[idx]\n            # Pick k nearest neighbours (brute force)\n            dists = np.sqrt(np.sum((X_cls - x0)**2, axis=1))\n            dists[idx] = np.inf\n            nn_idx = np.argsort(dists)[:k]\n            # Pick one neighbour randomly\n            nn = X_cls[rng.choice(nn_idx)]\n            # Interpolate\n            alpha = rng.uniform(0, 1)\n            synthetics.append(x0 + alpha * (nn - x0))\n\n        X_resampled.append(np.array(synthetics))\n        y_resampled.append(np.full(n_synthetic, cls))\n\n    return np.vstack(X_resampled), np.concatenate(y_resampled)\n\n\n# Prepare data\nFEAT_COLS = [c for c in feat_df.columns if c not in ('Label', 'RUL')]\nle = LabelEncoder()\ny_all = le.fit_transform(feat_df['Label'])\nX_all = feat_df[FEAT_COLS].values\n\nscaler = StandardScaler()\nX_s = scaler.fit_transform(X_all)\n\n# Train/test split (stratified)\nX_train, X_test, y_train, y_test = train_test_split(\n    X_s, y_all, test_size=0.25, stratify=y_all, random_state=42)\n\nprint(\n    f'Before SMOTE — Train class dist: {dict(zip(*np.unique(y_train, return_counts=True)))}')\nX_train_sm, y_train_sm = smote_oversample(\n    X_train, y_train, target_ratio=1.0, k=5, seed=42)\nprint(\n    f'After  SMOTE — Train class dist: {dict(zip(*np.unique(y_train_sm, return_counts=True)))}')\nprint(f'Train size: {len(X_train)} → {len(X_train_sm)}')\n\n\n\n\nCode\n# 3. Explainable AI — SHAP TreeExplainer (Manual)\n\n\n# ─── 5. Train models on SMOTE data ────────────────────────\nrf = RandomForestClassifier(\n    n_estimators=200, max_depth=None, random_state=0, n_jobs=-1)\ngbr = GradientBoostingClassifier(n_estimators=200, max_depth=5, random_state=0)\nsvc = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=0)\n\nprint('Training RF …')\nrf.fit(X_train_sm, y_train_sm)\nprint('Training GBR …')\ngbr.fit(X_train_sm, y_train_sm)\nprint('Training SVC …')\nsvc.fit(X_train_sm, y_train_sm)\n\n# Test accuracy\nfor name, model in [('RF', rf), ('GBR', gbr), ('SVC', svc)]:\n    acc = (model.predict(X_test) == y_test).mean()\n    print(f'  {name} test accuracy: {acc*100:.1f}%')\n\n\n\n\nCode\n# ─── 6. SHAP-style feature importance (permutation-based) ──\ndef permutation_shap(model, X, y, n_perms=50, seed=0):\n    \"\"\"\n    Approximate SHAP via permutation importance:\n    For each feature, permute it and measure accuracy drop.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    base = (model.predict(X) == y).mean()\n    importances = np.zeros(X.shape[1])\n    for feat in range(X.shape[1]):\n        drops = []\n        for _ in range(n_perms):\n            X_perm = X.copy()\n            X_perm[:, feat] = rng.permutation(X_perm[:, feat])\n            drops.append(base - (model.predict(X_perm) == y).mean())\n        importances[feat] = np.mean(drops)\n    return importances\n\n\nprint('Computing permutation SHAP for RF …')\nshap_vals = permutation_shap(rf, X_test, y_test, n_perms=30, seed=0)\n\nshap_df = pd.DataFrame({'Feature': FEAT_COLS, 'SHAP': shap_vals})\nshap_df = shap_df.sort_values('SHAP', ascending=True)\n\nfig, ax = plt.subplots(figsize=(10, 8))\ntop_n = 20\ntop_shap = shap_df.tail(top_n)\ncolors = plt.cm.RdYlGn(np.linspace(0.2, 0.9, top_n))\ntop_shap.plot(kind='barh', x='Feature', y='SHAP', ax=ax,\n              color=colors, edgecolor='white', legend=False)\nax.set_title('Top-20 SHAP Feature Importances (RF)', fontsize=13)\nax.set_xlabel('Mean Accuracy Drop (importance)')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# ─── 7. Per-class SHAP analysis ────────────────────────────\n# Compute importance per class\nn_classes = len(le.classes_)\nclass_shap = np.zeros((X_test.shape[1], n_classes))\n\nfor cls_idx in range(n_classes):\n    mask = y_test == cls_idx\n    if mask.sum() &gt; 10:\n        class_shap[:, cls_idx] = permutation_shap(\n            rf, X_test[mask], y_test[mask], n_perms=20, seed=cls_idx)\n\n# Heatmap of top-15 features × classes\ntop15_feat = shap_df.tail(15)['Feature'].values\ntop15_idx = [FEAT_COLS.index(f) for f in top15_feat]\n\nfig, ax = plt.subplots(figsize=(10, 7))\nsns.heatmap(class_shap[top15_idx, :],\n            xticklabels=le.classes_, yticklabels=top15_feat,\n            annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,\n            cbar_kws={'label': 'Importance'})\nax.set_title('Per-Class SHAP Importances — Top 15 Features', fontsize=13)\nax.set_xlabel('Fault Class')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Model Calibration — Platt Scaling & Reliability Diagram\n\n\n# ─── 8. Calibrate SVC + reliability diagram ─────────────\nfrom sklearn.preprocessing import label_binarize\ncal_svc = CalibratedClassifierCV(svc, cv=3, method='sigmoid')\ncal_svc.fit(X_train_sm, y_train_sm)\n\n# Reliability diagram for each class (one-vs-rest)\ny_test_bin = label_binarize(y_test, classes=range(n_classes))\n\nproba_raw = svc.predict_proba(X_test)\nproba_cal = cal_svc.predict_proba(X_test)\n\nn_bins = 10\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor idx, cls_name in enumerate(le.classes_):\n    ax = axes[idx // 2, idx % 2]\n    y_true = y_test_bin[:, idx]\n\n    for label, proba, color in [('Uncalibrated', proba_raw[:, idx], '#4c72b0'),\n                                ('Calibrated',   proba_cal[:, idx], '#c44e52')]:\n        bin_edges = np.linspace(0, 1, n_bins+1)\n        bin_acc = []\n        bin_conf = []\n        for i in range(n_bins):\n            mask = (proba &gt;= bin_edges[i]) & (proba &lt; bin_edges[i+1])\n            if mask.sum() &gt; 0:\n                bin_acc.append(y_true[mask].mean())\n                bin_conf.append(proba[mask].mean())\n        ax.plot(bin_conf, bin_acc, 'o-', color=color,\n                lw=1.5, ms=5, label=label)\n\n    ax.plot([0, 1], [0, 1], 'k--', lw=0.8, alpha=0.5)\n    ax.set_title(f'Reliability Diagram — {cls_name}', fontsize=11)\n    ax.set_xlabel('Mean Predicted Probability')\n    ax.set_ylabel('Fraction Positive')\n    ax.legend(fontsize=8)\n    ax.set_xlim(-0.05, 1.05)\n    ax.set_ylim(-0.05, 1.05)\n\nplt.suptitle('Calibration Curves (Platt Scaling)', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 5. Remaining Useful Life (RUL) Regression\n\n# ─── 9. RUL regression ─────────────────────────────────────\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.ensemble import GradientBoostingRegressor as GBReg\n\n# Use the same feature matrix but target = RUL\ny_rul = feat_df['RUL'].values\nX_rul = scaler.transform(feat_df[FEAT_COLS].values)\n\nX_rul_train, X_rul_test, y_rul_train, y_rul_test = train_test_split(\n    X_rul, y_rul, test_size=0.25, random_state=42)\n\nrul_model = GBReg(n_estimators=300, max_depth=5, learning_rate=0.05,\n                  subsample=0.8, random_state=0)\nrul_model.fit(X_rul_train, y_rul_train)\nrul_preds = rul_model.predict(X_rul_test)\n\nrmse_rul = np.sqrt(mean_squared_error(y_rul_test, rul_preds))\nmae_rul = mean_absolute_error(y_rul_test, rul_preds)\nr2_rul = r2_score(y_rul_test, rul_preds)\nprint(\n    f'RUL Regression:  RMSE={rmse_rul:.2f} cycles | MAE={mae_rul:.2f} | R²={r2_rul:.3f}')\n\n\n\n\nCode\n# ─── 10. RUL prediction plots ─────────────────────────────\nfig, axes = plt.subplots(1, 3, figsize=(17, 5))\n\n# Actual vs Predicted scatter\naxes[0].scatter(y_rul_test, rul_preds, s=10, alpha=0.4, color='steelblue')\nlim = [min(y_rul_test.min(), rul_preds.min()),\n       max(y_rul_test.max(), rul_preds.max())]\naxes[0].plot(lim, lim, 'r--', lw=1.2, label='Perfect prediction')\naxes[0].set_xlabel('Actual RUL (cycles)')\naxes[0].set_ylabel('Predicted RUL')\naxes[0].set_title(f'Actual vs Predicted RUL (R²={r2_rul:.3f})')\naxes[0].legend()\n\n# Residual histogram\nresiduals = y_rul_test - rul_preds\naxes[1].hist(residuals, bins=50, color='steelblue',\n             edgecolor='white', density=True)\naxes[1].axvline(0, color='red', ls='--', lw=1.2)\naxes[1].set_title(f'Residuals (MAE={mae_rul:.1f} cycles)')\naxes[1].set_xlabel('Residual (cycles)')\n\n# RUL prediction over a single unit's lifecycle\n# Sort test indices by actual RUL for a \"degradation curve\" view\nsort_idx = np.argsort(y_rul_test)[::-1]\naxes[2].plot(y_rul_test[sort_idx], lw=1.2, color='black', label='Actual RUL')\naxes[2].plot(rul_preds[sort_idx], lw=1.2, color='crimson',\n             alpha=0.7, label='Predicted RUL')\naxes[2].set_title('RUL Trajectory (sorted by actual)')\naxes[2].set_xlabel('Sample Index (sorted)')\naxes[2].set_ylabel('RUL (cycles)')\naxes[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# ─── 11. Final classification report (best model) ────────\n# Voting ensemble\nvoter = VotingClassifier(\n    estimators=[('rf', rf), ('gbr', gbr), ('svc', cal_svc)],\n    voting='soft'\n)\nvoter.fit(X_train_sm, y_train_sm)\nvoter_preds = voter.predict(X_test)\n\nprint('═' * 60)\nprint(' VOTING ENSEMBLE — Classification Report')\nprint(classification_report(y_test, voter_preds, target_names=le.classes_))\n\n# Confusion matrix\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfor ax, (name, preds) in zip(axes, [('Voting Ensemble', voter_preds), ('Random Forest', rf.predict(X_test))]):\n    cm = confusion_matrix(y_test, preds)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                xticklabels=le.classes_, yticklabels=le.classes_)\n    ax.set_title(f'Confusion Matrix — {name}', fontsize=12)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/05_ADV_Fault_Classification_ML.html#summary-portfolio-takeaways",
    "href": "projects/05_ADV_Fault_Classification_ML.html#summary-portfolio-takeaways",
    "title": "Advanced Fault Classification",
    "section": "",
    "text": "Technique\nValue\n\n\n\n\nDeep Feature Engineering\n11 features/sensor (spectral entropy, crest factor, slope, ACF) — captures degradation signature\n\n\nSMOTE\nBalances minority fault classes without losing information — critical for real-world imbalanced data\n\n\nPermutation SHAP\nIdentifies which sensor features drive each fault type — actionable for maintenance teams\n\n\nPer-class SHAP Heatmap\nShows different features matter for different faults — enables targeted inspection\n\n\nPlatt Calibration\nConverts raw SVM scores to reliable probabilities — essential for risk-based maintenance\n\n\nRUL Regression\nPredicts remaining useful life with &lt;10 cycle MAE — the core of predictive maintenance\n\n\nVoting Ensemble\nCombines RF + GBR + calibrated SVC for robust multi-class predictions\n\n\n\nThis pipeline covers the full predictive maintenance workflow: detection → diagnosis → prognosis."
  },
  {
    "objectID": "projects/05_Fault_Classification_ML.html",
    "href": "projects/05_Fault_Classification_ML.html",
    "title": "Predictive Maintenance & Fault Diagnosis",
    "section": "",
    "text": "Portfolio Project 5 — Predictive Maintenance Fault Diagnosis\n\n\n\nClassify machine operating states (Normal / Fault A / Fault B / Fault C) from vibration and temperature sensor data.\n\n\n\nNASA Bearing Dataset — simulated multi-class version Original: https://data.nasa.gov/Machinery-and-Dynamics/Case-1-Normal-Bearing/ We replicate the structure with synthetic vibration signals.\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.decomposition import PCA\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')\n\n\n\n\n\n\n\nCode\n# 2. Generate vibration + temperature data for 4 classes\ndef gen_vibration_data(samples_per_class=500, seed=2024):\n    rng = np.random.default_rng(seed)\n    t = np.linspace(0, 10, 200)  # 200 time-steps per sample\n\n    classes = ['Normal', 'Fault_A', 'Fault_B', 'Fault_C']\n    # Class signatures: different dominant frequencies and amplitudes\n    signatures = {\n        'Normal':  {'freqs': [10, 30],  'amps': [1.0, 0.3], 'noise': 0.1},\n        # high-freq component\n        'Fault_A': {'freqs': [10, 50],  'amps': [1.0, 1.2], 'noise': 0.2},\n        # increased noise (bearing wear)\n        'Fault_B': {'freqs': [10, 15],  'amps': [1.0, 0.8], 'noise': 0.4},\n        # low-freq dominance (imbalance)\n        'Fault_C': {'freqs': [5, 30],   'amps': [2.0, 0.5], 'noise': 0.15},\n    }\n\n    all_rows = []\n    for cls in classes:\n        sig = signatures[cls]\n        for i in range(samples_per_class):\n            x1 = sum(a*np.sin(2*np.pi*f*t + rng.uniform(0, 2*np.pi))\n                     for f, a in zip(sig['freqs'], sig['amps']))\n            x1 += rng.normal(0, sig['noise'], len(t))\n            x2 = 0.6*x1 + rng.normal(0, 0.3, len(t))  # correlated 2nd sensor\n            temp = 60 + {'Normal': 0, 'Fault_A': 5, 'Fault_B': 12,\n                         'Fault_C': 3}[cls] + rng.normal(0, 2)\n\n            # Statistical features from the window\n            feats = {\n                'rms_x1': np.sqrt(np.mean(x1**2)),\n                'peak_x1': np.max(np.abs(x1)),\n                'kurtosis_x1': float(pd.Series(x1).kurtosis()),\n                'skew_x1': float(pd.Series(x1).skew()),\n                'rms_x2': np.sqrt(np.mean(x2**2)),\n                'peak_x2': np.max(np.abs(x2)),\n                'kurtosis_x2': float(pd.Series(x2).kurtosis()),\n                'skew_x2': float(pd.Series(x2).skew()),\n                'temperature': temp,\n                'crest_factor': np.max(np.abs(x1)) / (np.sqrt(np.mean(x1**2)) + 1e-8),\n                'ptp_x1': np.ptp(x1),\n                'std_x1': np.std(x1),\n            }\n            feats['Label'] = cls\n            all_rows.append(feats)\n\n    return pd.DataFrame(all_rows)\n\n\ndf = gen_vibration_data()\nprint(df.shape)\ndf.groupby('Label').size()\n\n\n\n\n\n\n\nCode\n# 3. PCA plot coloured by class\nFEAT_COLS = [c for c in df.columns if c != 'Label']\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df[FEAT_COLS])\n\npca2 = PCA(n_components=2)\nX_pca = pca2.fit_transform(X_scaled)\n\nfig, ax = plt.subplots(figsize=(9, 6))\nfor cls in df['Label'].unique():\n    mask = df['Label'] == cls\n    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], s=25, alpha=0.6, label=cls)\nax.set_xlabel(f'PC1 ({pca2.explained_variance_ratio_[0]*100:.1f}%)')\nax.set_ylabel(f'PC2 ({pca2.explained_variance_ratio_[1]*100:.1f}%)')\nax.set_title('PCA — Fault Classes')\nax.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Feature distributions per class (box plot)\nfig, axes = plt.subplots(3, 4, figsize=(18, 10))\naxes = axes.flatten()\nfor i, feat in enumerate(FEAT_COLS):\n    sns.boxplot(data=df, x='Label', y=feat,\n                ax=axes[i], palette='Set2', linewidth=0.8)\n    axes[i].set_title(feat, fontsize=10)\n    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=15, fontsize=8)\n    axes[i].set_xlabel('')\n\nplt.suptitle('Feature Distributions by Fault Class', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 5. Encode labels, split, train\nle = LabelEncoder()\ny = le.fit_transform(df['Label'])\nX = X_scaled.copy()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, stratify=y, random_state=42\n)\n\nmodels = {\n    'Random Forest':       RandomForestClassifier(n_estimators=200, max_depth=None, random_state=0),\n    'Gradient Boosting':   GradientBoostingClassifier(n_estimators=200, max_depth=4, random_state=0),\n    'SVM (RBF)':           SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=0),\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    acc_cv = cross_val_score(model, X_train, y_train, cv=StratifiedKFold(\n        5, shuffle=True, random_state=0), scoring='accuracy')\n    preds = model.predict(X_test)\n    results[name] = {'model': model, 'preds': preds,\n                     'cv_acc': acc_cv.mean(), 'cv_std': acc_cv.std()}\n    print(f'{name:25s} | CV Acc = {acc_cv.mean()*100:.1f} ± {acc_cv.std()*100:.1f}%')\n\n\n\n\nCode\n# 6. Confusion matrices\nbest_name = max(results, key=lambda k: results[k]['cv_acc'])\nbest_preds = results[best_name]['preds']\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor ax, (name, res) in zip(axes, results.items()):\n    cm = confusion_matrix(y_test, res['preds'])\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                xticklabels=le.classes_, yticklabels=le.classes_)\n    ax.set_title(f'{name}', fontsize=12)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n\nplt.suptitle('Confusion Matrices — All Models', fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()\n\nprint(f'\\n📋 Best model classification report ({best_name}):')\nprint(classification_report(y_test, best_preds, target_names=le.classes_))\n\n\n\n\nCode\n# 7. ROC curves (one-vs-rest, macro average)\nfrom sklearn.preprocessing import label_binarize\n\ny_test_bin = label_binarize(y_test, classes=le.transform(le.classes_))\n\nfig, ax = plt.subplots(figsize=(8, 6))\nfor name, res in results.items():\n    model = res['model']\n    if hasattr(model, 'predict_proba'):\n        y_prob = model.predict_proba(X_test)\n        fpr_list, tpr_list, rocs = [], [], []\n        for i in range(len(le.classes_)):\n            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n            rocs.append(auc(fpr, tpr))\n            fpr_list.append(fpr)\n            tpr_list.append(tpr)\n        mean_auc = np.mean(rocs)\n        # Plot macro-average (interpolated)\n        mean_fpr = np.linspace(0, 1, 100)\n        mean_tpr = np.mean([np.interp(mean_fpr, f, t)\n                           for f, t in zip(fpr_list, tpr_list)], axis=0)\n        ax.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC={mean_auc:.3f})')\n\nax.plot([0, 1], [0, 1], 'k--', lw=0.8)\nax.set_xlabel('FPR')\nax.set_ylabel('TPR')\nax.set_title('ROC Curves — Macro Average (OvR)')\nax.legend(loc='lower right')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nGenerated realistic vibration features (RMS, kurtosis, crest factor, etc.)\nAll three classifiers achieved &gt;95% accuracy; SVM and RF led\nPCA visualization showed clear class separation in feature space\nROC analysis confirmed high discriminative power across all fault types"
  },
  {
    "objectID": "projects/05_Fault_Classification_ML.html#objective",
    "href": "projects/05_Fault_Classification_ML.html#objective",
    "title": "Predictive Maintenance & Fault Diagnosis",
    "section": "",
    "text": "Classify machine operating states (Normal / Fault A / Fault B / Fault C) from vibration and temperature sensor data."
  },
  {
    "objectID": "projects/05_Fault_Classification_ML.html#dataset",
    "href": "projects/05_Fault_Classification_ML.html#dataset",
    "title": "Predictive Maintenance & Fault Diagnosis",
    "section": "",
    "text": "NASA Bearing Dataset — simulated multi-class version Original: https://data.nasa.gov/Machinery-and-Dynamics/Case-1-Normal-Bearing/ We replicate the structure with synthetic vibration signals.\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.decomposition import PCA\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')"
  },
  {
    "objectID": "projects/05_Fault_Classification_ML.html#synthetic-vibration-data-generation",
    "href": "projects/05_Fault_Classification_ML.html#synthetic-vibration-data-generation",
    "title": "Predictive Maintenance & Fault Diagnosis",
    "section": "",
    "text": "Code\n# 2. Generate vibration + temperature data for 4 classes\ndef gen_vibration_data(samples_per_class=500, seed=2024):\n    rng = np.random.default_rng(seed)\n    t = np.linspace(0, 10, 200)  # 200 time-steps per sample\n\n    classes = ['Normal', 'Fault_A', 'Fault_B', 'Fault_C']\n    # Class signatures: different dominant frequencies and amplitudes\n    signatures = {\n        'Normal':  {'freqs': [10, 30],  'amps': [1.0, 0.3], 'noise': 0.1},\n        # high-freq component\n        'Fault_A': {'freqs': [10, 50],  'amps': [1.0, 1.2], 'noise': 0.2},\n        # increased noise (bearing wear)\n        'Fault_B': {'freqs': [10, 15],  'amps': [1.0, 0.8], 'noise': 0.4},\n        # low-freq dominance (imbalance)\n        'Fault_C': {'freqs': [5, 30],   'amps': [2.0, 0.5], 'noise': 0.15},\n    }\n\n    all_rows = []\n    for cls in classes:\n        sig = signatures[cls]\n        for i in range(samples_per_class):\n            x1 = sum(a*np.sin(2*np.pi*f*t + rng.uniform(0, 2*np.pi))\n                     for f, a in zip(sig['freqs'], sig['amps']))\n            x1 += rng.normal(0, sig['noise'], len(t))\n            x2 = 0.6*x1 + rng.normal(0, 0.3, len(t))  # correlated 2nd sensor\n            temp = 60 + {'Normal': 0, 'Fault_A': 5, 'Fault_B': 12,\n                         'Fault_C': 3}[cls] + rng.normal(0, 2)\n\n            # Statistical features from the window\n            feats = {\n                'rms_x1': np.sqrt(np.mean(x1**2)),\n                'peak_x1': np.max(np.abs(x1)),\n                'kurtosis_x1': float(pd.Series(x1).kurtosis()),\n                'skew_x1': float(pd.Series(x1).skew()),\n                'rms_x2': np.sqrt(np.mean(x2**2)),\n                'peak_x2': np.max(np.abs(x2)),\n                'kurtosis_x2': float(pd.Series(x2).kurtosis()),\n                'skew_x2': float(pd.Series(x2).skew()),\n                'temperature': temp,\n                'crest_factor': np.max(np.abs(x1)) / (np.sqrt(np.mean(x1**2)) + 1e-8),\n                'ptp_x1': np.ptp(x1),\n                'std_x1': np.std(x1),\n            }\n            feats['Label'] = cls\n            all_rows.append(feats)\n\n    return pd.DataFrame(all_rows)\n\n\ndf = gen_vibration_data()\nprint(df.shape)\ndf.groupby('Label').size()"
  },
  {
    "objectID": "projects/05_Fault_Classification_ML.html#exploratory-visualisation",
    "href": "projects/05_Fault_Classification_ML.html#exploratory-visualisation",
    "title": "Predictive Maintenance & Fault Diagnosis",
    "section": "",
    "text": "Code\n# 3. PCA plot coloured by class\nFEAT_COLS = [c for c in df.columns if c != 'Label']\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(df[FEAT_COLS])\n\npca2 = PCA(n_components=2)\nX_pca = pca2.fit_transform(X_scaled)\n\nfig, ax = plt.subplots(figsize=(9, 6))\nfor cls in df['Label'].unique():\n    mask = df['Label'] == cls\n    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], s=25, alpha=0.6, label=cls)\nax.set_xlabel(f'PC1 ({pca2.explained_variance_ratio_[0]*100:.1f}%)')\nax.set_ylabel(f'PC2 ({pca2.explained_variance_ratio_[1]*100:.1f}%)')\nax.set_title('PCA — Fault Classes')\nax.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Feature distributions per class (box plot)\nfig, axes = plt.subplots(3, 4, figsize=(18, 10))\naxes = axes.flatten()\nfor i, feat in enumerate(FEAT_COLS):\n    sns.boxplot(data=df, x='Label', y=feat,\n                ax=axes[i], palette='Set2', linewidth=0.8)\n    axes[i].set_title(feat, fontsize=10)\n    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=15, fontsize=8)\n    axes[i].set_xlabel('')\n\nplt.suptitle('Feature Distributions by Fault Class', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/05_Fault_Classification_ML.html#train-evaluate-multiple-classifiers",
    "href": "projects/05_Fault_Classification_ML.html#train-evaluate-multiple-classifiers",
    "title": "Predictive Maintenance & Fault Diagnosis",
    "section": "",
    "text": "Code\n# 5. Encode labels, split, train\nle = LabelEncoder()\ny = le.fit_transform(df['Label'])\nX = X_scaled.copy()\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, stratify=y, random_state=42\n)\n\nmodels = {\n    'Random Forest':       RandomForestClassifier(n_estimators=200, max_depth=None, random_state=0),\n    'Gradient Boosting':   GradientBoostingClassifier(n_estimators=200, max_depth=4, random_state=0),\n    'SVM (RBF)':           SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=0),\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    acc_cv = cross_val_score(model, X_train, y_train, cv=StratifiedKFold(\n        5, shuffle=True, random_state=0), scoring='accuracy')\n    preds = model.predict(X_test)\n    results[name] = {'model': model, 'preds': preds,\n                     'cv_acc': acc_cv.mean(), 'cv_std': acc_cv.std()}\n    print(f'{name:25s} | CV Acc = {acc_cv.mean()*100:.1f} ± {acc_cv.std()*100:.1f}%')\n\n\n\n\nCode\n# 6. Confusion matrices\nbest_name = max(results, key=lambda k: results[k]['cv_acc'])\nbest_preds = results[best_name]['preds']\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor ax, (name, res) in zip(axes, results.items()):\n    cm = confusion_matrix(y_test, res['preds'])\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                xticklabels=le.classes_, yticklabels=le.classes_)\n    ax.set_title(f'{name}', fontsize=12)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n\nplt.suptitle('Confusion Matrices — All Models', fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()\n\nprint(f'\\n📋 Best model classification report ({best_name}):')\nprint(classification_report(y_test, best_preds, target_names=le.classes_))\n\n\n\n\nCode\n# 7. ROC curves (one-vs-rest, macro average)\nfrom sklearn.preprocessing import label_binarize\n\ny_test_bin = label_binarize(y_test, classes=le.transform(le.classes_))\n\nfig, ax = plt.subplots(figsize=(8, 6))\nfor name, res in results.items():\n    model = res['model']\n    if hasattr(model, 'predict_proba'):\n        y_prob = model.predict_proba(X_test)\n        fpr_list, tpr_list, rocs = [], [], []\n        for i in range(len(le.classes_)):\n            fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n            rocs.append(auc(fpr, tpr))\n            fpr_list.append(fpr)\n            tpr_list.append(tpr)\n        mean_auc = np.mean(rocs)\n        # Plot macro-average (interpolated)\n        mean_fpr = np.linspace(0, 1, 100)\n        mean_tpr = np.mean([np.interp(mean_fpr, f, t)\n                           for f, t in zip(fpr_list, tpr_list)], axis=0)\n        ax.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC={mean_auc:.3f})')\n\nax.plot([0, 1], [0, 1], 'k--', lw=0.8)\nax.set_xlabel('FPR')\nax.set_ylabel('TPR')\nax.set_title('ROC Curves — Macro Average (OvR)')\nax.legend(loc='lower right')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/05_Fault_Classification_ML.html#summary",
    "href": "projects/05_Fault_Classification_ML.html#summary",
    "title": "Predictive Maintenance & Fault Diagnosis",
    "section": "",
    "text": "Generated realistic vibration features (RMS, kurtosis, crest factor, etc.)\nAll three classifiers achieved &gt;95% accuracy; SVM and RF led\nPCA visualization showed clear class separation in feature space\nROC analysis confirmed high discriminative power across all fault types"
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html",
    "href": "projects/06_Process_Data_SPC.html",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Portfolio Project 6 — Statistical Process Control (SPC)\n\n\n\nImplement control charts, capability indices, and drift detection on simulated manufacturing process data.\n\n\n\nSimulated CNC / Chemical Reactor Process (mirrors Tennessee Eastman benchmark structure) Tennessee Eastman: https://github.com/Ramin-Khalatbari/dataset-Tennessee-Eastman\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.signal import find_peaks\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')\n\n\n\n\n\n\n\nCode\n# 2. Generate process streams with injected faults\ndef gen_process_data(n=2000, seed=55):\n    rng = np.random.default_rng(seed)\n\n    # Normal-state streams\n    temp = rng.normal(85.0, 1.5, n)   # reactor temperature\n    pressure = rng.normal(3.2, 0.2, n)    # reactor pressure\n    flow = rng.normal(50.0, 3.0, n)   # feed flow\n    conc_A = rng.normal(0.45, 0.03, n)  # reactant A concentration\n    conc_B = 1.0 - conc_A + rng.normal(0, 0.01, n)  # reactant B (mass balance)\n\n    # Inject faults\n    fault_label = np.zeros(n, dtype=int)\n\n    # Fault 1: Temperature drift (gradual) — samples 500-700\n    drift = np.linspace(0, 4, 200)\n    temp[500:700] += drift\n    fault_label[500:700] = 1\n\n    # Fault 2: Pressure spike — samples 1000-1020\n    temp[1000:1020] += rng.normal(0, 0.5, 20)\n    pressure[1000:1020] += rng.uniform(1.0, 2.0, 20)\n    fault_label[1000:1020] = 2\n\n    # Fault 3: Flow step change — samples 1500-1600\n    flow[1500:1600] += 8\n    conc_A[1500:1600] -= 0.05  # downstream effect\n    fault_label[1500:1600] = 3\n\n    df = pd.DataFrame({\n        'Temperature': temp.round(2),\n        'Pressure': pressure.round(3),\n        'Flow': flow.round(2),\n        'Conc_A': conc_A.round(4),\n        'Conc_B': conc_B.round(4),\n        'Fault': fault_label\n    })\n    df['Time'] = pd.date_range('2024-06-01', periods=n, freq='5min')\n    return df\n\n\ndf = gen_process_data()\nprint(df.shape)\ndf.head()\n\n\n\n\n\n\n\nCode\n# 3. Individual + Moving Range (I-MR) control chart for Temperature\n# Using first 500 samples (normal phase) to set limits\nnormal = df.iloc[:500]\nmean_T = normal['Temperature'].mean()\nstd_T = normal['Temperature'].std()\n\nUCL = mean_T + 3*std_T\nLCL = mean_T - 3*std_T\n\nfig, ax = plt.subplots(figsize=(16, 5))\nax.plot(df['Time'], df['Temperature'], lw=0.8,\n        color='steelblue', label='Temperature')\nax.axhline(UCL, color='red',   ls='--', lw=1.2, label=f'UCL = {UCL:.2f}')\nax.axhline(LCL, color='red',   ls='--', lw=1.2, label=f'LCL = {LCL:.2f}')\nax.axhline(mean_T, color='green', ls='-', lw=1.0, label=f'CL = {mean_T:.2f}')\n\n# Highlight violations\nviolations = (df['Temperature'] &gt; UCL) | (df['Temperature'] &lt; LCL)\nax.scatter(df.loc[violations, 'Time'], df.loc[violations, 'Temperature'],\n           s=30, color='red', zorder=5, label=f'Violations ({violations.sum()})')\n\nax.set_title('I-Chart — Reactor Temperature', fontsize=13)\nax.set_ylabel('Temperature (°C)')\nax.set_xlabel('Time')\nax.legend(loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Control charts for all variables\nvars_to_plot = ['Temperature', 'Pressure', 'Flow', 'Conc_A']\n\nfig, axes = plt.subplots(len(vars_to_plot), 1, figsize=(16, 12), sharex=True)\n\nfor ax, var in zip(axes, vars_to_plot):\n    norm_data = df[var].iloc[:500]\n    mu = norm_data.mean()\n    sig = norm_data.std()\n    ucl = mu + 3*sig\n    lcl = mu - 3*sig\n\n    ax.plot(df['Time'], df[var], lw=0.7, color='steelblue')\n    ax.axhline(ucl, color='red',   ls='--', lw=1)\n    ax.axhline(lcl, color='red',   ls='--', lw=1)\n    ax.axhline(mu,  color='green', ls='-',  lw=0.8)\n    ax.set_ylabel(var, fontsize=10)\n\n    # Shade fault regions\n    for f_id, color in [(1, '#ff9999'), (2, '#ffcc99'), (3, '#cc99ff')]:\n        mask = df['Fault'] == f_id\n        if mask.any():\n            ax.axvspan(df.loc[mask, 'Time'].iloc[0], df.loc[mask, 'Time'].iloc[-1],\n                       alpha=0.15, color=color, label=f'Fault {f_id}')\n    if var == vars_to_plot[0]:\n        ax.legend(loc='upper left', fontsize=8)\n\naxes[-1].set_xlabel('Time')\nplt.suptitle('Multi-Variable Control Charts with Fault Windows',\n             fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 5. Cpk calculation for each variable (normal phase only)\ndef cpk(data, usl, lsl):\n    mu = data.mean()\n    sig = data.std()\n    cpu = (usl - mu) / (3*sig) if sig &gt; 0 else np.inf\n    cpl = (mu - lsl) / (3*sig) if sig &gt; 0 else np.inf\n    return min(cpu, cpl)\n\n\n# Define spec limits (± 4 sigma for illustration)\nspecs = {}\nfor var in vars_to_plot:\n    mu = df[var].iloc[:500].mean()\n    sig = df[var].iloc[:500].std()\n    specs[var] = {'USL': mu + 4*sig, 'LSL': mu - 4*sig,\n                  'Cpk': cpk(df[var].iloc[:500], mu+4*sig, mu-4*sig)}\n\nspecs_df = pd.DataFrame(specs).T\nprint('Process Capability (Normal Phase):')\nprint(specs_df.round(4))\n\nfig, ax = plt.subplots(figsize=(8, 4))\ncolors = ['green' if c &gt;= 1.33 else 'orange' if c &gt;=\n          1.0 else 'red' for c in specs_df['Cpk']]\nspecs_df['Cpk'].plot(kind='bar', ax=ax, color=colors, edgecolor='white')\nax.axhline(1.33, color='green', ls='--', lw=1, label='Target Cpk=1.33')\nax.axhline(1.0,  color='orange', ls='--', lw=1, label='Min Cpk=1.0')\nax.set_title('Process Capability Index (Cpk)')\nax.set_ylabel('Cpk')\nax.legend()\nplt.xticks(rotation=15)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 6. CUSUM chart for Temperature\nk = 0.5 * std_T   # allowance\nh = 5.0 * std_T   # decision interval\n\ncusum_pos = np.zeros(len(df))\ncusum_neg = np.zeros(len(df))\nalerts = np.zeros(len(df), dtype=bool)\n\nfor i in range(1, len(df)):\n    cusum_pos[i] = max(0, cusum_pos[i-1] +\n                       (df['Temperature'].iloc[i] - mean_T) - k)\n    cusum_neg[i] = max(0, cusum_neg[i-1] -\n                       (df['Temperature'].iloc[i] - mean_T) - k)\n    alerts[i] = (cusum_pos[i] &gt; h) or (cusum_neg[i] &gt; h)\n\nfig, axes = plt.subplots(2, 1, figsize=(16, 7), sharex=True)\n\naxes[0].plot(df['Time'], cusum_pos, lw=1, color='steelblue', label='CUSUM+')\naxes[0].plot(df['Time'], -cusum_neg, lw=1, color='orange', label='CUSUM−')\naxes[0].axhline(h,  color='red', ls='--', lw=1, label=f'H = {h:.2f}')\naxes[0].axhline(-h, color='red', ls='--', lw=1)\naxes[0].set_title('CUSUM Chart — Temperature')\naxes[0].set_ylabel('CUSUM Value')\naxes[0].legend()\n\n# Alert indicator\naxes[1].fill_between(df['Time'], alerts.astype(int), color='red', alpha=0.5)\naxes[1].set_title('CUSUM Alert Signal')\naxes[1].set_ylabel('Alert')\naxes[1].set_xlabel('Time')\naxes[1].set_yticks([0, 1])\naxes[1].set_yticklabels(['No Alert', 'Alert'])\n\nplt.tight_layout()\nplt.show()\nprint(f'Total CUSUM alert samples: {alerts.sum()}')\n\n\n\n\n\n\nImplemented I-MR control charts for 4 process variables\nDetected all three injected faults via limit violations\nCalculated Cpk for normal-phase capability assessment\nCUSUM successfully detected the gradual temperature drift early"
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html#objective",
    "href": "projects/06_Process_Data_SPC.html#objective",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Implement control charts, capability indices, and drift detection on simulated manufacturing process data."
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html#dataset",
    "href": "projects/06_Process_Data_SPC.html#dataset",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Simulated CNC / Chemical Reactor Process (mirrors Tennessee Eastman benchmark structure) Tennessee Eastman: https://github.com/Ramin-Khalatbari/dataset-Tennessee-Eastman\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.signal import find_peaks\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')"
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html#synthetic-process-data",
    "href": "projects/06_Process_Data_SPC.html#synthetic-process-data",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Code\n# 2. Generate process streams with injected faults\ndef gen_process_data(n=2000, seed=55):\n    rng = np.random.default_rng(seed)\n\n    # Normal-state streams\n    temp = rng.normal(85.0, 1.5, n)   # reactor temperature\n    pressure = rng.normal(3.2, 0.2, n)    # reactor pressure\n    flow = rng.normal(50.0, 3.0, n)   # feed flow\n    conc_A = rng.normal(0.45, 0.03, n)  # reactant A concentration\n    conc_B = 1.0 - conc_A + rng.normal(0, 0.01, n)  # reactant B (mass balance)\n\n    # Inject faults\n    fault_label = np.zeros(n, dtype=int)\n\n    # Fault 1: Temperature drift (gradual) — samples 500-700\n    drift = np.linspace(0, 4, 200)\n    temp[500:700] += drift\n    fault_label[500:700] = 1\n\n    # Fault 2: Pressure spike — samples 1000-1020\n    temp[1000:1020] += rng.normal(0, 0.5, 20)\n    pressure[1000:1020] += rng.uniform(1.0, 2.0, 20)\n    fault_label[1000:1020] = 2\n\n    # Fault 3: Flow step change — samples 1500-1600\n    flow[1500:1600] += 8\n    conc_A[1500:1600] -= 0.05  # downstream effect\n    fault_label[1500:1600] = 3\n\n    df = pd.DataFrame({\n        'Temperature': temp.round(2),\n        'Pressure': pressure.round(3),\n        'Flow': flow.round(2),\n        'Conc_A': conc_A.round(4),\n        'Conc_B': conc_B.round(4),\n        'Fault': fault_label\n    })\n    df['Time'] = pd.date_range('2024-06-01', periods=n, freq='5min')\n    return df\n\n\ndf = gen_process_data()\nprint(df.shape)\ndf.head()"
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html#control-charts-xbar-s",
    "href": "projects/06_Process_Data_SPC.html#control-charts-xbar-s",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Code\n# 3. Individual + Moving Range (I-MR) control chart for Temperature\n# Using first 500 samples (normal phase) to set limits\nnormal = df.iloc[:500]\nmean_T = normal['Temperature'].mean()\nstd_T = normal['Temperature'].std()\n\nUCL = mean_T + 3*std_T\nLCL = mean_T - 3*std_T\n\nfig, ax = plt.subplots(figsize=(16, 5))\nax.plot(df['Time'], df['Temperature'], lw=0.8,\n        color='steelblue', label='Temperature')\nax.axhline(UCL, color='red',   ls='--', lw=1.2, label=f'UCL = {UCL:.2f}')\nax.axhline(LCL, color='red',   ls='--', lw=1.2, label=f'LCL = {LCL:.2f}')\nax.axhline(mean_T, color='green', ls='-', lw=1.0, label=f'CL = {mean_T:.2f}')\n\n# Highlight violations\nviolations = (df['Temperature'] &gt; UCL) | (df['Temperature'] &lt; LCL)\nax.scatter(df.loc[violations, 'Time'], df.loc[violations, 'Temperature'],\n           s=30, color='red', zorder=5, label=f'Violations ({violations.sum()})')\n\nax.set_title('I-Chart — Reactor Temperature', fontsize=13)\nax.set_ylabel('Temperature (°C)')\nax.set_xlabel('Time')\nax.legend(loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Control charts for all variables\nvars_to_plot = ['Temperature', 'Pressure', 'Flow', 'Conc_A']\n\nfig, axes = plt.subplots(len(vars_to_plot), 1, figsize=(16, 12), sharex=True)\n\nfor ax, var in zip(axes, vars_to_plot):\n    norm_data = df[var].iloc[:500]\n    mu = norm_data.mean()\n    sig = norm_data.std()\n    ucl = mu + 3*sig\n    lcl = mu - 3*sig\n\n    ax.plot(df['Time'], df[var], lw=0.7, color='steelblue')\n    ax.axhline(ucl, color='red',   ls='--', lw=1)\n    ax.axhline(lcl, color='red',   ls='--', lw=1)\n    ax.axhline(mu,  color='green', ls='-',  lw=0.8)\n    ax.set_ylabel(var, fontsize=10)\n\n    # Shade fault regions\n    for f_id, color in [(1, '#ff9999'), (2, '#ffcc99'), (3, '#cc99ff')]:\n        mask = df['Fault'] == f_id\n        if mask.any():\n            ax.axvspan(df.loc[mask, 'Time'].iloc[0], df.loc[mask, 'Time'].iloc[-1],\n                       alpha=0.15, color=color, label=f'Fault {f_id}')\n    if var == vars_to_plot[0]:\n        ax.legend(loc='upper left', fontsize=8)\n\naxes[-1].set_xlabel('Time')\nplt.suptitle('Multi-Variable Control Charts with Fault Windows',\n             fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html#process-capability-analysis",
    "href": "projects/06_Process_Data_SPC.html#process-capability-analysis",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Code\n# 5. Cpk calculation for each variable (normal phase only)\ndef cpk(data, usl, lsl):\n    mu = data.mean()\n    sig = data.std()\n    cpu = (usl - mu) / (3*sig) if sig &gt; 0 else np.inf\n    cpl = (mu - lsl) / (3*sig) if sig &gt; 0 else np.inf\n    return min(cpu, cpl)\n\n\n# Define spec limits (± 4 sigma for illustration)\nspecs = {}\nfor var in vars_to_plot:\n    mu = df[var].iloc[:500].mean()\n    sig = df[var].iloc[:500].std()\n    specs[var] = {'USL': mu + 4*sig, 'LSL': mu - 4*sig,\n                  'Cpk': cpk(df[var].iloc[:500], mu+4*sig, mu-4*sig)}\n\nspecs_df = pd.DataFrame(specs).T\nprint('Process Capability (Normal Phase):')\nprint(specs_df.round(4))\n\nfig, ax = plt.subplots(figsize=(8, 4))\ncolors = ['green' if c &gt;= 1.33 else 'orange' if c &gt;=\n          1.0 else 'red' for c in specs_df['Cpk']]\nspecs_df['Cpk'].plot(kind='bar', ax=ax, color=colors, edgecolor='white')\nax.axhline(1.33, color='green', ls='--', lw=1, label='Target Cpk=1.33')\nax.axhline(1.0,  color='orange', ls='--', lw=1, label='Min Cpk=1.0')\nax.set_title('Process Capability Index (Cpk)')\nax.set_ylabel('Cpk')\nax.legend()\nplt.xticks(rotation=15)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html#cusum-drift-detection",
    "href": "projects/06_Process_Data_SPC.html#cusum-drift-detection",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Code\n# 6. CUSUM chart for Temperature\nk = 0.5 * std_T   # allowance\nh = 5.0 * std_T   # decision interval\n\ncusum_pos = np.zeros(len(df))\ncusum_neg = np.zeros(len(df))\nalerts = np.zeros(len(df), dtype=bool)\n\nfor i in range(1, len(df)):\n    cusum_pos[i] = max(0, cusum_pos[i-1] +\n                       (df['Temperature'].iloc[i] - mean_T) - k)\n    cusum_neg[i] = max(0, cusum_neg[i-1] -\n                       (df['Temperature'].iloc[i] - mean_T) - k)\n    alerts[i] = (cusum_pos[i] &gt; h) or (cusum_neg[i] &gt; h)\n\nfig, axes = plt.subplots(2, 1, figsize=(16, 7), sharex=True)\n\naxes[0].plot(df['Time'], cusum_pos, lw=1, color='steelblue', label='CUSUM+')\naxes[0].plot(df['Time'], -cusum_neg, lw=1, color='orange', label='CUSUM−')\naxes[0].axhline(h,  color='red', ls='--', lw=1, label=f'H = {h:.2f}')\naxes[0].axhline(-h, color='red', ls='--', lw=1)\naxes[0].set_title('CUSUM Chart — Temperature')\naxes[0].set_ylabel('CUSUM Value')\naxes[0].legend()\n\n# Alert indicator\naxes[1].fill_between(df['Time'], alerts.astype(int), color='red', alpha=0.5)\naxes[1].set_title('CUSUM Alert Signal')\naxes[1].set_ylabel('Alert')\naxes[1].set_xlabel('Time')\naxes[1].set_yticks([0, 1])\naxes[1].set_yticklabels(['No Alert', 'Alert'])\n\nplt.tight_layout()\nplt.show()\nprint(f'Total CUSUM alert samples: {alerts.sum()}')"
  },
  {
    "objectID": "projects/06_Process_Data_SPC.html#summary",
    "href": "projects/06_Process_Data_SPC.html#summary",
    "title": "Statistical Process Control",
    "section": "",
    "text": "Implemented I-MR control charts for 4 process variables\nDetected all three injected faults via limit violations\nCalculated Cpk for normal-phase capability assessment\nCUSUM successfully detected the gradual temperature drift early"
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html",
    "href": "projects/07_Quality_Defect_Prediction.html",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Portfolio Project 7 — Manufacturing Quality Analytics\n\n\n\nAnalyse product quality data, perform root-cause analysis using correlation and regression, and build a defect-prediction model.\n\n\n\nSimulated manufacturing quality log (mirrors structure of common industry datasets such as the Steel Defect Detection dataset on Kaggle or the UCI Concrete Quality dataset)\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')\n\n\n\n\n\n\n\nCode\n# 2. Generate manufacturing quality records\ndef gen_quality_data(n=5000, seed=2025):\n    rng = np.random.default_rng(seed)\n\n    # Process inputs\n    mach_speed = rng.normal(500, 30, n)        # RPM\n    mach_temp = rng.normal(220, 8, n)         # °C\n    raw_mat_qual = rng.normal(85, 5, n)          # supplier quality score\n    humidity = rng.uniform(30, 80, n)        # %\n    operator_exp = rng.choice([1, 2, 3, 5, 8], n)    # years\n\n    # Measured quality dimensions\n    thickness = 10.0 + 0.02*mach_speed - 0.05*mach_temp + rng.normal(0, 0.3, n)\n    surface_fin = 3.0 - 0.005*mach_speed + \\\n        0.01*raw_mat_qual + rng.normal(0, 0.2, n)\n    tensile_str = 400 + 0.5*raw_mat_qual - 0.2*humidity + rng.normal(0, 15, n)\n    hardness = 55 + 0.1*mach_temp - 0.05*humidity + rng.normal(0, 2, n)\n\n    # Defect probability (logistic)\n    log_odds = (\n        -3.0\n        + 0.05 * (mach_temp - 220)\n        - 0.04 * raw_mat_qual\n        + 0.02 * humidity\n        - 0.3 * operator_exp\n        + 0.01 * np.abs(thickness - 10.0) * 100\n    )\n    p_defect = 1 / (1 + np.exp(-log_odds))\n    defect = (rng.uniform(0, 1, n) &lt; p_defect).astype(int)\n\n    df = pd.DataFrame({\n        'Machine_Speed': mach_speed.round(1),\n        'Machine_Temp': mach_temp.round(1),\n        'Raw_Material_Quality': raw_mat_qual.round(1),\n        'Humidity': humidity.round(1),\n        'Operator_Experience': operator_exp,\n        'Thickness': thickness.round(3),\n        'Surface_Finish': surface_fin.round(3),\n        'Tensile_Strength': tensile_str.round(1),\n        'Hardness': hardness.round(2),\n        'Defect': defect\n    })\n    return df\n\n\ndf = gen_quality_data()\nprint(f'Shape: {df.shape}  |  Defect rate: {df[\"Defect\"].mean()*100:.1f}%')\ndf.describe().round(2)\n\n\n\n\n\n\n\nCode\n# 3. Defect rate by operator experience\ndefect_by_exp = df.groupby('Operator_Experience')['Defect'].mean()*100\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bar chart\ndefect_by_exp.plot(kind='bar', ax=axes[0],\n                   color='steelblue', edgecolor='white')\naxes[0].set_title('Defect Rate by Operator Experience')\naxes[0].set_ylabel('Defect Rate (%)')\naxes[0].set_xlabel('Experience (years)')\naxes[0].tick_params(axis='x', rotation=0)\n\n# Violin: Machine_Temp by Defect\nsns.violinplot(data=df, x='Defect', y='Machine_Temp',\n               ax=axes[1], palette=['#4c72b0', '#c44e52'])\naxes[1].set_title('Machine Temperature by Defect Status')\naxes[1].set_xticklabels(['OK', 'Defective'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Correlation heatmap\ncorr_cols = [c for c in df.columns if c != 'Defect']\ncorr = df[corr_cols + ['Defect']].corr()\n\nfig, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n            vmin=-1, vmax=1, linewidths=0.5, ax=ax)\nax.set_title('Correlation Matrix (incl. Defect)', fontsize=13)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 5. Logistic regression coefficients as root-cause proxy\nFEAT_COLS = [c for c in df.columns if c != 'Defect']\nscaler = StandardScaler()\nX_s = scaler.fit_transform(df[FEAT_COLS])\ny = df['Defect']\n\nlr = LogisticRegression(max_iter=1000, random_state=0)\nlr.fit(X_s, y)\n\ncoef_df = pd.DataFrame({'Feature': FEAT_COLS, 'Coefficient': lr.coef_[0]})\ncoef_df = coef_df.sort_values('Coefficient', key=abs, ascending=True)\n\nfig, ax = plt.subplots(figsize=(9, 5))\ncolors = ['#c44e52' if c &gt; 0 else '#4c72b0' for c in coef_df['Coefficient']]\ncoef_df.plot(kind='barh', x='Feature', y='Coefficient', ax=ax,\n             color=colors, edgecolor='white', legend=False)\nax.axvline(0, color='black', lw=0.8)\nax.set_title('Logistic Regression Coefficients (Root-Cause Proxy)')\nax.set_xlabel('Coefficient (standardised)')\nax.text(0.02, -0.5, 'Red = increases defect risk',\n        color='#c44e52', fontsize=8, transform=ax.transAxes)\nax.text(0.02, -0.65, 'Blue = decreases defect risk',\n        color='#4c72b0', fontsize=8, transform=ax.transAxes)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 6. Train classifiers\nX_train, X_test, y_train, y_test = train_test_split(\n    X_s, y, test_size=0.25, stratify=y, random_state=42)\n\nmodels = {\n    'Logistic Regression':  LogisticRegression(max_iter=1000, random_state=0),\n    'Random Forest':        RandomForestClassifier(n_estimators=200, max_depth=8, random_state=0),\n    'Gradient Boosting':    GradientBoostingClassifier(n_estimators=200, max_depth=4, random_state=0),\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    proba = model.predict_proba(X_test)[:, 1]\n    fpr, tpr, _ = roc_curve(y_test, proba)\n    auc_val = auc(fpr, tpr)\n    results[name] = {'preds': preds, 'proba': proba,\n                     'fpr': fpr, 'tpr': tpr, 'auc': auc_val, 'model': model}\n    print(f'{name:25s} | AUC = {auc_val:.3f}')\n\nprint(f'\\n📋 Best AUC: {max(results, key=lambda k: results[k][\"auc\"])}')\n\n\n\n\nCode\n# 7. ROC + Confusion matrix for best model\nbest = max(results, key=lambda k: results[k]['auc'])\n\nfig, axes = plt.subplots(1, 2, figsize=(13, 5))\n\n# ROC\nfor name, r in results.items():\n    axes[0].plot(r['fpr'], r['tpr'], lw=2,\n                 label=f\"{name} (AUC={r['auc']:.3f})\")\naxes[0].plot([0, 1], [0, 1], 'k--', lw=0.8)\naxes[0].set_xlabel('FPR')\naxes[0].set_ylabel('TPR')\naxes[0].set_title('ROC Curves — Defect Prediction')\naxes[0].legend(loc='lower right', fontsize=8)\n\n# Confusion matrix of best\ncm = confusion_matrix(y_test, results[best]['preds'])\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n            xticklabels=['OK', 'Defect'], yticklabels=['OK', 'Defect'])\naxes[1].set_title(f'Confusion Matrix — {best}')\naxes[1].set_xlabel('Predicted')\naxes[1].set_ylabel('Actual')\n\nplt.tight_layout()\nplt.show()\n\nprint(classification_report(\n    y_test, results[best]['preds'], target_names=['OK', 'Defect']))\n\n\n\n\nCode\n# 8. Feature importance from best tree-based model\nif hasattr(results[best]['model'], 'feature_importances_'):\n    imp = pd.Series(results[best]['model'].feature_importances_,\n                    index=FEAT_COLS).sort_values(ascending=True)\n    fig, ax = plt.subplots(figsize=(9, 5))\n    imp.plot(kind='barh', ax=ax, color='steelblue', edgecolor='white')\n    ax.set_title(f'Feature Importance — {best}')\n    ax.set_xlabel('Importance')\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\nModelled a realistic manufacturing quality pipeline with process → quality → defect linkage\nRoot-cause analysis via logistic coefficients highlighted temperature, humidity, and operator experience\nGradient Boosting delivered the best AUC for defect prediction\nFeature importance confirmed alignment with the engineered data-generating process"
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html#objective",
    "href": "projects/07_Quality_Defect_Prediction.html#objective",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Analyse product quality data, perform root-cause analysis using correlation and regression, and build a defect-prediction model."
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html#dataset",
    "href": "projects/07_Quality_Defect_Prediction.html#dataset",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Simulated manufacturing quality log (mirrors structure of common industry datasets such as the Steel Defect Detection dataset on Kaggle or the UCI Concrete Quality dataset)\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')"
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html#synthetic-quality-data",
    "href": "projects/07_Quality_Defect_Prediction.html#synthetic-quality-data",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Code\n# 2. Generate manufacturing quality records\ndef gen_quality_data(n=5000, seed=2025):\n    rng = np.random.default_rng(seed)\n\n    # Process inputs\n    mach_speed = rng.normal(500, 30, n)        # RPM\n    mach_temp = rng.normal(220, 8, n)         # °C\n    raw_mat_qual = rng.normal(85, 5, n)          # supplier quality score\n    humidity = rng.uniform(30, 80, n)        # %\n    operator_exp = rng.choice([1, 2, 3, 5, 8], n)    # years\n\n    # Measured quality dimensions\n    thickness = 10.0 + 0.02*mach_speed - 0.05*mach_temp + rng.normal(0, 0.3, n)\n    surface_fin = 3.0 - 0.005*mach_speed + \\\n        0.01*raw_mat_qual + rng.normal(0, 0.2, n)\n    tensile_str = 400 + 0.5*raw_mat_qual - 0.2*humidity + rng.normal(0, 15, n)\n    hardness = 55 + 0.1*mach_temp - 0.05*humidity + rng.normal(0, 2, n)\n\n    # Defect probability (logistic)\n    log_odds = (\n        -3.0\n        + 0.05 * (mach_temp - 220)\n        - 0.04 * raw_mat_qual\n        + 0.02 * humidity\n        - 0.3 * operator_exp\n        + 0.01 * np.abs(thickness - 10.0) * 100\n    )\n    p_defect = 1 / (1 + np.exp(-log_odds))\n    defect = (rng.uniform(0, 1, n) &lt; p_defect).astype(int)\n\n    df = pd.DataFrame({\n        'Machine_Speed': mach_speed.round(1),\n        'Machine_Temp': mach_temp.round(1),\n        'Raw_Material_Quality': raw_mat_qual.round(1),\n        'Humidity': humidity.round(1),\n        'Operator_Experience': operator_exp,\n        'Thickness': thickness.round(3),\n        'Surface_Finish': surface_fin.round(3),\n        'Tensile_Strength': tensile_str.round(1),\n        'Hardness': hardness.round(2),\n        'Defect': defect\n    })\n    return df\n\n\ndf = gen_quality_data()\nprint(f'Shape: {df.shape}  |  Defect rate: {df[\"Defect\"].mean()*100:.1f}%')\ndf.describe().round(2)"
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html#exploratory-quality-analysis",
    "href": "projects/07_Quality_Defect_Prediction.html#exploratory-quality-analysis",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Code\n# 3. Defect rate by operator experience\ndefect_by_exp = df.groupby('Operator_Experience')['Defect'].mean()*100\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bar chart\ndefect_by_exp.plot(kind='bar', ax=axes[0],\n                   color='steelblue', edgecolor='white')\naxes[0].set_title('Defect Rate by Operator Experience')\naxes[0].set_ylabel('Defect Rate (%)')\naxes[0].set_xlabel('Experience (years)')\naxes[0].tick_params(axis='x', rotation=0)\n\n# Violin: Machine_Temp by Defect\nsns.violinplot(data=df, x='Defect', y='Machine_Temp',\n               ax=axes[1], palette=['#4c72b0', '#c44e52'])\naxes[1].set_title('Machine Temperature by Defect Status')\naxes[1].set_xticklabels(['OK', 'Defective'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 4. Correlation heatmap\ncorr_cols = [c for c in df.columns if c != 'Defect']\ncorr = df[corr_cols + ['Defect']].corr()\n\nfig, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n            vmin=-1, vmax=1, linewidths=0.5, ax=ax)\nax.set_title('Correlation Matrix (incl. Defect)', fontsize=13)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html#root-cause-analysis-feature-importance",
    "href": "projects/07_Quality_Defect_Prediction.html#root-cause-analysis-feature-importance",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Code\n# 5. Logistic regression coefficients as root-cause proxy\nFEAT_COLS = [c for c in df.columns if c != 'Defect']\nscaler = StandardScaler()\nX_s = scaler.fit_transform(df[FEAT_COLS])\ny = df['Defect']\n\nlr = LogisticRegression(max_iter=1000, random_state=0)\nlr.fit(X_s, y)\n\ncoef_df = pd.DataFrame({'Feature': FEAT_COLS, 'Coefficient': lr.coef_[0]})\ncoef_df = coef_df.sort_values('Coefficient', key=abs, ascending=True)\n\nfig, ax = plt.subplots(figsize=(9, 5))\ncolors = ['#c44e52' if c &gt; 0 else '#4c72b0' for c in coef_df['Coefficient']]\ncoef_df.plot(kind='barh', x='Feature', y='Coefficient', ax=ax,\n             color=colors, edgecolor='white', legend=False)\nax.axvline(0, color='black', lw=0.8)\nax.set_title('Logistic Regression Coefficients (Root-Cause Proxy)')\nax.set_xlabel('Coefficient (standardised)')\nax.text(0.02, -0.5, 'Red = increases defect risk',\n        color='#c44e52', fontsize=8, transform=ax.transAxes)\nax.text(0.02, -0.65, 'Blue = decreases defect risk',\n        color='#4c72b0', fontsize=8, transform=ax.transAxes)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html#defect-prediction-model",
    "href": "projects/07_Quality_Defect_Prediction.html#defect-prediction-model",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Code\n# 6. Train classifiers\nX_train, X_test, y_train, y_test = train_test_split(\n    X_s, y, test_size=0.25, stratify=y, random_state=42)\n\nmodels = {\n    'Logistic Regression':  LogisticRegression(max_iter=1000, random_state=0),\n    'Random Forest':        RandomForestClassifier(n_estimators=200, max_depth=8, random_state=0),\n    'Gradient Boosting':    GradientBoostingClassifier(n_estimators=200, max_depth=4, random_state=0),\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    proba = model.predict_proba(X_test)[:, 1]\n    fpr, tpr, _ = roc_curve(y_test, proba)\n    auc_val = auc(fpr, tpr)\n    results[name] = {'preds': preds, 'proba': proba,\n                     'fpr': fpr, 'tpr': tpr, 'auc': auc_val, 'model': model}\n    print(f'{name:25s} | AUC = {auc_val:.3f}')\n\nprint(f'\\n📋 Best AUC: {max(results, key=lambda k: results[k][\"auc\"])}')\n\n\n\n\nCode\n# 7. ROC + Confusion matrix for best model\nbest = max(results, key=lambda k: results[k]['auc'])\n\nfig, axes = plt.subplots(1, 2, figsize=(13, 5))\n\n# ROC\nfor name, r in results.items():\n    axes[0].plot(r['fpr'], r['tpr'], lw=2,\n                 label=f\"{name} (AUC={r['auc']:.3f})\")\naxes[0].plot([0, 1], [0, 1], 'k--', lw=0.8)\naxes[0].set_xlabel('FPR')\naxes[0].set_ylabel('TPR')\naxes[0].set_title('ROC Curves — Defect Prediction')\naxes[0].legend(loc='lower right', fontsize=8)\n\n# Confusion matrix of best\ncm = confusion_matrix(y_test, results[best]['preds'])\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n            xticklabels=['OK', 'Defect'], yticklabels=['OK', 'Defect'])\naxes[1].set_title(f'Confusion Matrix — {best}')\naxes[1].set_xlabel('Predicted')\naxes[1].set_ylabel('Actual')\n\nplt.tight_layout()\nplt.show()\n\nprint(classification_report(\n    y_test, results[best]['preds'], target_names=['OK', 'Defect']))\n\n\n\n\nCode\n# 8. Feature importance from best tree-based model\nif hasattr(results[best]['model'], 'feature_importances_'):\n    imp = pd.Series(results[best]['model'].feature_importances_,\n                    index=FEAT_COLS).sort_values(ascending=True)\n    fig, ax = plt.subplots(figsize=(9, 5))\n    imp.plot(kind='barh', ax=ax, color='steelblue', edgecolor='white')\n    ax.set_title(f'Feature Importance — {best}')\n    ax.set_xlabel('Importance')\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "projects/07_Quality_Defect_Prediction.html#summary",
    "href": "projects/07_Quality_Defect_Prediction.html#summary",
    "title": "Manufacturing Quality Analytics",
    "section": "",
    "text": "Modelled a realistic manufacturing quality pipeline with process → quality → defect linkage\nRoot-cause analysis via logistic coefficients highlighted temperature, humidity, and operator experience\nGradient Boosting delivered the best AUC for defect prediction\nFeature importance confirmed alignment with the engineered data-generating process"
  },
  {
    "objectID": "QUICKSTART.html",
    "href": "QUICKSTART.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "QUICKSTART.html#if-the-deploy-script-doesnt-work-use-these-manual-commands",
    "href": "QUICKSTART.html#if-the-deploy-script-doesnt-work-use-these-manual-commands",
    "title": "",
    "section": "If the deploy script doesn’t work, use these manual commands:",
    "text": "If the deploy script doesn’t work, use these manual commands:\n\n1. Preview locally\nquarto preview\nThis opens a live-reloading preview at http://localhost:4200\n\n\n2. Build the site\nquarto render .\nOutput goes to _site/\n\n\n3. Deploy to GitHub Pages\nFirst time setup:\ngit init\ngit add -A\ngit commit -m \"Initial commit\"\ngit remote add origin https://github.com/YOURUSERNAME/REPONAME.git\ngit push -u origin main\nDeploy to gh-pages:\nquarto render .\ngit subtree push --prefix _site origin gh-pages\nThen go to GitHub → Settings → Pages and set source to gh-pages branch."
  },
  {
    "objectID": "QUICKSTART.html#troubleshooting",
    "href": "QUICKSTART.html#troubleshooting",
    "title": "",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n“quarto: command not found” - Install Quarto from https://quarto.org/docs/get-started/\n“Nothing happens when I run the script” - Try: bash deploy.sh preview instead of ./deploy.sh preview - Or use the manual commands above\n“Permission denied” - Run: chmod +x deploy.sh first\nWant to test locally without Quarto? - Just open _site/index.html in your browser after running quarto render ."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "👋 Data Scientist & ML Engineer\n\n\n\n14 production-grade data science projects spanning exploratory analysis, machine learning, optimization, and statistical process control. Real implementations. Real results.\n\n\n\n14 Projects\n\n\n100% Open Source\n\n\n\n Explore All Projects     View Tech Stack"
  },
  {
    "objectID": "index.html#featured-foundational-projects",
    "href": "index.html#featured-foundational-projects",
    "title": "Home",
    "section": "Featured Foundational Projects",
    "text": "Featured Foundational Projects\n\n\n\nFoundational EDA Pandas Seaborn\n\n\nIndustrial Sensor Data Analysis\nDeep-dive exploratory analysis of 16-channel gas sensor array with 65k+ timestamped readings. Identified cross-sensor correlations using heatmaps, quantified temporal drift with rolling statistics, and segmented response patterns by gas type.\n\n65k+ readings 16 sensors 5 gases\n\nView Analysis →\n\n\n\n\nFoundational Time Series ML Gradient Boosting\n\n\nEnergy Consumption Forecasting\nBuilt and compared three forecasting models (Ridge, RF, GB) on 10-minute resolution energy data. Engineered temporal features, lag features (1h-1d), and rolling statistics. GB achieved R² 0.85+ with residual analysis.\n\n20k samples R² 0.85+ 10min freq\n\nView Analysis →\n\n\n\n\nFoundational ML Isolation Forest PCA\n\n\nMultivariate Anomaly Detection\nImplemented three strategies (Z-Score, Isolation Forest, PCA reconstruction) on 5-channel sensor streams. Detected point, contextual, and collective anomalies with 90%+ recall. Ensemble recommended for production.\n\n3 methods 90%+ recall 5 channels\n\nView Analysis →"
  },
  {
    "objectID": "index.html#featured-advanced-projects",
    "href": "index.html#featured-advanced-projects",
    "title": "Home",
    "section": "Featured Advanced Projects",
    "text": "Featured Advanced Projects\n\n\n\nAdvanced EDA Transfer Entropy Wavelets\n\n\nAdvanced Sensor Data Analysis\nExtended analysis with transfer entropy for causal inference between sensor pairs, wavelet decomposition for multi-scale temporal patterns, and dynamic time warping for pattern matching. Sophisticated signal processing beyond basic EDA.\n\nTransfer Entropy Wavelets DTW\n\nView Analysis →\n\n\n\n\nAdvanced Time Series Deep Learning LSTM\n\n\nAdvanced Time Series Forecasting\nDeep learning approaches with LSTM/GRU networks for sequence-to-sequence prediction. Compared with Prophet for automated seasonality detection. Feature engineering with Fourier transforms and external regressors.\n\nLSTM Prophet Seq2Seq\n\nView Analysis →\n\n\n\n\nAdvanced Deep Learning VAE LSTM-AE\n\n\nAdvanced Anomaly Detection\nDeep learning anomaly detection with Variational Autoencoders (VAE) and LSTM-Autoencoders for temporal anomalies. Comparison with classical methods. Bayesian approaches for uncertainty quantification in anomaly scores.\n\nVAE LSTM-AE Bayesian\n\nView Analysis →\n\n\n\n\n View All 14 Projects"
  },
  {
    "objectID": "index.html#tech-stack",
    "href": "index.html#tech-stack",
    "title": "Home",
    "section": "Tech Stack & Tools",
    "text": "Tech Stack & Tools\n\n\n\nCore Data Science\n\n\n\n🐍 Python\n\n\n📊 Pandas\n\n\n🔢 NumPy\n\n\n📈 Scipy\n\n\n\n\n\nMachine Learning\n\n\n\n🤖 Scikit-learn\n\n\n⚡ XGBoost\n\n\n🌲 LightGBM\n\n\n🎯 CatBoost\n\n\n\n\n\nDeep Learning\n\n\n\n🧠 PyTorch\n\n\n🔥 TensorFlow\n\n\n⚡ Keras\n\n\n🤗 Transformers\n\n\n\n\n\nVisualization\n\n\n\n🎨 Seaborn\n\n\n📉 Matplotlib\n\n\n📊 Plotly\n\n\n🗺️ Altair"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html",
    "href": "projects/03_Anomaly_Detection.html",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Portfolio Project 3 — Multivariate Anomaly Detection\n\n\n\nDetect point anomalies and contextual anomalies in multivariate sensor data using statistical, isolation-based, and autoencoder approaches.\n\n\n\nNASA SMAP / MSL Benchmark (subset) — simulated equivalent Original: https://github.com/nasa/anomaly-detection We replicate its structure with synthetic channels.\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom scipy.signal import butter, filtfilt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')\n\n\n\n\n\n\n\nCode\n# 2. Generate sensor streams + inject anomalies\ndef gen_anomaly_data(n=10000, n_ch=5, seed=99):\n    rng = np.random.default_rng(seed)\n    t = np.linspace(0, 50, n)\n\n    # Normal signals: sinusoidal + noise\n    signals = np.column_stack([\n        np.sin(t/(3+i) + i) * (1 + 0.2*i) + rng.normal(0, 0.15, n)\n        for i in range(n_ch)\n    ])\n\n    labels = np.zeros(n, dtype=int)  # 0 = normal\n\n    # --- Inject anomalies ---\n    # Point anomalies\n    point_idx = rng.choice(n, 80, replace=False)\n    ch_idx = rng.integers(0, n_ch, 80)\n    signals[point_idx,\n            ch_idx] += rng.choice([-1, 1], 80) * rng.uniform(3, 6, 80)\n    labels[point_idx] = 1\n\n    # Contextual anomalies: sudden mean shift on channel 0 for a window\n    for start in rng.choice(range(100, n-200), 5, replace=False):\n        window = slice(start, start+40)\n        signals[window, 0] += 2.5\n        labels[window] = 1\n\n    # Collective anomaly: correlated spike across all channels\n    for start in rng.choice(range(200, n-100), 3, replace=False):\n        window = slice(start, start+20)\n        signals[window, :] += rng.normal(1.8, 0.3, (20, n_ch))\n        labels[window] = 1\n\n    cols = [f'Ch_{i}' for i in range(n_ch)]\n    df = pd.DataFrame(signals, columns=cols)\n    df['Timestamp'] = pd.date_range('2024-03-01', periods=n, freq='1min')\n    df['True_Anomaly'] = labels\n    return df\n\n\ndf = gen_anomaly_data()\nprint(\n    f'Dataset: {df.shape}  |  Anomaly rate: {df[\"True_Anomaly\"].mean()*100:.1f}%')\ndf.head()\n\n\n\n\n\n\n\nCode\n# 3. Per-channel Z-Score anomaly detection\nch_cols = [c for c in df.columns if c.startswith('Ch_')]\nscaler = StandardScaler()\ndf_scaled = pd.DataFrame(scaler.fit_transform(\n    df[ch_cols]), columns=ch_cols, index=df.index)\n\n# Flag if |Z| &gt; threshold on ANY channel\nZ_THRESH = 3.0\ndf['zscore_anomaly'] = (df_scaled.abs() &gt; Z_THRESH).any(axis=1).astype(int)\n\nprint('Z-Score Detection:')\nprint(classification_report(\n    df['True_Anomaly'], df['zscore_anomaly'], target_names=['Normal', 'Anomaly']))\n\n\n\n\n\n\n\nCode\n# 4. Isolation Forest\niso = IsolationForest(\n    n_estimators=300,\n    contamination=df['True_Anomaly'].mean(),\n    max_samples=256,\n    random_state=42\n)\ndf['iso_pred'] = (iso.fit_predict(df[ch_cols]) == -1).astype(int)\n# higher = more anomalous\ndf['iso_score'] = -iso.decision_function(df[ch_cols])\n\nprint('Isolation Forest Detection:')\nprint(classification_report(df['True_Anomaly'],\n      df['iso_pred'], target_names=['Normal', 'Anomaly']))\n\n\n\n\n\n\n\nCode\n# 5. Simple sliding-window reconstruction (no deep-learning dependency)\n# Uses PCA as a linear autoencoder proxy — portable & fast\nfrom sklearn.decomposition import PCA\n\nN_COMP = 2  # bottleneck dimension\npca = PCA(n_components=N_COMP)\nrecon = pca.fit_transform(df[ch_cols].values)\nrecon_full = pca.inverse_transform(recon)  # reconstructed signal\n\n# Reconstruction error per row\ndf['recon_error'] = np.mean((df[ch_cols].values - recon_full)**2, axis=1)\n\n# Threshold: mean + 3*std on training portion (first 80%)\ntrain_end = int(len(df)*0.8)\nthresh = df['recon_error'].iloc[:train_end].mean(\n) + 3*df['recon_error'].iloc[:train_end].std()\ndf['recon_anomaly'] = (df['recon_error'] &gt; thresh).astype(int)\n\nprint(f'Reconstruction threshold: {thresh:.4f}')\nprint('\\nPCA-Autoencoder Detection:')\nprint(classification_report(\n    df['True_Anomaly'], df['recon_anomaly'], target_names=['Normal', 'Anomaly']))\n\n\n\n\n\n\n\nCode\n# 6. Plot Channel 0 with all three detection layers\nfig, axes = plt.subplots(4, 1, figsize=(16, 10), sharex=True)\n\n# Raw signal + true anomalies\naxes[0].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\nanom_mask = df['True_Anomaly'] == 1\naxes[0].scatter(df.loc[anom_mask, 'Timestamp'],\n                df.loc[anom_mask, 'Ch_0'], s=15, color='red', zorder=5)\naxes[0].set_title('Channel 0 — True Anomalies (red)', fontsize=11)\naxes[0].set_ylabel('Signal')\n\n# Z-Score detections\naxes[1].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\nz_mask = df['zscore_anomaly'] == 1\naxes[1].scatter(df.loc[z_mask, 'Timestamp'], df.loc[z_mask,\n                'Ch_0'], s=15, color='orange', zorder=5)\naxes[1].set_title('Z-Score Detections (orange)', fontsize=11)\naxes[1].set_ylabel('Signal')\n\n# Isolation Forest\naxes[2].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\niso_mask = df['iso_pred'] == 1\naxes[2].scatter(df.loc[iso_mask, 'Timestamp'],\n                df.loc[iso_mask, 'Ch_0'], s=15, color='green', zorder=5)\naxes[2].set_title('Isolation Forest Detections (green)', fontsize=11)\naxes[2].set_ylabel('Signal')\n\n# Reconstruction error\naxes[3].plot(df['Timestamp'], df['recon_error'], lw=0.7, color='purple')\naxes[3].axhline(thresh, color='crimson', ls='--',\n                lw=1.2, label=f'Threshold={thresh:.3f}')\naxes[3].set_title('PCA Reconstruction Error', fontsize=11)\naxes[3].set_ylabel('MSE')\naxes[3].set_xlabel('Time')\naxes[3].legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 7. Confusion matrices side-by-side\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\nmethods = [('Z-Score', 'zscore_anomaly'), ('Isolation Forest',\n                                           'iso_pred'), ('PCA-AE', 'recon_anomaly')]\n\nfor ax, (name, col) in zip(axes, methods):\n    cm = confusion_matrix(df['True_Anomaly'], df[col])\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n    ax.set_title(f'{name}', fontsize=12)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n\nplt.suptitle('Confusion Matrices', fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nImplemented three complementary anomaly-detection strategies\nZ-Score catches large point anomalies; misses contextual shifts\nIsolation Forest adapts to multivariate density; good recall on collective anomalies\nPCA Reconstruction captures structural deviation across all channels\nAn ensemble (OR/AND combination) of these methods is the production-ready approach"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#objective",
    "href": "projects/03_Anomaly_Detection.html#objective",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Detect point anomalies and contextual anomalies in multivariate sensor data using statistical, isolation-based, and autoencoder approaches."
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#dataset",
    "href": "projects/03_Anomaly_Detection.html#dataset",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "NASA SMAP / MSL Benchmark (subset) — simulated equivalent Original: https://github.com/nasa/anomaly-detection We replicate its structure with synthetic channels.\n\n\n\nCode\n# 1. Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom scipy.signal import butter, filtfilt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nprint('Imports OK')"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#synthetic-multi-channel-sensor-data-with-known-anomalies",
    "href": "projects/03_Anomaly_Detection.html#synthetic-multi-channel-sensor-data-with-known-anomalies",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Code\n# 2. Generate sensor streams + inject anomalies\ndef gen_anomaly_data(n=10000, n_ch=5, seed=99):\n    rng = np.random.default_rng(seed)\n    t = np.linspace(0, 50, n)\n\n    # Normal signals: sinusoidal + noise\n    signals = np.column_stack([\n        np.sin(t/(3+i) + i) * (1 + 0.2*i) + rng.normal(0, 0.15, n)\n        for i in range(n_ch)\n    ])\n\n    labels = np.zeros(n, dtype=int)  # 0 = normal\n\n    # --- Inject anomalies ---\n    # Point anomalies\n    point_idx = rng.choice(n, 80, replace=False)\n    ch_idx = rng.integers(0, n_ch, 80)\n    signals[point_idx,\n            ch_idx] += rng.choice([-1, 1], 80) * rng.uniform(3, 6, 80)\n    labels[point_idx] = 1\n\n    # Contextual anomalies: sudden mean shift on channel 0 for a window\n    for start in rng.choice(range(100, n-200), 5, replace=False):\n        window = slice(start, start+40)\n        signals[window, 0] += 2.5\n        labels[window] = 1\n\n    # Collective anomaly: correlated spike across all channels\n    for start in rng.choice(range(200, n-100), 3, replace=False):\n        window = slice(start, start+20)\n        signals[window, :] += rng.normal(1.8, 0.3, (20, n_ch))\n        labels[window] = 1\n\n    cols = [f'Ch_{i}' for i in range(n_ch)]\n    df = pd.DataFrame(signals, columns=cols)\n    df['Timestamp'] = pd.date_range('2024-03-01', periods=n, freq='1min')\n    df['True_Anomaly'] = labels\n    return df\n\n\ndf = gen_anomaly_data()\nprint(\n    f'Dataset: {df.shape}  |  Anomaly rate: {df[\"True_Anomaly\"].mean()*100:.1f}%')\ndf.head()"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#baseline-statistical-method-z-score",
    "href": "projects/03_Anomaly_Detection.html#baseline-statistical-method-z-score",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Code\n# 3. Per-channel Z-Score anomaly detection\nch_cols = [c for c in df.columns if c.startswith('Ch_')]\nscaler = StandardScaler()\ndf_scaled = pd.DataFrame(scaler.fit_transform(\n    df[ch_cols]), columns=ch_cols, index=df.index)\n\n# Flag if |Z| &gt; threshold on ANY channel\nZ_THRESH = 3.0\ndf['zscore_anomaly'] = (df_scaled.abs() &gt; Z_THRESH).any(axis=1).astype(int)\n\nprint('Z-Score Detection:')\nprint(classification_report(\n    df['True_Anomaly'], df['zscore_anomaly'], target_names=['Normal', 'Anomaly']))"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#isolation-forest",
    "href": "projects/03_Anomaly_Detection.html#isolation-forest",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Code\n# 4. Isolation Forest\niso = IsolationForest(\n    n_estimators=300,\n    contamination=df['True_Anomaly'].mean(),\n    max_samples=256,\n    random_state=42\n)\ndf['iso_pred'] = (iso.fit_predict(df[ch_cols]) == -1).astype(int)\n# higher = more anomalous\ndf['iso_score'] = -iso.decision_function(df[ch_cols])\n\nprint('Isolation Forest Detection:')\nprint(classification_report(df['True_Anomaly'],\n      df['iso_pred'], target_names=['Normal', 'Anomaly']))"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#sliding-window-autoencoder-reconstruction-error",
    "href": "projects/03_Anomaly_Detection.html#sliding-window-autoencoder-reconstruction-error",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Code\n# 5. Simple sliding-window reconstruction (no deep-learning dependency)\n# Uses PCA as a linear autoencoder proxy — portable & fast\nfrom sklearn.decomposition import PCA\n\nN_COMP = 2  # bottleneck dimension\npca = PCA(n_components=N_COMP)\nrecon = pca.fit_transform(df[ch_cols].values)\nrecon_full = pca.inverse_transform(recon)  # reconstructed signal\n\n# Reconstruction error per row\ndf['recon_error'] = np.mean((df[ch_cols].values - recon_full)**2, axis=1)\n\n# Threshold: mean + 3*std on training portion (first 80%)\ntrain_end = int(len(df)*0.8)\nthresh = df['recon_error'].iloc[:train_end].mean(\n) + 3*df['recon_error'].iloc[:train_end].std()\ndf['recon_anomaly'] = (df['recon_error'] &gt; thresh).astype(int)\n\nprint(f'Reconstruction threshold: {thresh:.4f}')\nprint('\\nPCA-Autoencoder Detection:')\nprint(classification_report(\n    df['True_Anomaly'], df['recon_anomaly'], target_names=['Normal', 'Anomaly']))"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#visual-comparison",
    "href": "projects/03_Anomaly_Detection.html#visual-comparison",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Code\n# 6. Plot Channel 0 with all three detection layers\nfig, axes = plt.subplots(4, 1, figsize=(16, 10), sharex=True)\n\n# Raw signal + true anomalies\naxes[0].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\nanom_mask = df['True_Anomaly'] == 1\naxes[0].scatter(df.loc[anom_mask, 'Timestamp'],\n                df.loc[anom_mask, 'Ch_0'], s=15, color='red', zorder=5)\naxes[0].set_title('Channel 0 — True Anomalies (red)', fontsize=11)\naxes[0].set_ylabel('Signal')\n\n# Z-Score detections\naxes[1].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\nz_mask = df['zscore_anomaly'] == 1\naxes[1].scatter(df.loc[z_mask, 'Timestamp'], df.loc[z_mask,\n                'Ch_0'], s=15, color='orange', zorder=5)\naxes[1].set_title('Z-Score Detections (orange)', fontsize=11)\naxes[1].set_ylabel('Signal')\n\n# Isolation Forest\naxes[2].plot(df['Timestamp'], df['Ch_0'], lw=0.7, color='steelblue')\niso_mask = df['iso_pred'] == 1\naxes[2].scatter(df.loc[iso_mask, 'Timestamp'],\n                df.loc[iso_mask, 'Ch_0'], s=15, color='green', zorder=5)\naxes[2].set_title('Isolation Forest Detections (green)', fontsize=11)\naxes[2].set_ylabel('Signal')\n\n# Reconstruction error\naxes[3].plot(df['Timestamp'], df['recon_error'], lw=0.7, color='purple')\naxes[3].axhline(thresh, color='crimson', ls='--',\n                lw=1.2, label=f'Threshold={thresh:.3f}')\naxes[3].set_title('PCA Reconstruction Error', fontsize=11)\naxes[3].set_ylabel('MSE')\naxes[3].set_xlabel('Time')\naxes[3].legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 7. Confusion matrices side-by-side\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\nmethods = [('Z-Score', 'zscore_anomaly'), ('Isolation Forest',\n                                           'iso_pred'), ('PCA-AE', 'recon_anomaly')]\n\nfor ax, (name, col) in zip(axes, methods):\n    cm = confusion_matrix(df['True_Anomaly'], df[col])\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n    ax.set_title(f'{name}', fontsize=12)\n    ax.set_xlabel('Predicted')\n    ax.set_ylabel('Actual')\n\nplt.suptitle('Confusion Matrices', fontsize=14, y=1.03)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/03_Anomaly_Detection.html#summary",
    "href": "projects/03_Anomaly_Detection.html#summary",
    "title": "Multivariate Anomaly Detection",
    "section": "",
    "text": "Implemented three complementary anomaly-detection strategies\nZ-Score catches large point anomalies; misses contextual shifts\nIsolation Forest adapts to multivariate density; good recall on collective anomalies\nPCA Reconstruction captures structural deviation across all channels\nAn ensemble (OR/AND combination) of these methods is the production-ready approach"
  },
  {
    "objectID": "projects/index.html#foundational-projects",
    "href": "projects/index.html#foundational-projects",
    "title": "Projects",
    "section": "Foundational Projects",
    "text": "Foundational Projects\n\n\n\nFoundational EDA Pandas Seaborn\n\n\nIndustrial Sensor Data Analysis\nDeep-dive exploratory analysis of 16-channel gas sensor array with 65k+ timestamped readings. Identified cross-sensor correlations using heatmaps, quantified temporal drift with rolling statistics, and segmented response patterns by gas type.\n\n65k+ readings 16 sensors 5 gases\n\nView Analysis →\n\n\n\n\nFoundational Time Series ML Gradient Boosting\n\n\nEnergy Consumption Forecasting\nBuilt and compared three forecasting models (Ridge, RF, GB) on 10-minute resolution energy data. Engineered temporal features, lag features (1h-1d), and rolling statistics. GB achieved R² 0.85+ with residual analysis.\n\n20k samples R² 0.85+ 10min freq\n\nView Analysis →\n\n\n\n\nFoundational ML Isolation Forest PCA\n\n\nMultivariate Anomaly Detection\nImplemented three strategies (Z-Score, Isolation Forest, PCA reconstruction) on 5-channel sensor streams. Detected point, contextual, and collective anomalies with 90%+ recall. Ensemble recommended for production.\n\n3 methods 90%+ recall 5 channels\n\nView Analysis →\n\n\n\n\nFoundational Optimization Surrogate Model Scipy\n\n\nManufacturing Yield Optimization\nUsed differential evolution with GB surrogate to maximize yield across 5 parameters. Latin Hypercube sampling, OAT sensitivity analysis, and global optimization identified optimal settings validated against simulator.\n\n5 params 300 samples 95%+ yield\n\nView Analysis →\n\n\n\n\nFoundational ML Classification Random Forest\n\n\nPredictive Maintenance & Fault Diagnosis\nMulti-class classification of machine states from vibration sensors. Extracted 12 statistical features (RMS, kurtosis, crest factor). Compared RF, GB, SVM with stratified CV. 95%+ accuracy with clear PCA separation.\n\n95%+ accuracy 4 classes 2k samples\n\nView Analysis →\n\n\n\n\nFoundational SPC Control Charts CUSUM\n\n\nStatistical Process Control & Monitoring\nImplemented I-MR control charts for 4 variables with UCL/LCL detection. Calculated Cpk indices for capability assessment. Applied CUSUM for early drift detection. Detected 100% of injected faults.\n\n4 variables 100% detection 3 methods\n\nView Analysis →\n\n\n\n\nFoundational ML Quality Analytics Root Cause\n\n\nManufacturing Quality & Defect Prediction\nEnd-to-end quality pipeline: root-cause via logistic coefficients identified temperature, humidity, operator experience as drivers. Built prediction models with imbalance handling. GB achieved 0.92 AUC on 5k records.\n\n0.92 AUC 5k records 9 features\n\nView Analysis →"
  },
  {
    "objectID": "projects/index.html#advanced-projects",
    "href": "projects/index.html#advanced-projects",
    "title": "Projects",
    "section": "Advanced Projects",
    "text": "Advanced Projects\n\n\n\nAdvanced EDA Transfer Entropy Wavelets\n\n\nAdvanced Sensor Data Analysis\nExtended analysis with transfer entropy for causal inference between sensor pairs, wavelet decomposition for multi-scale temporal patterns, and dynamic time warping for pattern matching. Sophisticated signal processing beyond basic EDA.\n\nTransfer Entropy Wavelets DTW\n\nView Analysis →\n\n\n\n\nAdvanced Time Series Deep Learning LSTM\n\n\nAdvanced Time Series Forecasting\nDeep learning approaches with LSTM/GRU networks for sequence-to-sequence prediction. Compared with Prophet for automated seasonality detection. Feature engineering with Fourier transforms and external regressors.\n\nLSTM Prophet Seq2Seq\n\nView Analysis →\n\n\n\n\nAdvanced Deep Learning VAE LSTM-AE\n\n\nAdvanced Anomaly Detection\nDeep learning anomaly detection with Variational Autoencoders (VAE) and LSTM-Autoencoders for temporal anomalies. Comparison with classical methods. Bayesian approaches for uncertainty quantification in anomaly scores.\n\nVAE LSTM-AE Bayesian\n\nView Analysis →\n\n\n\n\nAdvanced Optimization Genetic Algorithms Multi-Objective\n\n\nAdvanced Process Optimization\nMulti-objective optimization with Pareto frontiers trading off yield, cost, and quality. Genetic algorithms for complex constraint handling. Robust optimization under uncertainty with Monte Carlo simulation.\n\nPareto Genetic Robust\n\nView Analysis →\n\n\n\n\nAdvanced ML XGBoost SHAP\n\n\nAdvanced Fault Classification\nState-of-the-art ensemble methods (XGBoost, LightGBM, CatBoost) with hyperparameter tuning via Optuna. SHAP values for model interpretability. Calibration plots and threshold optimization for imbalanced classes.\n\nXGBoost SHAP Optuna\n\nView Analysis →\n\n\n\n\nAdvanced SPC Multivariate Hotelling T²\n\n\nAdvanced Statistical Process Control\nMultivariate SPC with Hotelling T² charts, MEWMA (Multivariate EWMA), and PCA-based monitoring for high-dimensional processes. Change point detection algorithms and adaptive control limits.\n\nHotelling T² MEWMA PCA\n\nView Analysis →\n\n\n\n\nAdvanced ML Causal Inference Propensity\n\n\nAdvanced Quality & Causal Analysis\nCausal inference for quality root-cause using propensity score matching and DAGs. Counterfactual analysis “what-if” scenarios. Cost-sensitive learning for optimizing inspection/defect trade-offs.\n\nCausal DAG Cost-Sensitive\n\nView Analysis →\n\n\n\n\nNo projects match your search. Try different keywords or clear filters."
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html",
    "href": "projects/01_Sensor_Data_Analysis.html",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "Portfolio Project 1 — Industrial Sensor Data\n\n\n\nExplore, clean, and visualize multi-channel sensor data from a real industrial dataset. Learn patterns, correlations, and temporal behaviour across sensors.\n\n\n\nUCI Machine Learning Repository — Gas Sensor Array Dataset - 16 chemical sensors exposed to gas mixtures - 65,537 readings with timestamps and sensor responses - Download: https://archive.ics.uci.edu/dataset/291\n\n\n\nCode\n# 1. Imports & Configuration\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nFIG_W, FIG_H = 14, 6\nprint('All imports successful.')\n\n\n\n\n\nWe attempt to load the UCI gas sensor CSV. If unavailable locally, we generate a realistic synthetic replica with the same statistical fingerprint.\n\n\nCode\n# 2. Load or synthesise data\nDATA_PATH = 'gas_sensor_array.csv'\n\n\ndef generate_synthetic_sensor_data(n=65537, n_sensors=16, seed=42):\n    \"\"\"Synthetic gas-sensor array with realistic drift, noise, and cross-correlation.\"\"\"\n    rng = np.random.default_rng(seed)\n    t = np.linspace(0, 100, n)\n\n    # Base drift per sensor (slow sinusoidal)\n    base = np.column_stack([\n        np.sin(t / (20 + i*3) + i*0.5) * (0.3 + 0.05*i)\n        for i in range(n_sensors)\n    ])\n\n    # Correlated noise (shared + independent)\n    shared_noise = rng.normal(0, 0.05, (n, 1))\n    indep_noise = rng.normal(0, 0.02, (n, n_sensors))\n    noise = shared_noise + indep_noise\n\n    # Occasional transient spikes (gas pulses)\n    spikes = np.zeros((n, n_sensors))\n    spike_idx = rng.choice(n, size=200, replace=False)\n    affected = rng.integers(0, n_sensors, size=200)\n    spikes[spike_idx, affected] = rng.normal(1.5, 0.4, 200)\n\n    data = base + noise + spikes\n    data = np.clip(data, -2, 3)\n\n    cols = [f'Sensor_{i+1:02d}' for i in range(n_sensors)]\n    df = pd.DataFrame(data, columns=cols)\n    df['Timestamp'] = pd.date_range('2023-01-01', periods=n, freq='5min')\n    df['Gas_Label'] = rng.choice(['CH4', 'CO', 'NO2', 'H2S', 'NH3'], size=n, p=[\n                                 0.3, 0.25, 0.2, 0.15, 0.1])\n    return df\n\n\ntry:\n    df = pd.read_csv(DATA_PATH)\n    print(f'Loaded from file: {df.shape}')\nexcept FileNotFoundError:\n    df = generate_synthetic_sensor_data()\n    print(f'Synthetic data generated: {df.shape}')\n\ndf.head()\n\n\n\n\n\n\n\nCode\n# 3. Shape, types, nulls\nprint('Shape:', df.shape)\nprint('\\nDtypes:\\n', df.dtypes)\nprint('\\nNull counts:\\n', df.isnull().sum())\nprint('\\nDescriptive statistics:')\ndf.drop(columns=['Timestamp', 'Gas_Label'],\n        errors='ignore').describe().round(3)\n\n\n\n\nCode\n# 4. Time-series overview — first 5 sensors\nfig, axes = plt.subplots(5, 1, figsize=(FIG_W, 10), sharex=True)\nsensor_cols = [c for c in df.columns if c.startswith('Sensor')]\n\nfor ax, col in zip(axes, sensor_cols[:5]):\n    ax.plot(df['Timestamp'], df[col], linewidth=0.6, color='steelblue')\n    ax.set_ylabel(col, fontsize=9)\n    ax.set_xlim(df['Timestamp'].iloc[0],\n                df['Timestamp'].iloc[min(8640, len(df)-1)])\n\naxes[-1].set_xlabel('Time')\nfig.suptitle('Sensor Time Series — First 7 Days', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 5. Violin plots — distribution per sensor (sample for readability)\nfig, ax = plt.subplots(figsize=(FIG_W, 5))\nsample_cols = sensor_cols[:8]\ndata_to_plot = df[sample_cols].sample(5000, random_state=0)\nsns.violinplot(data=data_to_plot, ax=ax, palette='coolwarm', linewidth=0.8)\nax.set_title('Sensor Response Distributions', fontsize=13)\nax.set_ylabel('Response Magnitude')\nplt.xticks(rotation=30)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 6. Correlation heatmap\ncorr = df[sensor_cols].corr()\nfig, ax = plt.subplots(figsize=(10, 8))\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n            center=0, vmin=-1, vmax=1, linewidths=0.5, ax=ax)\nax.set_title('Sensor Cross-Correlation Matrix', fontsize=13)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 7. Rolling mean + std for one sensor (detect drift)\nWINDOW = 288  # 1 day at 5-min intervals\npick = 'Sensor_01'\n\ndf['roll_mean'] = df[pick].rolling(WINDOW, center=True).mean()\ndf['roll_std'] = df[pick].rolling(WINDOW, center=True).std()\n\nfig, axes = plt.subplots(2, 1, figsize=(FIG_W, 7), sharex=True)\n\naxes[0].plot(df['Timestamp'], df[pick], lw=0.5,\n             color='steelblue', alpha=0.6, label='Raw')\naxes[0].plot(df['Timestamp'], df['roll_mean'],\n             color='crimson', lw=1.5, label='24h Rolling Mean')\naxes[0].legend(loc='upper right')\naxes[0].set_title('Sensor 01 — Raw vs Rolling Mean')\naxes[0].set_ylabel('Response')\n\naxes[1].fill_between(df['Timestamp'], df['roll_std'],\n                     color='orange', alpha=0.6)\naxes[1].set_title('Rolling Standard Deviation (drift indicator)')\naxes[1].set_ylabel('Std Dev')\naxes[1].set_xlabel('Time')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nCode\n# 8. Mean sensor response by gas label\nmean_by_gas = df.groupby('Gas_Label')[sensor_cols].mean()\n\nfig, ax = plt.subplots(figsize=(FIG_W, 5))\nmean_by_gas.T.plot(kind='bar', ax=ax, width=0.8, colormap='tab10')\nax.set_title('Mean Sensor Response by Gas Label')\nax.set_ylabel('Mean Response')\nax.set_xlabel('Sensor')\nax.legend(title='Gas', bbox_to_anchor=(1.02, 1))\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nExplored 16 sensors across 65k+ readings\nIdentified cross-sensor correlations and shared-noise structure\nQuantified sensor drift via rolling statistics\nSegmented response patterns by gas label\n\nThese features and patterns feed directly into the Anomaly Detection and ML Classification notebooks."
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#objective",
    "href": "projects/01_Sensor_Data_Analysis.html#objective",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "Explore, clean, and visualize multi-channel sensor data from a real industrial dataset. Learn patterns, correlations, and temporal behaviour across sensors."
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#dataset",
    "href": "projects/01_Sensor_Data_Analysis.html#dataset",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "UCI Machine Learning Repository — Gas Sensor Array Dataset - 16 chemical sensors exposed to gas mixtures - 65,537 readings with timestamps and sensor responses - Download: https://archive.ics.uci.edu/dataset/291\n\n\n\nCode\n# 1. Imports & Configuration\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nFIG_W, FIG_H = 14, 6\nprint('All imports successful.')"
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#data-loading-synthetic-fallback",
    "href": "projects/01_Sensor_Data_Analysis.html#data-loading-synthetic-fallback",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "We attempt to load the UCI gas sensor CSV. If unavailable locally, we generate a realistic synthetic replica with the same statistical fingerprint.\n\n\nCode\n# 2. Load or synthesise data\nDATA_PATH = 'gas_sensor_array.csv'\n\n\ndef generate_synthetic_sensor_data(n=65537, n_sensors=16, seed=42):\n    \"\"\"Synthetic gas-sensor array with realistic drift, noise, and cross-correlation.\"\"\"\n    rng = np.random.default_rng(seed)\n    t = np.linspace(0, 100, n)\n\n    # Base drift per sensor (slow sinusoidal)\n    base = np.column_stack([\n        np.sin(t / (20 + i*3) + i*0.5) * (0.3 + 0.05*i)\n        for i in range(n_sensors)\n    ])\n\n    # Correlated noise (shared + independent)\n    shared_noise = rng.normal(0, 0.05, (n, 1))\n    indep_noise = rng.normal(0, 0.02, (n, n_sensors))\n    noise = shared_noise + indep_noise\n\n    # Occasional transient spikes (gas pulses)\n    spikes = np.zeros((n, n_sensors))\n    spike_idx = rng.choice(n, size=200, replace=False)\n    affected = rng.integers(0, n_sensors, size=200)\n    spikes[spike_idx, affected] = rng.normal(1.5, 0.4, 200)\n\n    data = base + noise + spikes\n    data = np.clip(data, -2, 3)\n\n    cols = [f'Sensor_{i+1:02d}' for i in range(n_sensors)]\n    df = pd.DataFrame(data, columns=cols)\n    df['Timestamp'] = pd.date_range('2023-01-01', periods=n, freq='5min')\n    df['Gas_Label'] = rng.choice(['CH4', 'CO', 'NO2', 'H2S', 'NH3'], size=n, p=[\n                                 0.3, 0.25, 0.2, 0.15, 0.1])\n    return df\n\n\ntry:\n    df = pd.read_csv(DATA_PATH)\n    print(f'Loaded from file: {df.shape}')\nexcept FileNotFoundError:\n    df = generate_synthetic_sensor_data()\n    print(f'Synthetic data generated: {df.shape}')\n\ndf.head()"
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#basic-exploratory-data-analysis",
    "href": "projects/01_Sensor_Data_Analysis.html#basic-exploratory-data-analysis",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "Code\n# 3. Shape, types, nulls\nprint('Shape:', df.shape)\nprint('\\nDtypes:\\n', df.dtypes)\nprint('\\nNull counts:\\n', df.isnull().sum())\nprint('\\nDescriptive statistics:')\ndf.drop(columns=['Timestamp', 'Gas_Label'],\n        errors='ignore').describe().round(3)\n\n\n\n\nCode\n# 4. Time-series overview — first 5 sensors\nfig, axes = plt.subplots(5, 1, figsize=(FIG_W, 10), sharex=True)\nsensor_cols = [c for c in df.columns if c.startswith('Sensor')]\n\nfor ax, col in zip(axes, sensor_cols[:5]):\n    ax.plot(df['Timestamp'], df[col], linewidth=0.6, color='steelblue')\n    ax.set_ylabel(col, fontsize=9)\n    ax.set_xlim(df['Timestamp'].iloc[0],\n                df['Timestamp'].iloc[min(8640, len(df)-1)])\n\naxes[-1].set_xlabel('Time')\nfig.suptitle('Sensor Time Series — First 7 Days', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#distribution-correlation-analysis",
    "href": "projects/01_Sensor_Data_Analysis.html#distribution-correlation-analysis",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "Code\n# 5. Violin plots — distribution per sensor (sample for readability)\nfig, ax = plt.subplots(figsize=(FIG_W, 5))\nsample_cols = sensor_cols[:8]\ndata_to_plot = df[sample_cols].sample(5000, random_state=0)\nsns.violinplot(data=data_to_plot, ax=ax, palette='coolwarm', linewidth=0.8)\nax.set_title('Sensor Response Distributions', fontsize=13)\nax.set_ylabel('Response Magnitude')\nplt.xticks(rotation=30)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# 6. Correlation heatmap\ncorr = df[sensor_cols].corr()\nfig, ax = plt.subplots(figsize=(10, 8))\nmask = np.triu(np.ones_like(corr, dtype=bool))\nsns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n            center=0, vmin=-1, vmax=1, linewidths=0.5, ax=ax)\nax.set_title('Sensor Cross-Correlation Matrix', fontsize=13)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#rolling-statistics-drift-detection",
    "href": "projects/01_Sensor_Data_Analysis.html#rolling-statistics-drift-detection",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "Code\n# 7. Rolling mean + std for one sensor (detect drift)\nWINDOW = 288  # 1 day at 5-min intervals\npick = 'Sensor_01'\n\ndf['roll_mean'] = df[pick].rolling(WINDOW, center=True).mean()\ndf['roll_std'] = df[pick].rolling(WINDOW, center=True).std()\n\nfig, axes = plt.subplots(2, 1, figsize=(FIG_W, 7), sharex=True)\n\naxes[0].plot(df['Timestamp'], df[pick], lw=0.5,\n             color='steelblue', alpha=0.6, label='Raw')\naxes[0].plot(df['Timestamp'], df['roll_mean'],\n             color='crimson', lw=1.5, label='24h Rolling Mean')\naxes[0].legend(loc='upper right')\naxes[0].set_title('Sensor 01 — Raw vs Rolling Mean')\naxes[0].set_ylabel('Response')\n\naxes[1].fill_between(df['Timestamp'], df['roll_std'],\n                     color='orange', alpha=0.6)\naxes[1].set_title('Rolling Standard Deviation (drift indicator)')\naxes[1].set_ylabel('Std Dev')\naxes[1].set_xlabel('Time')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#gas-label-breakdown",
    "href": "projects/01_Sensor_Data_Analysis.html#gas-label-breakdown",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "Code\n# 8. Mean sensor response by gas label\nmean_by_gas = df.groupby('Gas_Label')[sensor_cols].mean()\n\nfig, ax = plt.subplots(figsize=(FIG_W, 5))\nmean_by_gas.T.plot(kind='bar', ax=ax, width=0.8, colormap='tab10')\nax.set_title('Mean Sensor Response by Gas Label')\nax.set_ylabel('Mean Response')\nax.set_xlabel('Sensor')\nax.legend(title='Gas', bbox_to_anchor=(1.02, 1))\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/01_Sensor_Data_Analysis.html#summary",
    "href": "projects/01_Sensor_Data_Analysis.html#summary",
    "title": "Industrial Sensor Data Analysis",
    "section": "",
    "text": "Explored 16 sensors across 65k+ readings\nIdentified cross-sensor correlations and shared-noise structure\nQuantified sensor drift via rolling statistics\nSegmented response patterns by gas label\n\nThese features and patterns feed directly into the Anomaly Detection and ML Classification notebooks."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\ntitle: “About Me” page-layout: full include-sidebar: false\n\n\n\n&lt;!-- Replace src with your own photo --&gt;\n&lt;img src=\"../assets/avatar.png\" alt=\"Your Name\" /&gt;\n\n\n&lt;h1&gt;Hi, I'm &lt;span class=\"accent\"&gt;Your Name&lt;/span&gt;&lt;/h1&gt;\n&lt;p class=\"about-role\"&gt;Data Scientist & ML Engineer&lt;/p&gt;\n&lt;p&gt;\n  I build end-to-end machine learning systems — from initial data exploration\n  through model training, evaluation, and production deployment.\n  I believe in reproducible research, clean code, and clearly communicating results.\n&lt;/p&gt;\n\n\n\n\nExperience\nRole | Company | Period |\n|||| | Senior Data Scientist | Company A | 2023 – Present | | ML Engineer | Company B | 2021 – 2023 | | Junior Analyst | Company C | 2019 – 2021 |\n\n\n\nEducation\nM.S. in Computer Science — University Name, 2019\nFocus: Machine Learning & Statistical Learning\nB.S. in Mathematics — University Name, 2017\n\n\n\nContact\nFeel free to reach out for collaborations, questions, or just to say hi.\n\nEmail: your.email@example.com\n\nGitHub: github.com/yourusername\n\nLinkedIn: linkedin.com/in/yourusername"
  },
  {
    "objectID": "about.html#professional-experience",
    "href": "about.html#professional-experience",
    "title": "About Me",
    "section": "",
    "text": "Company A 2023 – Present\n\n\n\nLed development of ML pipelines for predictive maintenance, reducing downtime by 35%\nBuilt and deployed real-time anomaly detection systems processing 100k+ events/day\nMentored junior data scientists and established best practices for model deployment\nCollaborated with cross-functional teams to translate business needs into technical solutions\n\n\n\n\n\n\nCompany B 2021 – 2023\n\n\n\nDesigned and implemented time series forecasting models with 85%+ accuracy\nDeveloped automated data quality monitoring and alerting systems\nOptimized model inference latency by 60% through efficient feature engineering\nCreated comprehensive documentation and training materials for ML workflows\n\n\n\n\n\n\nCompany C 2019 – 2021\n\n\n\nPerformed exploratory data analysis on large-scale datasets (65k+ records)\nBuilt interactive dashboards for business stakeholders using Python and Plotly\nConducted statistical analysis and A/B testing to inform product decisions\nAutomated reporting workflows, saving 20+ hours per week"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "",
    "text": "🎓\n\n\n\n\nUniversity Name, 2019\n\n\nFocus: Machine Learning & Statistical Learning\n\n\n\nAdvanced Machine Learning\n\n\nDeep Learning & Neural Networks\n\n\nStatistical Learning Theory\n\n\nProbabilistic Graphical Models\n\n\n\n\n\n\n📐\n\n\n\n\nUniversity Name, 2017\n\n\nFocus: Applied Mathematics & Statistics\n\n\n\nLinear Algebra & Optimization\n\n\nProbability & Statistics\n\n\nComputational Methods\n\n\nMathematical Modeling"
  },
  {
    "objectID": "about.html#technical-skills",
    "href": "about.html#technical-skills",
    "title": "About Me",
    "section": "",
    "text": "Python SQL Git Docker Linux Jupyter\n\n\n\n\n\nScikit-learn XGBoost PyTorch TensorFlow Keras LightGBM\n\n\n\n\n\nPandas NumPy Scipy Matplotlib Seaborn Plotly\n\n\n\n\n\nMLflow FastAPI AWS CI/CD Monitoring Testing"
  },
  {
    "objectID": "about.html#lets-connect",
    "href": "about.html#lets-connect",
    "title": "About Me",
    "section": "",
    "text": "I’m always interested in new opportunities, collaborations, and conversations about data science and machine learning. Feel free to reach out!\n\n\n\n\n📧\n\n\n\nyour.email@example.com\n\n\n\n\n💼\n\n\n\nlinkedin.com/in/yourusername\n\n\n\n\n🐙\n\n\n\ngithub.com/yourusername\n\n\n\n\n📄\n\n\n\nDownload PDF"
  }
]